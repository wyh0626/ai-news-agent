# ğŸ”¥ ä»Šæ—¥ç„¦ç‚¹
- ByteDance Protenix-v1ï¼šByteDance æ¨å‡º Protenix-v1 å¼€æºè›‹ç™½è´¨/ç”Ÿç‰©åˆ†å­ç»“æ„é¢„æµ‹æ¨¡å‹ï¼Œå®£ç§°è¾¾åˆ° AF3 çº§åˆ«æ€§èƒ½ï¼Œä»£ç æ‰˜ç®¡åœ¨ GitHubï¼ˆbytedance/Protenixï¼‰ï¼Œæ„åœ¨æä¾› AlphaFold çš„å¼€æºæ›¿ä»£æ–¹æ¡ˆï¼Œå¼•å‘ Reddit ç¤¾åŒºå…³æ³¨ã€‚é“¾æ¥ï¼šhttps://www.reddit.com/r/LocalLLaMA/comments/1r3mnm3/bytedance_releases_protenixv1/
- llama.cpp llama-server VRAM ä¿®å¤ï¼šllama.cpp çš„ llama-server é’ˆå¯¹ SSM æ··åˆæ¨¡å‹çš„ VRAM ä½¿ç”¨é—®é¢˜å·²åˆå¹¶ä¿®å¤ï¼Œåœ¨ 1M contextã€å¹¶è¡Œå‚æ•° --parallel=8 ä¸‹ï¼ŒKV ç¼“å­˜çš„æ˜¾å­˜éœ€æ±‚æ˜¾è‘—ä¸‹é™è‡³ ~6GBï¼Œä½¿åœ¨ 48GB VRAM æ¡ä»¶ä¸‹å¯å¹¶å‘æœåŠ¡æ›´å¤šç”¨æˆ·ï¼Œé€‚ç”¨äº Qwen3Nextã€Kimi Linearã€Nemotron 3 Nano ç­‰æ¨¡å‹ã€‚é“¾æ¥ï¼šhttps://www.reddit.com/r/LocalLLaMA/comments/1r3q0qb/llamacpp_llamaserver_running_ssm_models_vram_fix/
- Nvidia Dynamic Memory Sparsification (DMS)ï¼šNVIDIA æ¨å‡º DMSï¼Œé€šè¿‡å¯¹ KV ç¼“å­˜è¿›è¡Œå­¦ä¹ å‹ä¿ç•™ä¸å»¶è¿Ÿé€å‡ºï¼Œæœ€é«˜å¯å®ç° KV ç¼“å­˜é™å¹… 8 å€ï¼ŒåŒæ—¶æå‡æ¨ç†é€Ÿåº¦ä¸å¹¶å‘èƒ½åŠ›ï¼Œå¯¹è‡ªæ‰˜ç®¡å¤§æ¨¡å‹æ¨ç†å…·æœ‰é‡è¦æ„ä¹‰ã€‚é“¾æ¥ï¼šhttps://www.reddit.com/r/LocalLLaMA/comments/1r3t8ro/nvidias_new_technique_cuts_llm_reasoning_costs_by/

---

## é‡ç‚¹æ–°é—»

### ç”Ÿç‰©ä¿¡æ¯å­¦ä¸å¼€æºè›‹ç™½è´¨ç»“æ„é¢„æµ‹
- ByteDance Protenix-v1
  - ç®€ä»‹ä¸èƒŒæ™¯ï¼šByteDance æ¨å‡º Protenix-v1 å¼€æºè›‹ç™½è´¨/ç”Ÿç‰©åˆ†å­ç»“æ„é¢„æµ‹æ¨¡å‹ï¼Œå®šä½ä¸º AlphaFold çš„å¼€æºç«äº‰å¯¹æ‰‹ï¼Œæ—¨åœ¨æ¨åŠ¨æ›´å¹¿æ³›çš„ç¤¾åŒºå‚ä¸ä¸åˆ›æ–°ã€‚
  - å½±å“ä¸åˆ†æï¼šè‹¥å¯¹é½ AF3 çº§åˆ«çš„æ€§èƒ½æ‰¿è¯ºæˆç«‹ï¼Œå¯èƒ½æ‹“å±•å¼€æºç”Ÿç‰©ä¿¡æ¯å­¦å·¥å…·çš„å¯åŠæ€§ï¼ŒåŠ é€Ÿå­¦æœ¯ä¸äº§ä¸šç ”ç©¶çš„ä½æˆæœ¬éªŒè¯ä¸å†è®­ç»ƒï¼›GitHub çš„å¼€æºæ¨¡å¼ä¹Ÿå°†åŠ é€Ÿç¤¾åŒºå®¡é˜…ä¸æ”¹è¿›ã€‚
  - é“¾æ¥ï¼šhttps://www.reddit.com/r/LocalLLaMA/comments/1r3mnm3/bytedance_releases_protenixv1/

### LLM æ¨ç†ä¸åŸºç¡€è®¾æ–½ä¼˜åŒ–
- llama.cpp llama-server VRAM ä¿®å¤
  - ç®€ä»‹ä¸èƒŒæ™¯ï¼šé’ˆå¯¹ SSM æ··åˆæ¨¡å‹çš„ VRAM éœ€æ±‚ï¼Œä¿®å¤ååœ¨é«˜å¹¶å‘åœºæ™¯ä¸‹æ˜¾å­˜åˆ©ç”¨æ›´æ¥è¿‘ Transformer æ¨¡å‹ï¼Œæ˜¾è‘—é™ä½å•å¡æ˜¾å­˜å‹åŠ›ã€‚
  - å½±å“ä¸åˆ†æï¼šåœ¨ 48GB ä½™é‡çš„è®¾å¤‡ä¸Šå¯å¹¶å‘æœåŠ¡æ›´å¤šç”¨æˆ·ï¼Œæå‡è‡ªæ‰˜ç®¡éƒ¨ç½²çš„è§„æ¨¡åŒ–èƒ½åŠ›ï¼Œç‰¹åˆ«å¯¹ Qwen3Nextã€Kimi Linearã€Nemotron 3 Nano ç­‰æ¨¡å‹å‹å¥½ã€‚
  - é“¾æ¥ï¼šhttps://www.reddit.com/r/LocalLLaMA/comments/1r3q0qb/llamacpp_llamaserver_running_ssm_models_vram_fix/
- Nvidia Dynamic Memory Sparsification (DMS)
  - ç®€ä»‹ä¸èƒŒæ™¯ï¼šDMS åœ¨æ¨ç†é˜¶æ®µå¯¹ KV ç¼“å­˜è¿›è¡Œå­¦ä¹ å‹ä¿ç•™ä¸å»¶è¿Ÿé€å‡ºï¼Œå…è®¸å¯¹ä½é‡è¦æ€§ token è¿›è¡ŒçŸ­æ—¶ä¿ç•™ä»¥æå–ä¿¡æ¯ï¼Œæå‡æ¨ç†æ•ˆç‡ä¸å¹¶å‘å¤„ç†ã€‚
  - å½±å“ä¸åˆ†æï¼šæœ€é«˜å¯å®ç° 8x çš„ç¼“å­˜é™å¹…ï¼Œæ˜¾è‘—é™ä½æ˜¾å­˜å‹åŠ›ï¼Œæå‡è‡ªæ‰˜ç®¡åœºæ™¯çš„è§„æ¨¡åŒ–æ¨ç†èƒ½åŠ›ï¼Œæœªæ¥åœ¨æ•°æ®ä¸­å¿ƒä¸è¾¹ç¼˜éƒ¨ç½²ä¸­å€¼å¾—å…³æ³¨ã€‚
  - é“¾æ¥ï¼šhttps://www.reddit.com/r/LocalLLaMA/comments/1r3t8ro/nvidias_new_technique_cuts_llm_reasoning_costs_by/

### å¼€æºå¤§æ¨¡å‹ç”Ÿæ€ä¸ç¤¾åŒºæ´»åŠ¨
- MiniMax ç›¸å…³ AMA ä¸ç¤¾åŒºå¯¹è¯
  - AMA Announcement: MiniMax, The Opensource Lab Behind MiniMax-M2.5 SoTA Model
    - èƒŒæ™¯ï¼šå®£å¸ƒ MiniMax Lab å°†å‡ºå¸­æœ¬åœ° LLaMA ç¤¾åŒºçš„ AMAï¼Œå›´ç»• MiniMax-M2.5 è¿™ä¸€å¼€æº SoTA æ¨¡å‹åŠç›¸å…³å·¥ä½œè¿›è¡Œè®¨è®ºã€‚
    - å½±å“ï¼šä½“ç°ç¤¾åŒºé€æ˜åº¦ä¸å¼€æºç ”ç©¶çš„åä½œæ°›å›´ï¼Œå¯èƒ½æ¨åŠ¨åç»­ç‰ˆæœ¬å‘å¸ƒä¸ç”¨æˆ·åé¦ˆçš„å¿«é€Ÿé—­ç¯ã€‚
    - é“¾æ¥ï¼šhttps://www.reddit.com/r/LocalLLaMA/comments/1r3csbk/ama_announcement_minimax_the_opensource_lab/
  - AMA with MiniMax â€” Ask Us Anything!
    - èƒŒæ™¯ï¼šr/LocalLLaMA å¹³å°å†æ¬¡ä¸¾è¡Œ MiniMax å›¢é˜Ÿçš„ AMAï¼Œæˆå‘˜è¦†ç›– Founder/CEOã€LLM ç ”ç©¶è´Ÿè´£äººç­‰ï¼Œå¼ºåŒ–å¯¹ MiniMax äº§å“çº¿çš„ç†è§£ä¸å‚ä¸ã€‚
    - å½±å“ï¼šæœ‰åŠ©äºå»ºç«‹ç¤¾åŒºä¿¡ä»»å¹¶æ¨åŠ¨å¤šæ¨¡æ€äº§å“çº¿çš„è®¨è®ºä¸åˆä½œã€‚
    - é“¾æ¥ï¼šhttps://www.reddit.com/r/LocalLLaMA/comments/1r3t775/ama_with_minimax_ask_us_anything/
  - MiniMax onX: Weights dropping REALLY, REALLY, SOON
    - èƒŒæ™¯ï¼šå…³äº MiniMax onX å¼€æºæƒé‡å³å°†å…¬å¼€çš„ä¼ é—»ï¼Œè‹¥æˆçœŸå°†ç›´æ¥å½±å“å¼€æºå¤§æ¨¡å‹ç¤¾åŒºçš„æƒé‡è·å–ä¸å¯¹æ¯”ã€‚
    - å½±å“ï¼šå¯èƒ½æ”¹å˜å¼€æºæ¨¡å‹çš„å¯ç”¨æ€§ä¸ç«äº‰æ ¼å±€ï¼Œå€¼å¾—æŒç»­å…³æ³¨æƒé‡ä¸Šçº¿æ—¶é—´è¡¨ã€‚
    - é“¾æ¥ï¼šhttps://www.reddit.com/r/LocalLLaMA/comments/1r3l572/minimax_onx_weights_dropping_really_really_soon/
- DeepSeek é•¿ä¸Šä¸‹æ–‡ä¸æ¨¡å‹è¿›å±•
  - New DeepSeek update: 1M context window
    - èƒŒæ™¯ï¼šDeepSeek æ­£åœ¨æµ‹è¯•æ–°çš„é•¿ä¸Šä¸‹æ–‡æ¨¡å‹æ¶æ„ï¼ŒWeb/APP ç«¯å°†æ”¯æŒé«˜è¾¾ 1M çš„ä¸Šä¸‹æ–‡çª—å£ï¼Œæ˜¾ç¤ºåœ¨æ‰©å±•æ¨¡å‹èƒ½åŠ›æ–¹é¢çš„æŒç»­æŠ•å…¥ã€‚
    - å½±å“ï¼šå¯¹è¶…é•¿æ–‡æœ¬å¤„ç†åœºæ™¯å°†å¸¦æ¥æ˜¾è‘—çš„åº”ç”¨æ½œåŠ›ï¼Œå¯èƒ½æ¨åŠ¨ä¼ä¸šçº§åº”ç”¨çš„æœ€è¿‘éœ€æ±‚ã€‚
    - é“¾æ¥ï¼šhttps://www.reddit.com/r/LocalLLaMA/comments/1r3o6je/new_deepseek_update_deepseek_web_app_is_currently/
  - Deepseek announced they are testing a new model
    - èƒŒæ™¯ä¸åˆ†æï¼šå…¬å¸ƒæµ‹è¯•æ–°æ¨¡å‹å¹¶ç»™å‡ºé¢å‘é˜…è¯»ç†è§£æŠ€èƒ½çš„è¯„æµ‹ï¼Œå°½ç®¡åç§°ä¸ºå ä½ç¬¦ä»¥åŒºåˆ†æ¡ç›®ï¼Œä½†æ˜¾ç¤ºå…¶åœ¨è¡Œä¸šæ ‡å‡†æ•°æ®é›†ä¸Šçš„åˆæ­¥èƒ½åŠ›è¯„ä¼°ã€‚
    - é“¾æ¥ï¼šhttps://www.reddit.com/r/LocalLLaMA/comments/1r3ntgi/deepseek_announced_they_are_testing_a_new_model/
- Dhi-5B ä¸å¤šæ¨¡æ€è®­ç»ƒè¿›å±•
  - UG student launches Dhi-5B (Trained from Scratch)
    - èƒŒæ™¯ï¼šæœ¬ç§‘ç”ŸæŠ«éœ² 50 äº¿å‚æ•°çš„å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹ Dhi-5Bï¼Œè®­ç»ƒæˆæœ¬æ®ç§°ä»… â‚¹1.1 lakhï¼Œåˆ†é˜¶æ®µå‘å¸ƒè®¡åˆ’åŒ…æ‹¬ Base/Instruct ç­‰ç‰ˆæœ¬ã€‚
    - å½±å“ï¼šå±•ç¤ºä¸ªäººå’Œå°å›¢é˜Ÿåœ¨ä½æˆæœ¬æ¡ä»¶ä¸‹æ¢ç´¢é«˜å‚æ•°æ¨¡å‹çš„å¯èƒ½æ€§ï¼Œæˆ–æ¨åŠ¨ç¤¾åŒºåœ¨å¤šæ¨¡æ€æ¨¡å‹è®­ç»ƒæˆæœ¬æ–¹é¢çš„è®¨è®ºã€‚
    - é“¾æ¥ï¼šhttps://www.reddit.com/r/LocalLLaMA/comments/1r3hlfq/ug_student_launches_dhi5b_trained_from_scratch/
- Apple Silicon ç¯å¢ƒä¸‹çš„å¼€æºæ¨ç†æœåŠ¡å™¨
  - oMLX - open-source MLX inference server with paged SSD caching for Apple Silicon
    - èƒŒæ™¯ï¼šä»‹ç»é¢å‘ Apple Silicon çš„å¼€æº MLX æ¨ç†æœåŠ¡å™¨ï¼Œæä¾›åŸç”Ÿ macOS åº”ç”¨ä¸æ˜“ç”¨éƒ¨ç½²ï¼Œå¼ºè°ƒä¸ Obsidian Copilotã€ Ollama ç­‰ç”Ÿæ€çš„æ•´åˆã€‚
    - å½±å“ï¼šä¸ºåœ¨ Mac æœ¬åœ°è¿›è¡Œ LLM æ¨ç†çš„å¼€å‘è€…æä¾›ä¾¿æ·æ–¹æ¡ˆï¼Œæ¨åŠ¨æœ¬åœ°åŒ–æ¨ç†ç”Ÿæ€çš„å‘å±•ã€‚
    - é“¾æ¥ï¼šhttps://www.reddit.com/r/LocalLLaMA/comments/1r3qwyi/omlx_opensource_mlx_inference_server_with_paged/
- MiniMax ç”Ÿæ€çš„æƒé‡ä¸å‘å¸ƒåŠ¨æ€
  - MiniMax-M2.5 Checkpoints on huggingface will be in
    - èƒŒæ™¯ï¼šå…³äº MiniMax-M2.5 åœ¨ HuggingFace ä¸Šçº¿æ£€æŸ¥ç‚¹çš„æ—¶é—´çº¿æ›´æ–°ï¼Œæ ‡å¿—ç€æƒé‡å…¬å¼€çš„æ—¶é—´ç‚¹é€æ­¥é€¼è¿‘ã€‚
    - é“¾æ¥ï¼šhttps://www.reddit.com/r/LocalLLaMA/comments/1r3kzce/minimaxm25_checkpoints_on_huggingface_will_be_in/

---

## å¿«è®¯é€Ÿè§ˆ
- GLM 5 has a regression in international language writing according to NCBench
  - 1 æ¡ä¿¡æ¯æ‘˜è¦ï¼šGLM 5 åœ¨å›½é™…è¯­è¨€å†™ä½œåŸºå‡†ä¸Šå‡ºç°å›å½’ï¼Œè½åäº GLM 4.5â€“4.7ï¼Œæ¬§æ´²è¯­è¨€ä¸å°åœ°è¯­è¡¨ç°ä¸ä½³ï¼Œä½† Language Comprehension æœªæ˜¾å›é€€ã€‚æ¥æº Reddit ç”¨æˆ· u/jugalator çš„è¯„æµ‹è´´ã€‚
  - é“¾æ¥ï¼šhttps://www.reddit.com/r/LocalLLaMA/comments/1r3ob0r/glm_5_has_a_regression_in_international_language/
- MiniMaxAI/MiniMax-M2.5 Â· Hugging Face
  - 1 æ¡ä¿¡æ¯æ‘˜è¦ï¼šé€šè¿‡ HuggingFace æ¨¡å‹é¡µå¯æŸ¥çœ‹ MiniMax-M2.5 çš„æœ€æ–°è¿›å±•ä¸æƒé‡ï¼Œé¡µé¢æŒ‰ä¿®æ”¹æ—¶é—´æ’åºå¹¶å¸¦æœ‰ search=minimax m2.5 çš„æ£€ç´¢ã€‚æ¥æº Reddit ç”¨æˆ· /u/rerriã€‚
  - é“¾æ¥ï¼šhttps://www.reddit.com/r/LocalLLaMA/comments/1r3pxy7/minimaxaiminimaxm25_hugging_face/
- MiniMax-M2.5 Checkpoints on huggingface will be in
  - 1 æ¡ä¿¡æ¯æ‘˜è¦ï¼šMiniMax-M2.5 çš„æ£€æŸ¥ç‚¹å°†åœ¨å¤§çº¦ 8 å°æ—¶ååœ¨ HuggingFace ä¸Šçº¿ï¼Œç¤¾åŒºè®¨è®ºä¸­åŒ…å«ç›¸å…³æ¨æ–­ä¸ä¸Šçº¿å‡†å¤‡ã€‚æ¥æº Reddit ç”¨æˆ· Own_Forever_5997ã€‚
  - é“¾æ¥ï¼šhttps://www.reddit.com/r/LocalLLaMA/comments/1r3kzce/minimaxm25_checkpoints_on_huggingface_will_be_in/
- MiniMaxAI MiniMax-M2.5 has 230b parameters and 10b active parameters
  - 1 æ¡ä¿¡æ¯æ‘˜è¦ï¼šMiniMax-M2.5 æ€»å‚æ•°é‡ 2300 äº¿ï¼Œæ´»è·ƒå‚æ•° 100 äº¿ï¼Œè™½æŠ«éœ²è§„æ¨¡ä½†å°šæœªåœ¨ HuggingFace ä¸Šçº¿ï¼Œç­‰å¾…æ­£å¼å‘å¸ƒã€‚æ¥æº Reddit ç”¨æˆ· /u/Zyjã€‚
  - é“¾æ¥ï¼šhttps://www.reddit.com/r/LocalLLaMA/comments/1r35d2x/minimaxai_minimaxm25_has_230b_parameters_and_10b/
- RAM shortage problem solved
  - 1 æ¡ä¿¡æ¯æ‘˜è¦ï¼šLocalLLaMA ç¤¾åŒºè´´æ–‡æ ‡é¢˜â€œRAM shortage problem solvedâ€ï¼Œå½“å‰ä»…æœ‰æ ‡é¢˜ä¸é“¾æ¥ï¼ŒæœªæŠ«éœ²å…·ä½“ç»†èŠ‚ï¼ŒæŒ‡ç¤º RAM çŸ­ç¼ºé—®é¢˜å¯èƒ½å·²è¢«è§£å†³ã€‚
  - é“¾æ¥ï¼šhttps://www.reddit.com/r/LocalLLaMA/comments/1r3tqox/ram_shortage_problem_solved/