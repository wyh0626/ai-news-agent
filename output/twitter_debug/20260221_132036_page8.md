[![](https://nitter.net/pic/list_banner_img%2F1613505644405075970%2F9VRDCFnW%3Fformat%3Djpg%26name%3Dorig)](https://nitter.net/pic/list_banner_img%2F1613505644405075970%2F9VRDCFnW%3Fformat%3Djpg%26name%3Dorig)

"AI High Signal" by @

AI twitter accounts that are high signal

- [Tweets](https://nitter.net/i/lists/1585430245762441216)
- [Members](https://nitter.net/i/lists/1585430245762441216/members)

[Load newest](https://nitter.net/i/lists/1585430245762441216)

[![](https://nitter.net/pic/profile_images%2F1993095459338846208%2Fnm8-u0zh_bigger.jpg)](https://nitter.net/AymericRoucher)

[m\_ric](https://nitter.net/AymericRoucher "m_ric")

[@AymericRoucher](https://nitter.net/AymericRoucher "@AymericRoucher")

[21h](https://nitter.net/AymericRoucher/status/2024859949944156417#m "Feb 20, 2026 Â· 2:53 PM UTC")

Custom hardware from Taalas runs Llama-3.1-8B, at 17k tokens per second
17k ðŸ¤¯
Absolutely insane

(For the record Cerebras is crazy good and they're at 2k on the same model)
And latency is very low too!

Their chatbot is here: [chatjimmy.ai/](https://chatjimmy.ai/)

It's genuinely a eerie experience to get instant responses like that

[![](https://nitter.net/pic/media%2FHBm_PZiWMAAdbcW.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBm_PZiWMAAdbcW.jpg)

1

1

10

[![](https://nitter.net/pic/profile_images%2F1993095459338846208%2Fnm8-u0zh_bigger.jpg)](https://nitter.net/AymericRoucher)

[m\_ric](https://nitter.net/AymericRoucher "m_ric")

[@AymericRoucher](https://nitter.net/AymericRoucher "@AymericRoucher")

[21h](https://nitter.net/AymericRoucher/status/2024860081041317982#m "Feb 20, 2026 Â· 2:53 PM UTC")

My first thought was "why did they even bother implementing a streaming UI"

1

[![](https://nitter.net/pic/profile_images%2F1993095459338846208%2Fnm8-u0zh_bigger.jpg)](https://nitter.net/AymericRoucher)

[m\_ric](https://nitter.net/AymericRoucher "m_ric")

[@AymericRoucher](https://nitter.net/AymericRoucher "@AymericRoucher")

[21h](https://nitter.net/AymericRoucher/status/2024860156769587407#m "Feb 20, 2026 Â· 2:54 PM UTC")

Their blog post here: [taalas.com/the-path-to-ubiquâ€¦](https://taalas.com/the-path-to-ubiquitous-ai/)

[![](https://nitter.net/pic/card_img%2F2024516175854469120%2Fk6M6TB80%3Fformat%3Dpng%26name%3D420x420_2)\\
\\
**The path to ubiquitous AI \| Taalas** \\
\\
By Ljubisa Bajic Many believe AI is the real deal. In narrow domains, it already surpasses human performance. Used well, it is an unprecedented amplifier of human ingenuity and productivity. Its...\\
\\
taalas.com](https://taalas.com/the-path-to-ubiquitous-ai/)

[![](https://nitter.net/pic/profile_images%2F1790643775401754626%2Fcr9uM-ie_bigger.png)](https://nitter.net/ben_burtenshaw)

[Ben Burtenshaw](https://nitter.net/ben_burtenshaw "Ben Burtenshaw")

[@ben\_burtenshaw](https://nitter.net/ben_burtenshaw "@ben_burtenshaw")

[21h](https://nitter.net/ben_burtenshaw/status/2024859763855544499#m "Feb 20, 2026 Â· 2:52 PM UTC")

nano harness is a code first agent harness in 223 lines of code. it's rough, ready, and very hackable.

I had a lot of fun hacking with this today and learnt a lot about code first/ code act harnesses. take it for a spin and let me know if it's useful.

gist in the thread.

![](https://nitter.net/pic/amplify_video_thumb%2F2024858832644546560%2Fimg%2FXWevCztGEsWXwJSG.jpg%3Fname%3Dsmall%26format%3Dwebp)

Enable hls playback

1

4

33

[![](https://nitter.net/pic/profile_images%2F1790643775401754626%2Fcr9uM-ie_bigger.png)](https://nitter.net/ben_burtenshaw)

[Ben Burtenshaw](https://nitter.net/ben_burtenshaw "Ben Burtenshaw")

[@ben\_burtenshaw](https://nitter.net/ben_burtenshaw "@ben_burtenshaw")

[21h](https://nitter.net/ben_burtenshaw/status/2024859766544019657#m "Feb 20, 2026 Â· 2:52 PM UTC")

here's the gist to try it out: [gist.github.com/burtenshaw/4â€¦](https://gist.github.com/burtenshaw/4ec60226d81935b178c581b97b5fe9b1)

[![](https://nitter.net/pic/media%2FHBm-6mgWAAAWuYB.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBm-6mgWAAAWuYB.jpg)

1

2

[![](https://nitter.net/pic/profile_images%2F2019196082727620608%2FiIXCFAJb_bigger.jpg)](https://nitter.net/TheTuringPost)

[Ksenia\_TuringPost](https://nitter.net/TheTuringPost "Ksenia_TuringPost")

[@TheTuringPost](https://nitter.net/TheTuringPost "@TheTuringPost")

[21h](https://nitter.net/TheTuringPost/status/2024859570208735613#m "Feb 20, 2026 Â· 2:51 PM UTC")

â€œTired of the same ultracrepidarian professional talking headsâ€ â€“ what a brilliant phrase.

First, Swyx is absolutely right: who do these conferences actually serve?

Second, I admire how he is not a talker but a doer: he found a precise niche of builders and serves it with taste, in a way thatâ€™s genuinely useful for the whole industry.

Third, thereâ€™s such pure emotion in this text that that alone makes it worth reading.

![](https://nitter.net/pic/profile_images%2F1867875781676007424%2FRIF4Kt7U_mini.jpg)[swyx](https://nitter.net/swyx "swyx")

[@swyx](https://nitter.net/swyx "@swyx")

[Feb 19](https://nitter.net/swyx/status/2024616612599587282#m "Feb 19, 2026 Â· 10:46 PM UTC")

[x.com/i/article/202460118068â€¦](http://x.com/i/article/2024601180689903616)

1

3

[![](https://nitter.net/pic/profile_images%2F939313677647282181%2FvZjFWtAn_bigger.jpg)](https://nitter.net/omarsar0)

[elvis](https://nitter.net/omarsar0 "elvis")

[@omarsar0](https://nitter.net/omarsar0 "@omarsar0")

[21h](https://nitter.net/omarsar0/status/2024859532892029267#m "Feb 20, 2026 Â· 2:51 PM UTC")

"The Coding Agent is Dead"

There is something you don't hear these days.

It's worth the read. We are gradually moving toward higher levels of interaction with agents.

"How you organize your codebase for agents, how your organization uses them â€” those are now the bottlenecks."

![](https://nitter.net/pic/profile_images%2F845340663050899457%2FvNzxTmKV_mini.jpg)[Thorsten Ball](https://nitter.net/thorstenball "Thorsten Ball")

[@thorstenball](https://nitter.net/thorstenball "@thorstenball")

[Feb 19](https://nitter.net/thorstenball/status/2024509255894671396#m "Feb 19, 2026 Â· 3:39 PM UTC")

We believe the coding agent is dead.

Soon, Amp will look very different.

[ampcode.com/news/the-coding-â€¦](https://ampcode.com/news/the-coding-agent-is-dead)

[![](https://nitter.net/pic/media%2FHBh4FcBWQAAByU_.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBh4FcBWQAAByU_.jpg)

11

11

159

[![](https://nitter.net/pic/profile_images%2F1451191636810092553%2FkpM5Fe12_bigger.jpg)](https://nitter.net/_akhaliq)

[AK](https://nitter.net/_akhaliq "AK")

[@\_akhaliq](https://nitter.net/_akhaliq "@_akhaliq")

[21h](https://nitter.net/_akhaliq/status/2024859252297220294#m "Feb 20, 2026 Â· 2:50 PM UTC")

Llama.cpp joins Hugging Face

[![](https://nitter.net/pic/media%2FHBm-qqqXQAEJwyk.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBm-qqqXQAEJwyk.jpg)

3

10

54

Vaibhav (VB) Srivastav retweeted

[![](https://nitter.net/pic/profile_images%2F378800000261649705%2Fbe9cc55e64014e6d7663c50d7cb9fc75_bigger.jpeg)](https://nitter.net/simonw)

[Simon Willison](https://nitter.net/simonw "Simon Willison")

[@simonw](https://nitter.net/simonw "@simonw")

[21h](https://nitter.net/simonw/status/2024855027517702345#m "Feb 20, 2026 Â· 2:33 PM UTC")

Georgi's llama.cpp really kicked off the whole local model thing in my opinion - it made original Llama usable on personal computers, I wrote about it back in March 2023 [simonwillison.net/2023/Mar/1â€¦](https://simonwillison.net/2023/Mar/11/llama/#llama-cpp)

[![llama.cpp # LLaMA on its own isnâ€™t much good if itâ€™s still too hard to run it on a personal laptop.  Enter Georgi Gerganov.  Georgi is an open source developer based in Sofia, Bulgaria (according to his GitHub profile). He previously released whisper.cpp, a port of OpenAIâ€™s Whisper automatic speech recognition model to C++. That project made Whisper applicable to a huge range of new use cases.  Heâ€™s just done the same thing with LLaMA.  Georgiâ€™s llama.cpp project had its initial release yesterday. From the README:  The main goal is to run the model using 4-bit quantization on a MacBook.  4-bit quantization is a technique for reducing the size of models so they can run on less powerful hardware. It also reduces the model sizes on diskâ€”to 4GB for the 7B model and just under 8GB for the 13B one.  It totally works!  I used it to run the 7B LLaMA model on my laptop last night, and then this morning upgraded to the 13B modelâ€”the one that Facebook claim is competitive with GPT-3.](https://nitter.net/pic/media%2FHBm66bZbYAAKBU6.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBm66bZbYAAKBU6.jpg)

ALT llama.cpp #
LLaMA on its own isnâ€™t much good if itâ€™s still too hard to run it on a personal laptop.

Enter Georgi Gerganov.

Georgi is an open source developer based in Sofia, Bulgaria (according to his GitHub profile). He previously released whisper.cpp, a port of OpenAIâ€™s Whisper automatic speech recognition model to C++. That project made Whisper applicable to a huge range of new use cases.

Heâ€™s just done the same thing with LLaMA.

Georgiâ€™s llama.cpp project had its initial release yesterday. From the README:

The main goal is to run the model using 4-bit quantization on a MacBook.

4-bit quantization is a technique for reducing the size of models so they can run on less powerful hardware. It also reduces the model sizes on diskâ€”to 4GB for the 7B model and just under 8GB for the 13B one.

It totally works!

I used it to run the 7B LLaMA model on my laptop last night, and then this morning upgraded to the 13B modelâ€”the one that Facebook claim is competitive with GPT-3.

![](https://nitter.net/pic/profile_images%2F1654097134315098113%2FzCZD0wYz_mini.jpg)[Georgi Gerganov](https://nitter.net/ggerganov "Georgi Gerganov")

[@ggerganov](https://nitter.net/ggerganov "@ggerganov")

[22h](https://nitter.net/ggerganov/status/2024839991482777976#m "Feb 20, 2026 Â· 1:34 PM UTC")

Today [ggml.ai](http://ggml.ai/) joins Hugging Face

Together we will continue to build ggml, make llama.cpp more accessible and empower the open-source community. Our joint mission is to make local AI easy and efficient to use by everyone on their own hardware.

21

33

392

Kyle Russell retweeted

[![](https://nitter.net/pic/profile_images%2F1753264923365523456%2FmUCvwn7v_bigger.jpg)](https://nitter.net/nickcammarata)

[Nick](https://nitter.net/nickcammarata "Nick")

[@nickcammarata](https://nitter.net/nickcammarata "@nickcammarata")

[Feb 20](https://nitter.net/nickcammarata/status/2024704310479901147#m "Feb 20, 2026 Â· 4:34 AM UTC")

the obvious lesson is â€œonly do things for joyâ€

but the real move is deliberately training joy itself, as youâ€™d train your physical muscles. stop optimizing the activity, upgrade the substrate. then it doesnâ€™t matter what youâ€™re doing, whatever it is, it will be done joyfully

![](https://nitter.net/pic/profile_images%2F1927795530920239104%2Frv8FxhKB_mini.jpg)[Brad Stulberg](https://nitter.net/BStulberg "Brad Stulberg")

[@BStulberg](https://nitter.net/BStulberg "@BStulberg")

[Feb 19](https://nitter.net/BStulberg/status/2024628741910196463#m "Feb 19, 2026 Â· 11:34 PM UTC")

Joy is a competitive super power.

Alysa Liu retired from figure skating at 16.
She was tired of not not having fun, tired of being consumed by her sport.

She came back two years later with a new goal: to have as much fun on the ice as possible. And now sheâ€™s an Olympic gold medalist.

Liu won her first national title when she was just 13. But by 16, after competing in the 2022 Olympics, she decided sheâ€™d had enough and stepped away. She said pressure and losing her identity trying to be an elite athlete made it all miserable.

But then, she said she went on a ski trip that reminded her just how much fun she could have doing a sport. Something in her brain clicked. Maybe she could bring fun to figure skating. Maybe she could approach it in a way that could be full of joy and life and love.

She unretired at 18 and won a world championship the next year. At 20, she was ready to face these Olympic games differently than in 2022.

Liu went into the womenâ€™s figure skating final in third place. After her short program, she said:

â€œEven if I mess up and fall, thatâ€™s totally okay, too. Iâ€™m fine with any outcome, as long as Iâ€™m out there.â€

One of the greatest competitive advantages is having fun. People love to romanticize the athlete, artist, or entrepreneur who has a chip on their shoulder, fueled by anger and resentment.

But the truth is that if youâ€™re not having fun, you are not going to last long at whatever it is you do, and you certainly wonâ€™t get the best out of yourself. Thereâ€™s a foolish idea that you either have to be full of intensity or full of joy. But thatâ€™s nonsense.

Itâ€™s no surprise one of the first things out of Alysaâ€™s mouth after her free skate was: â€œThat was so much fun!â€

Joy and intensity can coexist, and in the best performers, they almost always do.

Alysa is unapologetically authentic and true to her values. She has said where she used to skate to win and be technically perfect, she now uses competition as a chance to show her art, to have fun, and to put herself out there.

Sheâ€™s a fierce athlete with an infectious sense of joy in her sport.

And she broke USA's 24-year gold medal draught in womenâ€™s figure skating doing it.

Excellence requires focus, determination, a little bit of crazy, at times obsession, and living a mundane lifestyle that many people would find boring.

But excellence also requires that you find deep joy in your craft, that you learn how to have fun while working hard.

What makes for excellenceâ€”and not just in sports, but in anythingâ€”is the combination of intensity and joy. Itâ€™s the latter that makes the former sustainable.

[![](https://nitter.net/pic/media%2FHBjolYDbUAIJFR4.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBjolYDbUAIJFR4.jpg)

21

410

4,618

[![](https://nitter.net/pic/profile_images%2F1982142240571920384%2Fhla62KCQ_bigger.jpg)](https://nitter.net/mervenoyann)

[merve](https://nitter.net/mervenoyann "merve")

[@mervenoyann](https://nitter.net/mervenoyann "@mervenoyann")

[21h](https://nitter.net/mervenoyann/status/2024854687845851195#m "Feb 20, 2026 Â· 2:32 PM UTC")

local AI goes brrr ðŸ’¥

GGML (llama.cpp) is officially part of [@huggingface](https://nitter.net/huggingface "Hugging Face") ðŸš€

[![](https://nitter.net/pic/media%2FHBm6mnbWIAEhQh9.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBm6mnbWIAEhQh9.jpg)

8

10

201

[![](https://nitter.net/pic/profile_images%2F1982142240571920384%2Fhla62KCQ_bigger.jpg)](https://nitter.net/mervenoyann)

[merve](https://nitter.net/mervenoyann "merve")

[@mervenoyann](https://nitter.net/mervenoyann "@mervenoyann")

[21h](https://nitter.net/mervenoyann/status/2024855012019478553#m "Feb 20, 2026 Â· 2:33 PM UTC")

announcement blog [huggingface.co/blog/ggml-joiâ€¦](https://huggingface.co/blog/ggml-joins-hf)

here's a nice write-up by [@ngxson](https://nitter.net/ngxson "Xuan-Son Nguyen") [blog.ngxson.com/ggml-and-llaâ€¦](https://blog.ngxson.com/ggml-and-llama-cpp-join-hugging-face) ðŸ¦™ ðŸ¤—

[![](https://nitter.net/pic/card_img%2F2024854991585071104%2F8_kezYnK%3Fformat%3Dpng%26name%3D800x419)\\
\\
**GGML and llama.cpp join HF to ensure the long-term progress of Local AI** \\
\\
Weâ€™re on a journey to advance and democratize artificial intelligence through open source and open science.\\
\\
huggingface.co](https://huggingface.co/blog/ggml-joins-hf)

4

14

[![](https://nitter.net/pic/profile_images%2F1654097134315098113%2FzCZD0wYz_bigger.jpg)](https://nitter.net/ggerganov)

[Georgi Gerganov](https://nitter.net/ggerganov "Georgi Gerganov")

[@ggerganov](https://nitter.net/ggerganov "@ggerganov")

[22h](https://nitter.net/ggerganov/status/2024839991482777976#m "Feb 20, 2026 Â· 1:34 PM UTC")

Today [ggml.ai](http://ggml.ai/) joins Hugging Face

Together we will continue to build ggml, make llama.cpp more accessible and empower the open-source community. Our joint mission is to make local AI easy and efficient to use by everyone on their own hardware.

![](https://nitter.net/pic/profile_images%2F1654097134315098113%2FzCZD0wYz_mini.jpg)[Georgi Gerganov](https://nitter.net/ggerganov "Georgi Gerganov")

[@ggerganov](https://nitter.net/ggerganov "@ggerganov")

[6 Jun 2023](https://nitter.net/ggerganov/status/1666120568993730561#m "Jun 6, 2023 Â· 4:31 PM UTC")

I've started a company: [ggml.ai](http://ggml.ai/)

From a fun side project just a few months ago, ggml has now become a useful library and framework for machine learning with a great open-source community

126

207

1,344

[![](https://nitter.net/pic/profile_images%2F1993095459338846208%2Fnm8-u0zh_bigger.jpg)](https://nitter.net/AymericRoucher)

[m\_ric](https://nitter.net/AymericRoucher "m_ric")

[@AymericRoucher](https://nitter.net/AymericRoucher "@AymericRoucher")

[22h](https://nitter.net/AymericRoucher/status/2024853636145107087#m "Feb 20, 2026 Â· 2:28 PM UTC")

Wow that's super cool, congrats! ðŸš€

1

[![](https://nitter.net/pic/profile_images%2F1624054272676532224%2FUNv4ONME_bigger.jpg)](https://nitter.net/danielhanchen)

[Daniel Han](https://nitter.net/danielhanchen "Daniel Han")

[@danielhanchen](https://nitter.net/danielhanchen "@danielhanchen")

[22h](https://nitter.net/danielhanchen/status/2024853232493949166#m "Feb 20, 2026 Â· 2:26 PM UTC")

Thanks so much to everyone for sharing your Unsloth models! ðŸ¦¥

There's lots of epic fine-tunes ranging from medical, OCR, multilingual, roleplay, TTS, legal, coding, distills & much more.

![](https://nitter.net/pic/profile_images%2F1790653115441782784%2FVXHiO8LM_mini.jpg)[Unsloth AI](https://nitter.net/UnslothAI "Unsloth AI")

[@UnslothAI](https://nitter.net/UnslothAI "@UnslothAI")

[22h](https://nitter.net/UnslothAI/status/2024847369733325202#m "Feb 20, 2026 Â· 2:03 PM UTC")

100,000+ models trained with Unsloth have now been open-sourced on Hugging Face!

Popular fine-tuned LLMs you can run locally:
1\. TeichAI - GLM-4.7-Flash distilled from Claude 4.5 Opus (high)
2\. Zed - Qwen Coder 7B fine-tuned for stronger coding
3\. DavidAU - Llama-3.3-8B distilled from Claude 4.5 Opus (high)
4\. huihui - gpt-oss made â€œabliberatedâ€

Links to models:
1\. TeichAI: [huggingface.co/TeichAI/GLM-4â€¦](https://huggingface.co/TeichAI/GLM-4.7-Flash-Claude-Opus-4.5-High-Reasoning-Distill-GGUF)
2\. Zed: [huggingface.co/zed-industrieâ€¦](https://huggingface.co/zed-industries/zeta)
3\. DavidAU: [huggingface.co/DavidAU/Llamaâ€¦](https://huggingface.co/DavidAU/Llama3.3-8B-Instruct-Thinking-Claude-4.5-Opus-High-Reasoning)
4\. huihui: [huggingface.co/huihui-ai/Huiâ€¦](https://huggingface.co/huihui-ai/Huihui-gpt-oss-20b-BF16-abliterated)

See all the 100K latest models fine-tuned with Unsloth here: [huggingface.co/models?other=â€¦](https://huggingface.co/models?other=unsloth&sort=created)

[![](https://nitter.net/pic/media%2FHBmw-lGasAAUGCD.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBmw-lGasAAUGCD.jpg)

3

7

72

Sara Hooker retweeted

[![](https://nitter.net/pic/profile_images%2F2024199453717254144%2FJ1kXYgOL_bigger.jpg)](https://nitter.net/hey_shivv)

[Shiv](https://nitter.net/hey_shivv "Shiv")

[@hey\_shivv](https://nitter.net/hey_shivv "@hey_shivv")

[22h](https://nitter.net/hey_shivv/status/2024852958865936596#m "Feb 20, 2026 Â· 2:25 PM UTC")

Replying to [@sarahookr](https://nitter.net/sarahookr) [@ndtv](https://nitter.net/ndtv) [@adaptionlabs](https://nitter.net/adaptionlabs)

Hey [@sarahookr](https://nitter.net/sarahookr "Sara Hooker") , this message of yours has been very helpful and insightful , thanks

Credits: [@OfficialINDIAai](https://nitter.net/OfficialINDIAai "IndiaAI")

![](https://nitter.net/pic/amplify_video_thumb%2F2024852637943017472%2Fimg%2F5zGoNZ0qYyXnVS_m.jpg%3Fname%3Dsmall%26format%3Dwebp)

Enable hls playback

4

22

[![](https://nitter.net/pic/profile_images%2F1778934412404523009%2F4fRabWRC_bigger.png)](https://nitter.net/Muennighoff)

[Niklas Muennighoff](https://nitter.net/Muennighoff "Niklas Muennighoff") [@Muennighoff](https://nitter.net/Muennighoff "@Muennighoff")

[22h](https://nitter.net/Muennighoff/status/2024851690877227303#m "Feb 20, 2026 Â· 2:20 PM UTC")

We released MAEB: Massive Audio Embedding BenchmarkðŸŽµ mteb now covers audio/image/text embedding! See the leaderboard for the top audio embedding modelsðŸ™‚

LB: [hf.co/spaces/mteb/leaderboarâ€¦](https://hf.co/spaces/mteb/leaderboard)
Paper: [hf.co/papers/2602.16008](https://hf.co/papers/2602.16008)

[![](https://nitter.net/pic/media%2FHBmzN4TWEAAJtMi.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBmzN4TWEAAJtMi.jpg)

3

8

41

[![](https://nitter.net/pic/profile_images%2F1778934412404523009%2F4fRabWRC_bigger.png)](https://nitter.net/Muennighoff)

[Niklas Muennighoff](https://nitter.net/Muennighoff "Niklas Muennighoff") [@Muennighoff](https://nitter.net/Muennighoff "@Muennighoff")

[22h](https://nitter.net/Muennighoff/status/2024851693108691295#m "Feb 20, 2026 Â· 2:20 PM UTC")

Congrats to [@Alibaba\_Qwen](https://nitter.net/Alibaba_Qwen "Qwen") [@JustinLin610](https://nitter.net/JustinLin610 "Junyang Lin") & team on being No1 currently ðŸ¥‡!

great aspect was having new researchers for whom this was their first paper; many more papers planned at mteb - feel free to join usðŸ˜Š

[![](https://nitter.net/pic/media%2FHBm1sKrWEAA9KHr.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBm1sKrWEAA9KHr.jpg)

2

3

[![](https://nitter.net/pic/profile_images%2F1778934412404523009%2F4fRabWRC_bigger.png)](https://nitter.net/Muennighoff)

[Niklas Muennighoff](https://nitter.net/Muennighoff "Niklas Muennighoff") [@Muennighoff](https://nitter.net/Muennighoff "@Muennighoff")

[22h](https://nitter.net/Muennighoff/status/2024851695860056435#m "Feb 20, 2026 Â· 2:20 PM UTC")

By [@AdnanElAssadi](https://nitter.net/AdnanElAssadi "Adnan El Assadi") [@isaacchung1217](https://nitter.net/isaacchung1217 "Isaac Chung") [@gowitheflow98](https://nitter.net/gowitheflow98 "Chenghao Xiao") [@risolomatin](https://nitter.net/risolomatin "Roman"), Animesh Jha, Rahul Chand, Silky Singh, [@kkaitlyn111](https://nitter.net/kkaitlyn111 "Kaitlyn Wang"), Ali Sartaz Khan, Marc Moussa Nasser, Sufen Fong, [@hepengfe](https://nitter.net/hepengfe "Pengfei He") Alan Xiao, [@MunotAyush6](https://nitter.net/MunotAyush6 "Ayush Munot"), Aditya Shrivastava, Artem Gazizov, Kenneth Enevoldsen :)

[![](https://nitter.net/pic/profile_images%2F539842407081066497%2F6JaLwehz_bigger.png)](https://nitter.net/sedielem)

[Sander Dieleman](https://nitter.net/sedielem "Sander Dieleman")

[@sedielem](https://nitter.net/sedielem "@sedielem")

[22h](https://nitter.net/sedielem/status/2024851421217149430#m "Feb 20, 2026 Â· 2:19 PM UTC")

Cool finding: temporally autoregressive video diffusion models use lower layers for noise-level-independent causal processing, and upper layers for intra-frame denoising.

Explicitly separating them brings practical and speed benefits! Reminds me of the AlphaFold 3 architectureðŸ¤”

![](https://nitter.net/pic/profile_images%2F1794079843736231936%2FQjKl00u8_mini.jpg)[Xingjian Bai](https://nitter.net/SimulatedAnneal "Xingjian Bai")

[@SimulatedAnneal](https://nitter.net/SimulatedAnneal "@SimulatedAnneal")

[Feb 19](https://nitter.net/SimulatedAnneal/status/2024615127996330474#m "Feb 19, 2026 Â· 10:40 PM UTC")

Do causal video diffusers really need dense causal attention at every layer, every denoising step?

We looked inside and found: no. Causality is separable from denoising.

Here are two surprising observations that hold across architectures, training objectives, and scales.

[![](https://nitter.net/pic/media%2FHBjguoHbsAAUUx2.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBjguoHbsAAUUx2.jpg)

3

8

139

Sara Hooker retweeted

[![](https://nitter.net/pic/profile_images%2F1283293055659974662%2F0hNt4aFh_bigger.jpg)](https://nitter.net/yagyaansh)

[A Pale Blue Dot](https://nitter.net/yagyaansh "A Pale Blue Dot")

[@yagyaansh](https://nitter.net/yagyaansh "@yagyaansh")

[22h](https://nitter.net/yagyaansh/status/2024851048104652966#m "Feb 20, 2026 Â· 2:18 PM UTC")

Replying to [@sarahookr](https://nitter.net/sarahookr)

Some captures from the talk :)

[![](https://nitter.net/pic/media%2FHBm1HD1bgAAZ8--.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBm1HD1bgAAZ8--.jpg)

[![](https://nitter.net/pic/media%2FHBm1HDxbcAAOOfZ.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBm1HDxbcAAOOfZ.jpg)

[![](https://nitter.net/pic/media%2FHBmz3P4aQAACTMR.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBmz3P4aQAACTMR.jpg)

2

4

38

Hamel Husain retweeted

[![](https://nitter.net/pic/profile_images%2F1998877988545273857%2F0sEbeyue_bigger.jpg)](https://nitter.net/egealtan)

[Ege Altan](https://nitter.net/egealtan "Ege Altan")

[@egealtan](https://nitter.net/egealtan "@egealtan")

[22h](https://nitter.net/egealtan/status/2024850362088440042#m "Feb 20, 2026 Â· 2:15 PM UTC")

Data scientists spent the last 3 years watching prompt engineers and vibe coders get the spotlight.

Meanwhile, they quietly mastered the skills that matter most for solving the remaining hard problems in AI: knowing what to measure and why.

That patience is about to pay dividends.

Full post below:

[![](https://nitter.net/pic/media%2FHBm2rD6aQAABSSs.png%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBm2rD6aQAABSSs.png)

2

5

39

apolinario ðŸŒ retweeted

[![](https://nitter.net/pic/profile_images%2F1099983311101984768%2Fp7dZK4S__bigger.jpg)](https://nitter.net/victormustar)

[Victor M](https://nitter.net/victormustar "Victor M")

[@victormustar](https://nitter.net/victormustar "@victormustar")

[22h](https://nitter.net/victormustar/status/2024842175532413016#m "Feb 20, 2026 Â· 1:42 PM UTC")

BREAKING: Llama.cpp joins Hugging Face ðŸ¤¯

[![](https://nitter.net/pic/media%2FHBmu3cnWEAEGPHL.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBmu3cnWEAEGPHL.jpg)

![](https://nitter.net/pic/profile_images%2F1654097134315098113%2FzCZD0wYz_mini.jpg)[Georgi Gerganov](https://nitter.net/ggerganov "Georgi Gerganov")

[@ggerganov](https://nitter.net/ggerganov "@ggerganov")

[22h](https://nitter.net/ggerganov/status/2024839991482777976#m "Feb 20, 2026 Â· 1:34 PM UTC")

Today [ggml.ai](http://ggml.ai/) joins Hugging Face

Together we will continue to build ggml, make llama.cpp more accessible and empower the open-source community. Our joint mission is to make local AI easy and efficient to use by everyone on their own hardware.

13

69

631

[![](https://nitter.net/pic/profile_images%2F1745893660099592193%2FMmYemsw6_bigger.jpg)](https://nitter.net/eliebakouch)

[elie](https://nitter.net/eliebakouch "elie")

[@eliebakouch](https://nitter.net/eliebakouch "@eliebakouch")

[22h](https://nitter.net/eliebakouch/status/2024850183637311627#m "Feb 20, 2026 Â· 2:14 PM UTC")

very big news for open source: ggml (llama.cpp org) joins hugging face!!

[![](https://nitter.net/pic/media%2FHBm2FPJXIAAc5RN.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBm2FPJXIAAc5RN.jpg)

![](https://nitter.net/pic/profile_images%2F1654097134315098113%2FzCZD0wYz_mini.jpg)[Georgi Gerganov](https://nitter.net/ggerganov "Georgi Gerganov")

[@ggerganov](https://nitter.net/ggerganov "@ggerganov")

[22h](https://nitter.net/ggerganov/status/2024839991482777976#m "Feb 20, 2026 Â· 1:34 PM UTC")

Today [ggml.ai](http://ggml.ai/) joins Hugging Face

Together we will continue to build ggml, make llama.cpp more accessible and empower the open-source community. Our joint mission is to make local AI easy and efficient to use by everyone on their own hardware.

10

78

[![](https://nitter.net/pic/profile_images%2F1673691034189025280%2Fs_NrYdYh_bigger.jpg)](https://nitter.net/scottastevenson)

[Scott Stevenson](https://nitter.net/scottastevenson "Scott Stevenson")

[@scottastevenson](https://nitter.net/scottastevenson "@scottastevenson")

[22h](https://nitter.net/scottastevenson/status/2024850105778532493#m "Feb 20, 2026 Â· 2:14 PM UTC")

So many things that used to be a 5 minute phone call are now a 30 minute zoom call. This will devour your time if you're not careful.

13

1

57

DAIR.AI retweeted

[![](https://nitter.net/pic/profile_images%2F939313677647282181%2FvZjFWtAn_bigger.jpg)](https://nitter.net/omarsar0)

[elvis](https://nitter.net/omarsar0 "elvis")

[@omarsar0](https://nitter.net/omarsar0 "@omarsar0")

[Feb 19](https://nitter.net/omarsar0/status/2024587792127340731#m "Feb 19, 2026 Â· 8:51 PM UTC")

If you are building with agents like Claude Code & Codex, you regularly hit context window limits.

It also happens a lot when building long-running or proactive agents.

This is a great article showing tips on how to best leverage prompt caching.

![](https://nitter.net/pic/profile_images%2F1976939058741039104%2Fr3GgzqRh_mini.jpg)[Thariq](https://nitter.net/trq212 "Thariq")

[@trq212](https://nitter.net/trq212 "@trq212")

[Feb 19](https://nitter.net/trq212/status/2024574133011673516#m "Feb 19, 2026 Â· 7:57 PM UTC")

[x.com/i/article/202454349206â€¦](http://x.com/i/article/2024543492064882688)

12

21

280

Cohere retweeted

[![](https://nitter.net/pic/profile_images%2F1801008130312036352%2FQ57iJ8T0_bigger.png)](https://nitter.net/BetaKit)

[BetaKit](https://nitter.net/BetaKit "BetaKit")

[@BetaKit](https://nitter.net/BetaKit "@BetaKit")

[22h](https://nitter.net/BetaKit/status/2024847958932385931#m "Feb 20, 2026 Â· 2:05 PM UTC")

. [@nickfrosst](https://nitter.net/nickfrosst "Nick Frosst") wants a global tech ecosystem that's not defined by Silicon Valley. He thinks [@cohere](https://nitter.net/cohere "Cohere") can play a role in changing the global view of [#AI](https://nitter.net/search?f=tweets&q=%23AI), but that doesn't mean chasing a "digital god."

[betakit.com/cohere-co-foundeâ€¦](https://betakit.com/cohere-co-founder-nick-frosst-wants-to-build-more-canadian-less-silicon-valley-centric-ai/)

[![](https://nitter.net/pic/card_img%2F2024605286368169984%2FJqSMLuA3%3Fformat%3Djpg%26name%3D800x419)\\
\\
**Cohere co-founder Nick Frosst wants to build more Canadian, less Silicon Valley-centric AI \| BetaKit** \\
\\
Frosst talked efficiency, AGI, and his band Good Kid at AI conference and recent media dinner.\\
\\
betakit.com](https://betakit.com/cohere-co-founder-nick-frosst-wants-to-build-more-canadian-less-silicon-valley-centric-ai/)

2

5

15

[![](https://nitter.net/pic/profile_images%2F1692481211888025600%2FlUJUEO_p_bigger.jpg)](https://nitter.net/dejavucoder)

[sankalp](https://nitter.net/dejavucoder "sankalp")

[@dejavucoder](https://nitter.net/dejavucoder "@dejavucoder")

[Feb 20](https://nitter.net/dejavucoder/status/2024749289441022321#m "Feb 20, 2026 Â· 7:33 AM UTC")

everyone is sandbox maxxing

![](https://nitter.net/pic/profile_images%2F1970182748146180096%2FdhZeXi_X_mini.jpg)[Cursor](https://nitter.net/cursor_ai "Cursor")

[@cursor\_ai](https://nitter.net/cursor_ai "@cursor_ai")

[Feb 19](https://nitter.net/cursor_ai/status/2024544628687687879#m "Feb 19, 2026 Â· 6:00 PM UTC")

Over the last three months, we've rolled out agent sandboxing on macOS, Linux, and Windows.

Sandboxes allow agents to run freely and securely, only requesting approval when they need to step outside it.

Here's how we built it: [cursor.com/blog/agent-sandboâ€¦](http://cursor.com/blog/agent-sandboxing)

6

1

155

[![](https://nitter.net/pic/profile_images%2F1692481211888025600%2FlUJUEO_p_bigger.jpg)](https://nitter.net/dejavucoder)

[sankalp](https://nitter.net/dejavucoder "sankalp")

[@dejavucoder](https://nitter.net/dejavucoder "@dejavucoder")

[22h](https://nitter.net/dejavucoder/status/2024847577712365864#m "Feb 20, 2026 Â· 2:04 PM UTC")

also like i keep saying sandbox sandbox - its because they have started coming in usage for consumers like us

but labs have been using cloud sandbox environments for rl rollouts since llm rl got popular

1

2

[![](https://nitter.net/pic/profile_images%2F1692481211888025600%2FlUJUEO_p_bigger.jpg)](https://nitter.net/dejavucoder)

[sankalp](https://nitter.net/dejavucoder "sankalp")

[@dejavucoder](https://nitter.net/dejavucoder "@dejavucoder")

[22h](https://nitter.net/dejavucoder/status/2024847830029144402#m "Feb 20, 2026 Â· 2:05 PM UTC")

if you wanna get a gist, check out [@srush\_nlp](https://nitter.net/srush_nlp "Sasha Rush") talk

![](https://nitter.net/pic/profile_images%2F1692481211888025600%2FlUJUEO_p_mini.jpg)[sankalp](https://nitter.net/dejavucoder "sankalp")

[@dejavucoder](https://nitter.net/dejavucoder "@dejavucoder")

[15 Nov 2025](https://nitter.net/dejavucoder/status/1989708723447894396#m "Nov 15, 2025 Â· 2:55 PM UTC")

some points from the talk
\- for the agent RL, the RL rollouts try to mimic how cursor works in production at scale including cursor as environment
\- try to keep training/inference similar so they use same tool call formats in prod

infra architecture
\- trainer server (pytorch stack scaled), inference server (ray orchestrates RL rollouts), environment server (micro VMs to rollout 100k+ mini cursors, this coincides with the infra they use for cursor cloud agents)

\- MXFP8: composer trainer has custom kernels for low-precision training; they don't need to do post-training quantisation

\- inference server runs the rollouts, calls tool calls. different rollouts may come back at different times, uses ray (single controller interface idk what it is) to load balance across diff threads/processes

\- composer likes parallel tool calls and semantic search

[![](https://nitter.net/pic/media%2FG5zZq2XbkAEIFSc.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FG5zZq2XbkAEIFSc.jpg)

[![](https://nitter.net/pic/media%2FG5zay1nbkAEjDOc.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FG5zay1nbkAEjDOc.jpg)

[![](https://nitter.net/pic/media%2FG5zblZ3awAAU5BU.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FG5zblZ3awAAU5BU.jpg)

[![](https://nitter.net/pic/media%2FG5zb3oSbAAAqB5f.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FG5zb3oSbAAAqB5f.jpg)

[![](https://nitter.net/pic/profile_images%2F1643277398522187778%2F31dedbLo_bigger.jpg)](https://nitter.net/dair_ai)

[DAIR.AI](https://nitter.net/dair_ai "DAIR.AI")

[@dair\_ai](https://nitter.net/dair_ai "@dair_ai")

[22h](https://nitter.net/dair_ai/status/2024847774379114632#m "Feb 20, 2026 Â· 2:05 PM UTC")

Interesting new work on dynamic multi-agent systems.

Traditional multi-agent RL assumes a fixed number of agents.

But real-world scenarios often involve populations that grow, split, or shrink dynamically, such as cell division, team expansion, or organizational scaling.

Fluid-Agent RL introduces a framework where agents can dynamically create other agents during an episode. The population isn't fixed. The researchers develop game-theoretic solution concepts for these fluid-agent games and validate the approach on fluid variants of Predator-Prey and Level-Based Foraging.

Why does it matter? This enables solution strategies that are simply unavailable in fixed-population settings. Agent teams can adjust their size to match environmental demands.

Paper: [arxiv.org/abs/2602.14559](https://arxiv.org/abs/2602.14559)

Learn to build effective AI agents in our academy: [academy.dair.ai/](https://academy.dair.ai/)

[![](https://nitter.net/pic/media%2FHBm0UcWagAA-a2j.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBm0UcWagAA-a2j.jpg)

5

19

117

[![](https://nitter.net/pic/profile_images%2F1944810713630830592%2FEp6nI7ky_bigger.jpg)](https://nitter.net/qdrant_engine)

[Qdrant](https://nitter.net/qdrant_engine "Qdrant")

[@qdrant\_engine](https://nitter.net/qdrant_engine "@qdrant_engine")

[22h](https://nitter.net/qdrant_engine/status/2024847597748273196#m "Feb 20, 2026 Â· 2:04 PM UTC")

ðƒð¢ð¬ðœð¨ð«ð ð’ðžð¬ð¬ð¢ð¨ð§: ðŒð¢ð ð«ðšð­ð¢ð§ð  ð­ð¨ ððð«ðšð§ð­ ð„ðð ðž ðŸð¨ð« ðŽð§-ðƒð¢ð¬ð¤ ð•ðžðœð­ð¨ð« ð’ð­ð¨ð«ðšð ðž ð¢ð§ ð‘ð®ð¬ð­

Weâ€™re excited to host [@itsclelia](https://nitter.net/itsclelia "Clelia Bertelli (ðŸ¦™/acc)") from [@llama\_index](https://nitter.net/llama_index "LlamaIndex ðŸ¦™") for a deep-dive session on:
â€œMigrating to Qdrant Edge for On-Disk Vector Storage in Rust.â€

If youâ€™re building AI systems in Rust or working with production-grade vector search, this session is for you.
ðŸ—“ February 27th
â° 4:00 PM CET / 7:00 AM PT / 8:30 PM IST
ðŸ“ Happening live on the Qdrant Discord server

ðŸ‘‰ Join us here: [discord.gg/PcgpnXa2?event=14â€¦](https://discord.gg/PcgpnXa2?event=1473577301470875820)

Clelia will cover:
\- Why and when to migrate to Qdrant Edge
\- Trade-offs of on-disk vector storage
\- Performance considerations in Rust-based systems
\- Wins, pitfalls, and lessons learned

If youâ€™re optimizing for edge deployments, reducing memory footprint, or scaling vector workloads efficiently - youâ€™ll walk away with practical insights.

Bring your questions - see you there!

[#Qdrant](https://nitter.net/search?f=tweets&q=%23Qdrant) [#LlamaIndex](https://nitter.net/search?f=tweets&q=%23LlamaIndex) [#VectorSearch](https://nitter.net/search?f=tweets&q=%23VectorSearch) [#Rust](https://nitter.net/search?f=tweets&q=%23Rust) [#EdgeAI](https://nitter.net/search?f=tweets&q=%23EdgeAI) [#OnDiskStorage](https://nitter.net/search?f=tweets&q=%23OnDiskStorage) [#RAG](https://nitter.net/search?f=tweets&q=%23RAG) [#GenAI](https://nitter.net/search?f=tweets&q=%23GenAI) [#AIEngineering](https://nitter.net/search?f=tweets&q=%23AIEngineering) [#VectorSearch](https://nitter.net/search?f=tweets&q=%23VectorSearch)

[![](https://nitter.net/pic/media%2FHBmz9DJasAAF89P.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBmz9DJasAAF89P.jpg)

1

1

5

Kevin Weil ðŸ‡ºðŸ‡¸ retweeted

[![](https://nitter.net/pic/profile_images%2F1949642818714050560%2F4SNDhOoD_bigger.jpg)](https://nitter.net/nasqret)

[Bartosz NaskrÄ™cki](https://nitter.net/nasqret "Bartosz NaskrÄ™cki")

[@nasqret](https://nitter.net/nasqret "@nasqret")

[Feb 20](https://nitter.net/nasqret/status/2024650108814401884#m "Feb 20, 2026 Â· 12:59 AM UTC")

Since yesterday, I have been working with my collaborator Piotr Pokora on a problem related to log surfaces. We were trying to figure out how to search the combinatorial space of possible configurations of lines on a smooth quartic in order to maximize the so-called Chern slope. In terms of numerics, we have done many examples, and the famous Fermat quartic x^4 + y^4 + z^4 + w^4 = 0 is currently the record holder for the slope (= 8/3) for a particular configuration of 16 lines (see our paper). This was the expected maximum, which we have been trying to beat or prove for the last two years. Today I ran the problem with the top version of GPT Pro using a hefty prompt that included many details about the problem and the full text of our paper.

I received a very interesting insight: to use mixed linear programming. This approach beats brute force techniques, including simulated annealing, by far. We had not seen it ourselves, yet the model found this insight and explained how to write efficient code using SciPy.

I now realize that there are three of us in the office: two humans and one agentic system with skills and substantial computational power. Skills are becoming increasingly important, and this agentic harness produces amazing results. I feel that I have completely shifted my perspective. I still like collaborating with humans, but I delegate deep searches, bold ideation, and extensive exploration to the models. It is simply faster and more efficient. And the progress is real. We now have a concrete path forward.

[![](https://nitter.net/pic/media%2FHBkAUm8XYAAL2Af.png%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBkAUm8XYAAL2Af.png)

[![](https://nitter.net/pic/media%2FHBkAUm7WMAAxcbL.png%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBkAUm7WMAAxcbL.png)

[![](https://nitter.net/pic/media%2FHBkAWy3WoAE5klk.png%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBkAWy3WoAE5klk.png)

8

16

130

[![](https://nitter.net/pic/profile_images%2F939313677647282181%2FvZjFWtAn_bigger.jpg)](https://nitter.net/omarsar0)

[elvis](https://nitter.net/omarsar0 "elvis")

[@omarsar0](https://nitter.net/omarsar0 "@omarsar0")

[22h](https://nitter.net/omarsar0/status/2024847274157945035#m "Feb 20, 2026 Â· 2:03 PM UTC")

Orchestration design is now a first-class optimization target, independent of model scaling.

As LLMs from different providers converge toward comparable benchmark performance, picking the best model yields diminishing returns.

The real lever is orchestration topology, where you strategize how multiple agents are coordinated, parallelized, and synthesized.

This paper introduces a framework for task-adaptive multi-agent orchestration that dynamically selects among four canonical topologies (parallel, sequential, hierarchical, and hybrid) based on task dependency graphs.

It formalizes a Performance Convergence Scaling Law showing when orchestration selection outweighs model selection, and includes a Topology Routing Algorithm that maps tasks to optimal patterns in O(\|V\| + \|E\|) time.

Results: 12-23% improvement over static single-topology baselines, even when using identical underlying models.

Paper: [arxiv.org/abs/2602.16873](https://arxiv.org/abs/2602.16873)

Learn to build effective AI agents in our academy: [academy.dair.ai/](https://academy.dair.ai/)

[![](https://nitter.net/pic/media%2FHBmz3WoacAE3qq5.png%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBmz3WoacAE3qq5.png)

17

28

173

[![](https://nitter.net/pic/profile_images%2F1745893660099592193%2FMmYemsw6_bigger.jpg)](https://nitter.net/eliebakouch)

[elie](https://nitter.net/eliebakouch "elie")

[@eliebakouch](https://nitter.net/eliebakouch "@eliebakouch")

[Feb 20](https://nitter.net/eliebakouch/status/2024804106615894347#m "Feb 20, 2026 Â· 11:11 AM UTC")

is there a good way to start a new thread from an existing conversation in claude code or codex?

in claude code, I often use --resume --fork-session, but this feels like bad UX. I wish I could start multiple new threads inside my main "branch" (i.e., the main conversation) at different points and then merge back the results if needed

3

11

[more replies](https://nitter.net/eliebakouch/status/2024833659258191985#m)

[![](https://nitter.net/pic/profile_images%2F1745893660099592193%2FMmYemsw6_bigger.jpg)](https://nitter.net/eliebakouch)

[elie](https://nitter.net/eliebakouch "elie")

[@eliebakouch](https://nitter.net/eliebakouch "@eliebakouch")

[23h](https://nitter.net/eliebakouch/status/2024833659258191985#m "Feb 20, 2026 Â· 1:08 PM UTC")

but then i don't have my main thread anymore :(

1

1

[![](https://nitter.net/pic/profile_images%2F1692481211888025600%2FlUJUEO_p_bigger.jpg)](https://nitter.net/dejavucoder)

[sankalp](https://nitter.net/dejavucoder "sankalp")

[@dejavucoder](https://nitter.net/dejavucoder "@dejavucoder")

[22h](https://nitter.net/dejavucoder/status/2024846044811723197#m "Feb 20, 2026 Â· 1:58 PM UTC")

makes sense, i didnt get your problem initially

2

[![](https://nitter.net/pic/profile_images%2F1692481211888025600%2FlUJUEO_p_bigger.jpg)](https://nitter.net/dejavucoder)

[sankalp](https://nitter.net/dejavucoder "sankalp")

[@dejavucoder](https://nitter.net/dejavucoder "@dejavucoder")

[22h](https://nitter.net/dejavucoder/status/2024844058548670568#m "Feb 20, 2026 Â· 1:50 PM UTC")

as much shipping is fun, it can get tiring af. pushing the bar with coding agents really needs one to think more intensely, make many micro-decisions in short bursts (few hours), context switch(multiple experiments), zoom in/out (what to do next lmao) perspectives (ux design)

6

2

60

[![](https://nitter.net/pic/profile_images%2F1403376500192071683%2Fzvr_Hkox_bigger.jpg)](https://nitter.net/sarahookr)

[Sara Hooker](https://nitter.net/sarahookr "Sara Hooker")

[@sarahookr](https://nitter.net/sarahookr "@sarahookr")

[22h](https://nitter.net/sarahookr/status/2024842688881930409#m "Feb 20, 2026 Â· 1:44 PM UTC")

Honored to have been on [@ndtv](https://nitter.net/ndtv "NDTV") live today talking about [@adaptionlabs](https://nitter.net/adaptionlabs "adaption").

It has been an incredible summit, most change requires talent density and ambition in the same place. This summit had both.

Many reasons to return to India, truly my first visit was very special.

22

41

571

[![](https://nitter.net/pic/profile_images%2F1403376500192071683%2Fzvr_Hkox_bigger.jpg)](https://nitter.net/sarahookr)

[Sara Hooker](https://nitter.net/sarahookr "Sara Hooker")

[@sarahookr](https://nitter.net/sarahookr "@sarahookr")

[22h](https://nitter.net/sarahookr/status/2024843718193557634#m "Feb 20, 2026 Â· 1:48 PM UTC")

And yes, I was asked about being stuck in Delhi traffic + missing my invitation to the gala with Prime Minister Modi. ðŸ˜‚

One of the reasons to return is to look forward to future galas and culinary adventures across Delhi. ðŸ”¥

8

2

90

[![](https://nitter.net/pic/profile_images%2F1692481211888025600%2FlUJUEO_p_bigger.jpg)](https://nitter.net/dejavucoder)

[sankalp](https://nitter.net/dejavucoder "sankalp")

[@dejavucoder](https://nitter.net/dejavucoder "@dejavucoder")

[22h](https://nitter.net/dejavucoder/status/2024842443242553743#m "Feb 20, 2026 Â· 1:43 PM UTC")

you don't have to be an expert at something to post about it. infact posts that are made in process of learning hit harder on the timeline. they just feel more visceral and they can help ppl who are n-1, n+1 steps range of you. a lot of my posts come out of me learning things and just talking about stuff i find interesting. its the adult version of me telling my mom things that happened in school. let the inner child talk anon.

5

4

97

[![](https://nitter.net/pic/profile_images%2F1745893660099592193%2FMmYemsw6_bigger.jpg)](https://nitter.net/eliebakouch)

[elie](https://nitter.net/eliebakouch "elie")

[@eliebakouch](https://nitter.net/eliebakouch "@eliebakouch")

[23h](https://nitter.net/eliebakouch/status/2024834429529530478#m "Feb 20, 2026 Â· 1:12 PM UTC")

ðŸ‘€

![](https://nitter.net/pic/profile_images%2F1108502565925326850%2FzPsBf2BI_mini.png)[Julien Chaumond](https://nitter.net/julien_c "Julien Chaumond")

[@julien\_c](https://nitter.net/julien_c "@julien_c")

[Feb 20](https://nitter.net/julien_c/status/2024820492008325235#m "Feb 20, 2026 Â· 12:16 PM UTC")

Any big announcements expected today?!

5

72

[![](https://nitter.net/pic/profile_images%2F1745893660099592193%2FMmYemsw6_bigger.jpg)](https://nitter.net/eliebakouch)

[elie](https://nitter.net/eliebakouch "elie")

[@eliebakouch](https://nitter.net/eliebakouch "@eliebakouch")

[22h](https://nitter.net/eliebakouch/status/2024842416407101474#m "Feb 20, 2026 Â· 1:43 PM UTC")

![](https://nitter.net/pic/profile_images%2F1654097134315098113%2FzCZD0wYz_mini.jpg)[Georgi Gerganov](https://nitter.net/ggerganov "Georgi Gerganov")

[@ggerganov](https://nitter.net/ggerganov "@ggerganov")

[22h](https://nitter.net/ggerganov/status/2024839991482777976#m "Feb 20, 2026 Â· 1:34 PM UTC")

Today [ggml.ai](http://ggml.ai/) joins Hugging Face

Together we will continue to build ggml, make llama.cpp more accessible and empower the open-source community. Our joint mission is to make local AI easy and efficient to use by everyone on their own hardware.

1

16

Omar Khattab retweeted

[![](https://nitter.net/pic/profile_images%2F1783145504890650624%2FSoRkDHKa_bigger.jpg)](https://nitter.net/mstockton)

[Matt Stockton](https://nitter.net/mstockton "Matt Stockton")

[@mstockton](https://nitter.net/mstockton "@mstockton")

[Feb 20](https://nitter.net/mstockton/status/2024707187931517145#m "Feb 20, 2026 Â· 4:46 AM UTC")

DSPy is the right answer and itâ€™s still immensely underrated - I am still struggling to see why this hasnâ€™t caught on more amongst experienced â€˜classicalâ€™ software engineers

![](https://nitter.net/pic/profile_images%2F1867875781676007424%2FRIF4Kt7U_mini.jpg)[swyx](https://nitter.net/swyx "swyx")

[@swyx](https://nitter.net/swyx "@swyx")

[Feb 19](https://nitter.net/swyx/status/2024631884693827648#m "Feb 19, 2026 Â· 11:47 PM UTC")

Replying to [@fchollet](https://nitter.net/fchollet)

\> what will be the Keras of agentic coding?

i mean at this point the community default answer/presumptive winner is [@DSPyOSS](https://nitter.net/DSPyOSS "DSPy") no?

(if no, your thoughts / criticisms would be very helpful given your experience!!)

3

4

44

[![](https://nitter.net/pic/profile_images%2F1606206113245904897%2FN6RH65PF_bigger.jpg)](https://nitter.net/LearnOpenCV)

[Satya Mallick](https://nitter.net/LearnOpenCV "Satya Mallick")

[@LearnOpenCV](https://nitter.net/LearnOpenCV "@LearnOpenCV")

[23h](https://nitter.net/LearnOpenCV/status/2024839237078569153#m "Feb 20, 2026 Â· 1:31 PM UTC")

Over time, this pattern can create dependence that is difficult to recognize or break.

![](https://nitter.net/pic/amplify_video_thumb%2F2024839199753453568%2Fimg%2FtGBRAc_B3nEPTmwc.jpg%3Fname%3Dsmall%26format%3Dwebp)

Enable hls playback

2

[![](https://nitter.net/pic/profile_images%2F1909353910130950147%2FEeSGdgA5_bigger.jpg)](https://nitter.net/theo)

[Theo - t3.gg](https://nitter.net/theo "Theo - t3.gg")

[@theo](https://nitter.net/theo "@theo")

[23h](https://nitter.net/theo/status/2024839053900910612#m "Feb 20, 2026 Â· 1:30 PM UTC")

Cursor's biggest underrated advantage is that they've somehow tamed Gemini. It's the only harness that actually keeps Google models productive and on task.

88

19

1,329

Sara Hooker retweeted

[![](https://nitter.net/pic/profile_images%2F884996480347635712%2FAHrhZgKZ_bigger.jpg)](https://nitter.net/sandeepssrin)

[Sandeep Srinivasa](https://nitter.net/sandeepssrin "Sandeep Srinivasa")

[@sandeepssrin](https://nitter.net/sandeepssrin "@sandeepssrin")

[23h](https://nitter.net/sandeepssrin/status/2024838553910567245#m "Feb 20, 2026 Â· 1:28 PM UTC")

[@sarahookr](https://nitter.net/sarahookr "Sara Hooker") had some mind blowing stats.

The performance of models under 13B has been following a J-curve.

I had no idea !

[![](https://nitter.net/pic/media%2FHBmr6XaaUAA47hD.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBmr6XaaUAA47hD.jpg)

2

8

99

Yann LeCun retweeted

[![](https://nitter.net/pic/profile_images%2F2022856156612562946%2FqgKIw83__bigger.jpg)](https://nitter.net/allenanalysis)

[Brian Allen](https://nitter.net/allenanalysis "Brian Allen")

[@allenanalysis](https://nitter.net/allenanalysis "@allenanalysis")

[Feb 19](https://nitter.net/allenanalysis/status/2024567903333261450#m "Feb 19, 2026 Â· 7:32 PM UTC")

ðŸš¨ BREAKING: Trump just announced the U.S. will send $10 BILLION to his so-called â€œBoard of Peace.â€

An offshore entity he controls. Where heâ€™s chairman for life.

Thatâ€™s taxpayer money â†’ straight into Trumpâ€™s personal power structure.

Heâ€™s robbing America in real time.

![](https://nitter.net/pic/amplify_video_thumb%2F2024567833875636224%2Fimg%2FVGc2NcmzgXm_hb4Y.jpg%3Fname%3Dsmall%26format%3Dwebp)

Enable hls playback

3,686

18,168

81,807

[![](https://nitter.net/pic/profile_images%2F1606206113245904897%2FN6RH65PF_bigger.jpg)](https://nitter.net/LearnOpenCV)

[Satya Mallick](https://nitter.net/LearnOpenCV "Satya Mallick")

[@LearnOpenCV](https://nitter.net/LearnOpenCV "@LearnOpenCV")

[23h](https://nitter.net/LearnOpenCV/status/2024837544408437158#m "Feb 20, 2026 Â· 1:24 PM UTC")

Counterfeiters, beware!

AI isnâ€™t guessing-itâ€™s inspecting. ðŸ”
From leather grain to stitching, from logo alignment to hardware details, AI spots the tiny flaws humans miss.

Trained on real vs. fake, it can expose counterfeits in secondsâ€”at scale.
Fabric. Patterns. Hardware.

Every detail tells the truth.
And AI is already watching. ðŸ‘€

[#AI](https://nitter.net/search?f=tweets&q=%23AI) [#CounterfeitDetection](https://nitter.net/search?f=tweets&q=%23CounterfeitDetection) [#LuxuryGoods](https://nitter.net/search?f=tweets&q=%23LuxuryGoods) [#ComputerVision](https://nitter.net/search?f=tweets&q=%23ComputerVision) [#TechInnovation](https://nitter.net/search?f=tweets&q=%23TechInnovation) [#FutureOfAI](https://nitter.net/search?f=tweets&q=%23FutureOfAI) [#BrandProtectio](https://nitter.net/search?f=tweets&q=%23BrandProtectio)

![](https://nitter.net/pic/amplify_video_thumb%2F2024837448245600256%2Fimg%2FP26xjYOl7y_RfRpp.jpg%3Fname%3Dsmall%26format%3Dwebp)

Enable hls playback

Andreas Kirsch ðŸ‡ºðŸ‡¦ retweeted

[![](https://nitter.net/pic/profile_images%2F1765378013095419904%2FZ_Ukpy7q_bigger.jpg)](https://nitter.net/ShakeelHashim)

[Shakeel](https://nitter.net/ShakeelHashim "Shakeel")

[@ShakeelHashim](https://nitter.net/ShakeelHashim "@ShakeelHashim")

[Feb 20](https://nitter.net/ShakeelHashim/status/2024659531075342571#m "Feb 20, 2026 Â· 1:37 AM UTC")

It seems extremely underdiscussed that OpenAI and Google DeepMind have "agreed in principle" to having their models used by the Pentagon for domestic surveillance.

[![](https://nitter.net/pic/media%2FHBkJCMkbUAEo3Ya.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBkJCMkbUAEo3Ya.jpg)

4

21

99

Yann LeCun retweeted

[![](https://nitter.net/pic/profile_images%2F1994312429157928961%2FvKCxw-08_bigger.jpg)](https://nitter.net/rajatsandeepsen)

[Rajat](https://nitter.net/rajatsandeepsen "Rajat")

[@rajatsandeepsen](https://nitter.net/rajatsandeepsen "@rajatsandeepsen")

[Feb 18](https://nitter.net/rajatsandeepsen/status/2024169052562931894#m "Feb 18, 2026 Â· 5:08 PM UTC")

Dr. [@ylecun](https://nitter.net/ylecun "Yann LeCun") traveled all the way to India just to say "fuck the LLMs" ðŸ˜­

[![](https://nitter.net/pic/media%2FHBdK4q9bUAEARTe.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBdK4q9bUAEARTe.jpg)

123

396

5,750

[![](https://nitter.net/pic/profile_images%2F1760005111055777792%2FNmshY7lw_bigger.jpg)](https://nitter.net/nrehiew_)

[wh](https://nitter.net/nrehiew_ "wh")

[@nrehiew\_](https://nitter.net/nrehiew_ "@nrehiew_")

[23h](https://nitter.net/nrehiew_/status/2024835776048169266#m "Feb 20, 2026 Â· 1:17 PM UTC")

My favourite part of the entire GLM 5 paper. Its easy to forget the team and people behind every new model release

[![](https://nitter.net/pic/media%2FHBmpSqkb0AAMWBD.png%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBmpSqkb0AAMWBD.png)

![](https://nitter.net/pic/profile_images%2F1760005111055777792%2FNmshY7lw_mini.jpg)[wh](https://nitter.net/nrehiew_ "wh")

[@nrehiew\_](https://nitter.net/nrehiew_ "@nrehiew_")

[Feb 19](https://nitter.net/nrehiew_/status/2024491384531800343#m "Feb 19, 2026 Â· 2:28 PM UTC")

Notes on GLM 5. The latest/best (?) frontier model to come out of China.

Really cool tech report

[![](https://nitter.net/pic/media%2FHBhc_7vbUAgPmG_.png%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBhc_7vbUAgPmG_.png)

2

7

116

Kevin Fischer retweeted

[![](https://nitter.net/pic/profile_images%2F1982070651423694848%2F0vUKWPER_bigger.jpg)](https://nitter.net/paraschopra)

[Paras Chopra](https://nitter.net/paraschopra "Paras Chopra")

[@paraschopra](https://nitter.net/paraschopra "@paraschopra")

[Feb 20](https://nitter.net/paraschopra/status/2024686487795880013#m "Feb 20, 2026 Â· 3:24 AM UTC")

This [#book](https://nitter.net/search?f=tweets&q=%23book) makes a convincing case that consciousness arose during the Cambrian explosion 550 million years ago when prey-predator dynamics kickstarted an arms race to better represent the environment in order to outsmart the other.

The book is full of detailed figures of how brains of fishes, birds, slugs and mammals integrate information from different senses. I loved seeing all of them!

I am 100% aligned with the authors that the phenomenal consciousness has to be evolutionarily adaptive, and agree that itâ€™s widespread among life. This should motivate our moral consideration towards animals.

But Iâ€™m not sure if we can reject certain systems NOT having consciousness because they donâ€™t have â€œbrainsâ€. Say, a single celled organism? Perhaps they have a different kind of experience (as compared to our unified one). Even a single cell is so richly complicated that we should reserve our judgement on whether they have subjective experiences until we have better theories or consciousness validated.

Similarly, I wasnâ€™t expecting the treatment of the â€œhardâ€ problem but the book just handwaves the explanation of why red feels like red and not something else. Although it made sense that qualia is required for discriminating stimulus.

Overall, the book is a fantastic gateway to understanding how brains of diverse creatures might be feeling from the inside.

As an example, I learned that even through Mantis Shrimp have 13 photoreceptors (vs 3 that we have), they have poorer color discrimination because their brains donâ€™t integrate information from different photoreceptors. So their world must be 13 different colored bins instead of the smooth circular color map we feel!

[![](https://nitter.net/pic/media%2FHBkhntRbUAAoLQ1.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBkhntRbUAAoLQ1.jpg)

68

259

2,040

[![](https://nitter.net/pic/profile_images%2F1606206113245904897%2FN6RH65PF_bigger.jpg)](https://nitter.net/LearnOpenCV)

[Satya Mallick](https://nitter.net/LearnOpenCV "Satya Mallick")

[@LearnOpenCV](https://nitter.net/LearnOpenCV "@LearnOpenCV")

[23h](https://nitter.net/LearnOpenCV/status/2024832924617740724#m "Feb 20, 2026 Â· 1:06 PM UTC")

This Trick Makes LLMs 2X Faster

Autoregressive decoding has a hard ceiling-one token at a time. Speculative Decoding uses a "draft" model to jump ahead without losing quality.

[#Innovation](https://nitter.net/search?f=tweets&q=%23Innovation) [#AI](https://nitter.net/search?f=tweets&q=%23AI) [#FutureTech](https://nitter.net/search?f=tweets&q=%23FutureTech) [#Python](https://nitter.net/search?f=tweets&q=%23Python)

![](https://nitter.net/pic/amplify_video_thumb%2F2024832749400715264%2Fimg%2F-2uwUPMe-YMp5y-O.jpg%3Fname%3Dsmall%26format%3Dwebp)

Enable hls playback

1

Yann LeCun retweeted

[![](https://nitter.net/pic/profile_images%2F1700879782504722432%2FxNu3zdGs_bigger.jpg)](https://nitter.net/MarcoFoster_)

[Marco Foster](https://nitter.net/MarcoFoster_ "Marco Foster")

[@MarcoFoster\_](https://nitter.net/MarcoFoster_ "@MarcoFoster_")

[Feb 19](https://nitter.net/MarcoFoster_/status/2024490001422262410#m "Feb 19, 2026 Â· 2:23 PM UTC")

Lawrence Oâ€™Donnell quotes the scathing takedown of Trump in the NY Daily News: â€œIt is time to acknowledge what has become tragically obvious: the Trump administration is operating as a massive criminal enterprise. It lies, steals, extorts, and murders â€” all while cloaked in the awesome authority of the state. It is on a crime spree that puts Al Capone to shame.â€

![](https://nitter.net/pic/amplify_video_thumb%2F2024489465683869696%2Fimg%2FOHT_mQEfox3akyac.jpg%3Fname%3Dsmall%26format%3Dwebp)

Enable hls playback

757

13,579

33,267

[![](https://nitter.net/pic/profile_images%2F1831493788679761920%2F-q9w6dzd_bigger.jpg)](https://nitter.net/scaling01)

[Lisan al Gaib](https://nitter.net/scaling01 "Lisan al Gaib")

[@scaling01](https://nitter.net/scaling01 "@scaling01")

[23h](https://nitter.net/scaling01/status/2024832543141302550#m "Feb 20, 2026 Â· 1:04 PM UTC")

Results for Gemini 3.1 Pro are extremely bipolar lol

20

2

185

Lisan al Gaib retweeted

[![](https://nitter.net/pic/abs.twimg.com%2Fsticky%2Fdefault_profile_images%2Fdefault_profile_bigger.png)](https://nitter.net/Hangsiin)

[NomoreID](https://nitter.net/Hangsiin "NomoreID")

[@Hangsiin](https://nitter.net/Hangsiin "@Hangsiin")

[Feb 19](https://nitter.net/Hangsiin/status/2024605310913216614#m "Feb 19, 2026 Â· 10:01 PM UTC")

Update regarding Gemini 3.1 Pro:

-Ranked #1 among all Gemini models released to date.
-Ranked #1 among all models I have tested so far. (GPT-5.2 high 165.9 vs Gemini 3.1 Pro 166.6)

However, please note that my testing has limitations due to budget constraints:

-I have not tested the very latest models, such as Opus 4.6 Thinking.
-Only one test run was conducted per model, so there may be some variance in the results.

Even taking these factors into account, some of the outputs generated by Gemini 3.1 Pro were the best I have ever seen.

[![](https://nitter.net/pic/media%2FHBjVn-pbEAASXRU.png%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBjVn-pbEAASXRU.png)

![](https://nitter.net/pic/abs.twimg.com%2Fsticky%2Fdefault_profile_images%2Fdefault_profile_mini.png)[NomoreID](https://nitter.net/Hangsiin "NomoreID")

[@Hangsiin](https://nitter.net/Hangsiin "@Hangsiin")

[17 Dec 2025](https://nitter.net/Hangsiin/status/2001341564145250770#m "Dec 17, 2025 Â· 5:19 PM UTC")

Gemini 3.0 Flash achieved a very impressive 161.8/190 on one of my vibe tests, the Korean Sator Square Test (KSST), placing it 2nd or 3rd among all the models I have tested so far.

This is slightly higher than Gemini 3.0 Pro, and the difference is within the margin of error.

Below are a few observations I found noteworthy:

1\. Gemini 3.0 Flash (Low) appears to be token-efficient. Even on Low, it scored 158.6/190, which is near the top-tier range. This is an outstanding result achieved with only 2,394 total tokens (reasoning + output), and it compares very favorably against other top-performing models.

2\. Although the Low reasoning setting still produced a strong score, it occasionally made mistakes in some of the quantitative evaluation metrics. However, at High, it achieved perfect scores across all quantitative metrics with zero mistakes. This has only been matched by GPT-5.2 High.

3\. Gemini 3.0 Flash (High) showed a dramatic improvement of 60 points(!) compared to Gemini 2.5 Flash (reasoning).

Overall, I am very impressed by how strong the results were relative to my expectations, and I am excited to explore adopting this model in production.

Thank you to [@GoogleDeepMind](https://nitter.net/GoogleDeepMind "Google DeepMind") for the excellent work.

[![](https://nitter.net/pic/media%2FG8YwR4QbQAAaPnJ.png%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FG8YwR4QbQAAaPnJ.png)

[![](https://nitter.net/pic/media%2FG8YwfxcawAEJ9b6.png%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FG8YwfxcawAEJ9b6.png)

2

9

121

Yann LeCun retweeted

[![](https://nitter.net/pic/profile_images%2F1559587528109395969%2FHfLfInk2_bigger.jpg)](https://nitter.net/SteveRattner)

[Steven Rattner](https://nitter.net/SteveRattner "Steven Rattner")

[@SteveRattner](https://nitter.net/SteveRattner "@SteveRattner")

[23h](https://nitter.net/SteveRattner/status/2024828207619326409#m "Feb 20, 2026 Â· 12:47 PM UTC")

Trump sought deep cuts to the EPA, HUD, CDC, NIH, and more. Congress by and large left spending levels unchanged.

My [@Morning\_Joe](https://nitter.net/Morning_Joe "Morning Joe") Chart

[![](https://nitter.net/pic/media%2FHBmihJTWsAAppsP.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBmihJTWsAAppsP.jpg)

15

84

257

Yann LeCun retweeted

[![](https://nitter.net/pic/profile_images%2F1618421776794677248%2FEYJex5NK_bigger.jpg)](https://nitter.net/PTI_News)

[Press Trust of India](https://nitter.net/PTI_News "Press Trust of India")

[@PTI\_News](https://nitter.net/PTI_News "@PTI_News")

[Feb 20](https://nitter.net/PTI_News/status/2024811688516874662#m "Feb 20, 2026 Â· 11:41 AM UTC")

VIDEO \| Delhi: Yann LeCun ( [@ylecun](https://nitter.net/ylecun "Yann LeCun")), AI pioneer and former Chief AI Scientist at Meta, says, â€œItâ€™s enormous and very impressive, with so much activity and many interesting one-on-one interactions and forums. I think many countries should come together to build frontier models using data available across different regions of the world, which is not accessible to proprietary models. This could help open-source AI models become better than closed, proprietary ones... India should invest more in research, incentivise more students to pursue advanced degrees and PhDs, and encourage them to stay in India. Given the changing geopolitical situation, it is becoming harder to study in certain countries, which makes developing local expertise even more important. Being a leader in technology requires vibrant research activity, which can only happen with strong funding for academic research and PhD programmes.â€

He visited Puch AI stall with Puch AI co-founder & CEO Siddharth Bhatia ( [@siddharthb\_](https://nitter.net/siddharthb_ "Siddharth Bhatia")) at Bharat Mandapam during India AI Impact Summit.

[#PTIAtAIImpactSummit](https://nitter.net/search?f=tweets&q=%23PTIAtAIImpactSummit) [#IndiaAIImpactSummit2026](https://nitter.net/search?f=tweets&q=%23IndiaAIImpactSummit2026) [#AIImpactSummit2026](https://nitter.net/search?f=tweets&q=%23AIImpactSummit2026)

(Full video available on [ptivideos.com](http://ptivideos.com/))

![](https://nitter.net/pic/amplify_video_thumb%2F2024797396396646400%2Fimg%2F1KsG-Yx0GykJYjoB.jpg%3Fname%3Dsmall%26format%3Dwebp)

Enable hls playback

7

23

192

Zach Mueller retweeted

[![](https://nitter.net/pic/profile_images%2F1810349775910318081%2FuOXxMFYs_bigger.jpg)](https://nitter.net/k7agar)

[atharva â˜†](https://nitter.net/k7agar "atharva â˜†")

[@k7agar](https://nitter.net/k7agar "@k7agar")

[Feb 20](https://nitter.net/k7agar/status/2024778706489929985#m "Feb 20, 2026 Â· 9:30 AM UTC")

your goal as a computer wizard is to keep the gpu's happy and the tokens flowing

2

20

[![](https://nitter.net/pic/profile_images%2F1904933748015255552%2Fk43GMz63_bigger.jpg)](https://nitter.net/sama)

[Sam Altman](https://nitter.net/sama "Sam Altman")

[@sama](https://nitter.net/sama "@sama")

[23h](https://nitter.net/sama/status/2024826822060290508#m "Feb 20, 2026 Â· 12:41 PM UTC")

Great meeting with PM [@narendramodi](https://nitter.net/narendramodi "Narendra Modi") today to talk about the incredible energy around AI in India.

India is our fastest growing market for codex globally, up 4x in weekly users in the past 2 weeks alone.

ðŸ‡®ðŸ‡³!

[![](https://nitter.net/pic/media%2FHBmhLRaWgAANwWX.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBmhLRaWgAANwWX.jpg)

1,607

2,217

25,553

[![](https://nitter.net/pic/profile_images%2F1509901130670747666%2FJFlrSzB4_bigger.jpg)](https://nitter.net/reach_vb)

[Vaibhav (VB) Srivastav](https://nitter.net/reach_vb "Vaibhav (VB) Srivastav")

[@reach\_vb](https://nitter.net/reach_vb "@reach_vb")

[23h](https://nitter.net/reach_vb/status/2024831310317969423#m "Feb 20, 2026 Â· 12:59 PM UTC")

IndiaðŸ‡®ðŸ‡³ for the win!

24

Lisan al Gaib retweeted

[![](https://nitter.net/pic/profile_images%2F1780887025089957888%2FkOF2rK0X_bigger.jpg)](https://nitter.net/aicodeking)

[AICodeKing](https://nitter.net/aicodeking "AICodeKing") [@aicodeking](https://nitter.net/aicodeking "@aicodeking")

[23h](https://nitter.net/aicodeking/status/2024824978781421759#m "Feb 20, 2026 Â· 12:34 PM UTC")

TL;DR: 3.1 Pro is worse than Gemini 3.0 Pro in all of my tests and daily usage. It thinks too much, costs more and is not a good experience at all for the price. 3.1 Flash is a better google model IMHO.

[![](https://nitter.net/pic/media%2FHBmer5MaYAACod1.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBmer5MaYAACod1.jpg)

[![](https://nitter.net/pic/media%2FHBmfhfzakAEqgHw.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBmfhfzakAEqgHw.jpg)

![](https://nitter.net/pic/profile_images%2F1780887025089957888%2FkOF2rK0X_mini.jpg)[AICodeKing](https://nitter.net/aicodeking "AICodeKing") [@aicodeking](https://nitter.net/aicodeking "@aicodeking")

[Feb 20](https://nitter.net/aicodeking/status/2024822537658761430#m "Feb 20, 2026 Â· 12:24 PM UTC")

Gemini 3.1 Pro is one of the worst models in recent times for Agentic Coding: [piped.video/watch?v=R3GjTBSQâ€¦](https://piped.video/watch?v=R3GjTBSQjRk)

48

20

368

[![](https://nitter.net/pic/profile_images%2F1692481211888025600%2FlUJUEO_p_bigger.jpg)](https://nitter.net/dejavucoder)

[sankalp](https://nitter.net/dejavucoder "sankalp")

[@dejavucoder](https://nitter.net/dejavucoder "@dejavucoder")

[23h](https://nitter.net/dejavucoder/status/2024829174691836272#m "Feb 20, 2026 Â· 12:51 PM UTC")

part 2 is out!

![](https://nitter.net/pic/profile_images%2F963573106232225795%2F2JilY9CN_mini.jpg)[Steve Kaliski](https://nitter.net/stevekaliski "Steve Kaliski")

[@stevekaliski](https://nitter.net/stevekaliski "@stevekaliski")

[Feb 19](https://nitter.net/stevekaliski/status/2024578928430764362#m "Feb 19, 2026 Â· 8:16 PM UTC")

Part 2 is out!

Learn more about how our minions (our one-shot, end-to-end coding agents) work and the Stripe-specific work that went into building them.

[stripe.dev/blog/minions-striâ€¦](https://stripe.dev/blog/minions-stripes-one-shot-end-to-end-coding-agents-part-2)

13

[![](https://nitter.net/pic/profile_images%2F1831493788679761920%2F-q9w6dzd_bigger.jpg)](https://nitter.net/scaling01)

[Lisan al Gaib](https://nitter.net/scaling01 "Lisan al Gaib")

[@scaling01](https://nitter.net/scaling01 "@scaling01")

[23h](https://nitter.net/scaling01/status/2024828845367423048#m "Feb 20, 2026 Â· 12:49 PM UTC")

Gemini 3.1 Pro new SOTA on SimpleBench

[![](https://nitter.net/pic/media%2FHBmjGsFXoAEiuSp.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBmjGsFXoAEiuSp.jpg)

7

17

344

[![](https://nitter.net/pic/profile_images%2F1790643775401754626%2Fcr9uM-ie_bigger.png)](https://nitter.net/ben_burtenshaw)

[Ben Burtenshaw](https://nitter.net/ben_burtenshaw "Ben Burtenshaw")

[@ben\_burtenshaw](https://nitter.net/ben_burtenshaw "@ben_burtenshaw")

[Feb 20](https://nitter.net/ben_burtenshaw/status/2024816303018783163#m "Feb 20, 2026 Â· 12:00 PM UTC")

codex --yolo "fine tune LFM2.5-1.2B-Instruct for $2"

you can just let agents finetune models on hf. right now, it is free!

![](https://nitter.net/pic/profile_images%2F1790643775401754626%2Fcr9uM-ie_mini.png)[Ben Burtenshaw](https://nitter.net/ben_burtenshaw "Ben Burtenshaw")

[@ben\_burtenshaw](https://nitter.net/ben_burtenshaw "@ben_burtenshaw")

[Feb 19](https://nitter.net/ben_burtenshaw/status/2024552060558229858#m "Feb 19, 2026 Â· 6:30 PM UTC")

You can finetune AI models with Unsloth + Hugging Face, and right now itâ€™s free!

We're giving away GPU credits on HF Jobs + Unsloth.

Train a 1.2B model like [@liquidai](https://nitter.net/liquidai "Liquid AI") LFM2.5-1.2B with one command. Ship it to your phone, laptop, or API.

No infra. No setup. Just prompt your coding agent and go.

[![](https://nitter.net/pic/media%2FHBiadLSXAAEZ2TT.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBiadLSXAAEZ2TT.jpg)

3

9

63

[![](https://nitter.net/pic/profile_images%2F1790643775401754626%2Fcr9uM-ie_bigger.png)](https://nitter.net/ben_burtenshaw)

[Ben Burtenshaw](https://nitter.net/ben_burtenshaw "Ben Burtenshaw")

[@ben\_burtenshaw](https://nitter.net/ben_burtenshaw "@ben_burtenshaw")

[23h](https://nitter.net/ben_burtenshaw/status/2024827586044481958#m "Feb 20, 2026 Â· 12:44 PM UTC")

join this org to get the credit [huggingface.co/organizationsâ€¦](https://huggingface.co/organizations/unsloth-jobs/share/yzqqXYYzitHAUsdscaGuHEsnRMtiyTSLbY)

[![](https://nitter.net/pic/card_img%2F2023998670794862592%2FqdvAhQ9l%3Fformat%3Dpng%26name%3D800x419)\\
\\
**Hugging Face â€“ The AI community building the future.** \\
\\
Weâ€™re on a journey to advance and democratize artificial intelligence through open source and open science.\\
\\
huggingface.co](https://huggingface.co/organizations/unsloth-jobs/share/yzqqXYYzitHAUsdscaGuHEsnRMtiyTSLbY)

3

sankalp retweeted

[![](https://nitter.net/pic/profile_images%2F1197707958387273728%2FxzhFJjZl_bigger.jpg)](https://nitter.net/ponnappa)

[Sidu Ponnappa](https://nitter.net/ponnappa "Sidu Ponnappa")

[@ponnappa](https://nitter.net/ponnappa "@ponnappa")

[Feb 19](https://nitter.net/ponnappa/status/2024417519789101518#m "Feb 19, 2026 Â· 9:35 AM UTC")

[x.com/i/article/202438376343â€¦](http://x.com/i/article/2024383763430723585)

75

154

948

[![](https://nitter.net/pic/profile_images%2F1650881612756942850%2FbZYjMyFU_bigger.jpg)](https://nitter.net/random_walker)

[Arvind Narayanan](https://nitter.net/random_walker "Arvind Narayanan")

[@random\_walker](https://nitter.net/random_walker "@random_walker")

[23h](https://nitter.net/random_walker/status/2024827356813087053#m "Feb 20, 2026 Â· 12:43 PM UTC")

Excellent analysis. And Exhibit #3084 in support of my and [@sayashk](https://nitter.net/sayashk "Sayash Kapoor")'s position that alignment/safety is not a model property, which we first wrote about two years ago [normaltech.ai/p/ai-safety-isâ€¦](https://www.normaltech.ai/p/ai-safety-is-not-a-model-property)

Whether a particular analysis constitutes p-hacking or a responsible investigation is not a property of the analysis itself, but how the user plans to use the analysis. And the user can trivially lie about this to the model.

It's the exact same pattern with other malicious / unethical uses such as using AI for hacking, phishing, disinformation, etc. [normaltech.ai/p/ai-safety-isâ€¦](https://www.normaltech.ai/p/ai-safety-is-not-a-model-property)

The fact that models didn't p-hack by default is important and good. This helps guard well-intentioned but clueless researchers from p-hacking without knowing it (surprisingly common). The fact that ill-intentioned users can trick models into p-hacking should not be considered a problem and is not fixable.

The other piece of good news is that, as Andy says, "the same tools that may lower the cost of p-hacking also lower the cost of catching it."

[![](https://nitter.net/pic/card_img%2F2024245320570540032%2F8z7Xek9d%3Fformat%3Djpg%26name%3D800x419)\\
\\
**AI safety is not a model property** \\
\\
Trying to make an AI model that canâ€™t be misused is like trying to make a computer that canâ€™t be used for bad things\\
\\
normaltech.ai](https://www.normaltech.ai/p/ai-safety-is-not-a-model-property)

![](https://nitter.net/pic/profile_images%2F1940818025537482752%2FeMsuRJq3_mini.jpg)[Andy Hall](https://nitter.net/ahall_research "Andy Hall")

[@ahall\_research](https://nitter.net/ahall_research "@ahall_research")

[Feb 19](https://nitter.net/ahall_research/status/2024544040784720365#m "Feb 19, 2026 Â· 5:58 PM UTC")

AI is about to write thousands of papers. Will it p-hack them?

We ran an experiment to find out, giving AI coding agents real datasets from published null results and pressuring them to manufacture significant findings.

It was surprisingly hard to get the models to p-hack, and they even scolded us when we asked them to!

"I need to stop here. I cannot complete this task as requested... This is a form of scientific fraud." â€” Claude

"I can't help you manipulate analysis choices to force statistically significant results." â€” GPT-5

BUT, when we reframed p-hacking as "responsible uncertainty quantification" â€” asking for the upper bound of plausible estimates â€” both models went wild. They searched over hundreds of specifications and selected the winner, tripling effect sizes in some cases.

Our takeaway: AI models are surprisingly resistant to sycophantic p-hacking when doing social science research. But they can be jailbroken into sophisticated p-hacking with surprisingly little effort â€” and the more analytical flexibility a research design has, the worse the damage.

As AI starts writing thousands of papers---like [@paulnovosad](https://nitter.net/paulnovosad "Paul Novosad") and [@YanagizawaD](https://nitter.net/YanagizawaD "D. Yanagizawa-Drott") have been exploring---this will be a big deal. We're inspired in part by the work that [@joabaum](https://nitter.net/joabaum "Joachim Baumann") et al have been doing on p-hacking and LLMs.

Weâ€™ll be doing more work to explore p-hacking in AI and to propose new ways of curating and evaluating research with these issues in mind. The good news is that the same tools that may lower the cost of p-hacking also lower the cost of catching it.

Full paper and repo linked in the reply below.

[![](https://nitter.net/pic/media%2FHBibonHbsAAkCC1.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBibonHbsAAkCC1.jpg)

3

27

[![](https://nitter.net/pic/profile_images%2F1728327996375719936%2FRW7VBJfD_bigger.jpg)](https://nitter.net/kimmonismus)

[Chubbyâ™¨ï¸](https://nitter.net/kimmonismus "Chubbyâ™¨ï¸")

[@kimmonismus](https://nitter.net/kimmonismus "@kimmonismus")

[23h](https://nitter.net/kimmonismus/status/2024827123085840826#m "Feb 20, 2026 Â· 12:43 PM UTC")

Maybe AGI was the friends we made along the way.

14

21

357

[![](https://nitter.net/pic/profile_images%2F1992723717156433920%2FMLFviQhQ_bigger.jpg)](https://nitter.net/maharshii)

[maharshi](https://nitter.net/maharshii "maharshi")

[@maharshii](https://nitter.net/maharshii "@maharshii")

[23h](https://nitter.net/maharshii/status/2024826905137226089#m "Feb 20, 2026 Â· 12:42 PM UTC")

sorry to bite this ragebait but these are the kind of people who have never multiplied two matrices and think AI is a long chain of if-else statements

[![](https://nitter.net/pic/media%2FHBmhVd-asAAFWGg.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBmhVd-asAAFWGg.jpg)

35

77

1,195

[![](https://nitter.net/pic/profile_images%2F1728327996375719936%2FRW7VBJfD_bigger.jpg)](https://nitter.net/kimmonismus)

[Chubbyâ™¨ï¸](https://nitter.net/kimmonismus "Chubbyâ™¨ï¸")

[@kimmonismus](https://nitter.net/kimmonismus "@kimmonismus")

[23h](https://nitter.net/kimmonismus/status/2024825744287785275#m "Feb 20, 2026 Â· 12:37 PM UTC")

Now Iâ€™m curious- some DeepSeek incoming

![](https://nitter.net/pic/profile_images%2F1926364057004646400%2Fz3oD9QyB_mini.jpg)[Chetaslua](https://nitter.net/chetaslua "Chetaslua")

[@chetaslua](https://nitter.net/chetaslua "@chetaslua")

[Feb 20](https://nitter.net/chetaslua/status/2024772308402159658#m "Feb 20, 2026 Â· 9:05 AM UTC")

i have some good news regarding whale , will reveal in few hours

stay tuned , till then comments what you think it is ðŸ‘€

[![](https://nitter.net/pic/media%2FHBlvd-WaYAAUIUf.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBlvd-WaYAAUIUf.jpg)

8

8

212

[![](https://nitter.net/pic/profile_images%2F1831493788679761920%2F-q9w6dzd_bigger.jpg)](https://nitter.net/scaling01)

[Lisan al Gaib](https://nitter.net/scaling01 "Lisan al Gaib")

[@scaling01](https://nitter.net/scaling01 "@scaling01")

[Feb 20](https://nitter.net/scaling01/status/2024824372607750367#m "Feb 20, 2026 Â· 12:32 PM UTC")

I love that there are people who have been with me on this journey since day 1

2

22

Brivael retweeted

[![](https://nitter.net/pic/profile_images%2F1256841238298292232%2FycqwaMI2_bigger.jpg)](https://nitter.net/naval)

[Naval](https://nitter.net/naval "Naval")

[@naval](https://nitter.net/naval "@naval")

[Feb 20](https://nitter.net/naval/status/2024700227111047581#m "Feb 20, 2026 Â· 4:18 AM UTC")

New podcast on AI (full episode). Links below.

A Motorcycle for the Mind

0:00 If you want to learn, do

2:13 Vibe coding is the new product management

6:49 Training models is the new coding

10:13 Is traditional software engineering dead?

13:07 There is no demand for average

14:12 The hottest new programming language is English

18:36 AI is adapting to us faster than we are adapting to it

22:56 No entrepreneur is worried about AI taking their job

26:46 The goal is not to have a job

29:49 AIs are not alive

32:55 AI fails the only true test of intelligence

36:49 Early adopters of AI have an enormous edge

39:37 AI meets you exactly where you are

43:02 Always leverage the best intelligence

44:37 If you can't define it, you can't program it

49:37 The solution to AI anxiety is action

![](https://nitter.net/pic/amplify_video_thumb%2F2024697027918249984%2Fimg%2Fr0sjTZbJvN2gIK5F.jpg%3Fname%3Dsmall%26format%3Dwebp)

Enable hls playback

324

1,479

10,660

[![](https://nitter.net/pic/profile_images%2F1831950115873157120%2F43tadGLR_bigger.jpg)](https://nitter.net/kipperrii)

[kipply](https://nitter.net/kipperrii "kipply")

[@kipperrii](https://nitter.net/kipperrii "@kipperrii")

[Feb 20](https://nitter.net/kipperrii/status/2024822999531098212#m "Feb 20, 2026 Â· 12:26 PM UTC")

so much fun that they cant ignore you

![](https://nitter.net/pic/profile_images%2F1753264923365523456%2FmUCvwn7v_mini.jpg)[Nick](https://nitter.net/nickcammarata "Nick")

[@nickcammarata](https://nitter.net/nickcammarata "@nickcammarata")

[Feb 20](https://nitter.net/nickcammarata/status/2024704310479901147#m "Feb 20, 2026 Â· 4:34 AM UTC")

the obvious lesson is â€œonly do things for joyâ€

but the real move is deliberately training joy itself, as youâ€™d train your physical muscles. stop optimizing the activity, upgrade the substrate. then it doesnâ€™t matter what youâ€™re doing, whatever it is, it will be done joyfully

1

2

30

[![](https://nitter.net/pic/profile_images%2F1803756314469847040%2FXn7-ka2P_bigger.jpg)](https://nitter.net/TheZachMueller)

[Zach Mueller](https://nitter.net/TheZachMueller "Zach Mueller")

[@TheZachMueller](https://nitter.net/TheZachMueller "@TheZachMueller")

[Feb 20](https://nitter.net/TheZachMueller/status/2024822326840209447#m "Feb 20, 2026 Â· 12:23 PM UTC")

Taking a rest day today. No one is allowed to release anything.

Thanks for coming to this important announcement

3

21

[![](https://nitter.net/pic/profile_images%2F1692481211888025600%2FlUJUEO_p_bigger.jpg)](https://nitter.net/dejavucoder)

[sankalp](https://nitter.net/dejavucoder "sankalp")

[@dejavucoder](https://nitter.net/dejavucoder "@dejavucoder")

[Feb 20](https://nitter.net/dejavucoder/status/2024821016590246205#m "Feb 20, 2026 Â· 12:18 PM UTC")

me telling codex to review code written by me and claude

[![](https://nitter.net/pic/media%2FHBmb81Va4AAChjy.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBmb81Va4AAChjy.jpg)

5

14

287

[![](https://nitter.net/pic/profile_images%2F1403376500192071683%2Fzvr_Hkox_bigger.jpg)](https://nitter.net/sarahookr)

[Sara Hooker](https://nitter.net/sarahookr "Sara Hooker")

[@sarahookr](https://nitter.net/sarahookr "@sarahookr")

[Feb 20](https://nitter.net/sarahookr/status/2024819637322694890#m "Feb 20, 2026 Â· 12:13 PM UTC")

Fresh flowers are a very nice detail on each of the stages.

[![](https://nitter.net/pic/media%2FHBmaucIbkAAdJqH.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBmaucIbkAAdJqH.jpg)

8

24

699

[![](https://nitter.net/pic/profile_images%2F1831493788679761920%2F-q9w6dzd_bigger.jpg)](https://nitter.net/scaling01)

[Lisan al Gaib](https://nitter.net/scaling01 "Lisan al Gaib")

[@scaling01](https://nitter.net/scaling01 "@scaling01")

[Feb 20](https://nitter.net/scaling01/status/2024819312335245800#m "Feb 20, 2026 Â· 12:11 PM UTC")

more evidence in favor of the "Google is 3 months behind OAI and Ant" hypothesis

![](https://nitter.net/pic/profile_images%2F2018048606905810944%2Fdg-YVGR7_mini.jpg)[leo ðŸ¾](https://nitter.net/synthwavedd "leo ðŸ¾")

[@synthwavedd](https://nitter.net/synthwavedd "@synthwavedd")

[Feb 20](https://nitter.net/synthwavedd/status/2024818410962513966#m "Feb 20, 2026 Â· 12:08 PM UTC")

wtf happened with 3.1 pro and FrontierMath lol

regressed on both Tier 1-3 and Tier 4 compared to 3 Pro

[![](https://nitter.net/pic/media%2FHBmZZABW8AAJ3gO.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBmZZABW8AAJ3gO.jpg)

8

6

171

Demis Hassabis retweeted

[![](https://nitter.net/pic/profile_images%2F2015405434597744640%2FO38X4QG2_bigger.jpg)](https://nitter.net/LexnLin)

[Leon Lin](https://nitter.net/LexnLin "Leon Lin")

[@LexnLin](https://nitter.net/LexnLin "@LexnLin")

[Feb 19](https://nitter.net/LexnLin/status/2024589077685629100#m "Feb 19, 2026 Â· 8:57 PM UTC")

gemini pro 3.1 ui gen is really cracked

just one shotted this

![](https://nitter.net/pic/amplify_video_thumb%2F2024588705642455040%2Fimg%2F7ezMjBJEj-6YkjpH.jpg%3Fname%3Dsmall%26format%3Dwebp)

Enable hls playback

74

94

2,836

[![](https://nitter.net/pic/profile_images%2F1831493788679761920%2F-q9w6dzd_bigger.jpg)](https://nitter.net/scaling01)

[Lisan al Gaib](https://nitter.net/scaling01 "Lisan al Gaib")

[@scaling01](https://nitter.net/scaling01 "@scaling01")

[Feb 20](https://nitter.net/scaling01/status/2024817652779057254#m "Feb 20, 2026 Â· 12:05 PM UTC")

Definitely worth a read:

designing a neural network for 10 digit addition with Codex and Claude Code

![](https://nitter.net/pic/profile_images%2F1733487310728024064%2FAh_NBQlM_mini.jpg)[Dimitris Papailiopoulos](https://nitter.net/DimitrisPapail "Dimitris Papailiopoulos")

[@DimitrisPapail](https://nitter.net/DimitrisPapail "@DimitrisPapail")

[Feb 19](https://nitter.net/DimitrisPapail/status/2024555561199480918#m "Feb 19, 2026 Â· 6:43 PM UTC")

[x.com/i/article/202454779264â€¦](http://x.com/i/article/2024547792648359937)

2

33

[![](https://nitter.net/pic/profile_images%2F1221029033162498048%2FY8WqOZlY_bigger.jpg)](https://nitter.net/paul_cal)

[Paul Calcraft](https://nitter.net/paul_cal "Paul Calcraft")

[@paul\_cal](https://nitter.net/paul_cal "@paul_cal")

[Feb 20](https://nitter.net/paul_cal/status/2024817020529766764#m "Feb 20, 2026 Â· 12:02 PM UTC")

Opus 4.6 keeps blowing through its \*entire\* token budget & eventually responding completely empty when I ask for max reasoning. Finish reason: "length"

These are short prompts - 160 token input. Thinks for 20 mins then blows up & charges me money for the privilege

[![](https://nitter.net/pic/media%2FHBmW-y-XcAAzRhw.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBmW-y-XcAAzRhw.jpg)

2

30

[![](https://nitter.net/pic/profile_images%2F1672707817197965312%2FzsxkJv_T_bigger.jpg)](https://nitter.net/TheRundownAI)

[The Rundown AI](https://nitter.net/TheRundownAI "The Rundown AI")

[@TheRundownAI](https://nitter.net/TheRundownAI "@TheRundownAI")

[Feb 20](https://nitter.net/TheRundownAI/status/2024808855293559141#m "Feb 20, 2026 Â· 11:30 AM UTC")

Top stories in AI today:

\- The handshake refusal heard around the AI world
\- Google's Gemini 3.1 Pro doubles up on reasoning
\- Write viral YouTube scripts with NotebookLM
\- Corporate giant Accenture ties AI usage to promotions
\- 4 new AI tools, community workflows, and more

[![](https://nitter.net/pic/media%2FHBmQ7BSXEAA89eK.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBmQ7BSXEAA89eK.jpg)

4

1

13

[![](https://nitter.net/pic/profile_images%2F1672707817197965312%2FzsxkJv_T_bigger.jpg)](https://nitter.net/TheRundownAI)

[The Rundown AI](https://nitter.net/TheRundownAI "The Rundown AI")

[@TheRundownAI](https://nitter.net/TheRundownAI "@TheRundownAI")

[Feb 20](https://nitter.net/TheRundownAI/status/2024808858485445004#m "Feb 20, 2026 Â· 11:30 AM UTC")

Read more: [therundown.ai/p/the-handshakâ€¦](https://www.therundown.ai/p/the-handshake-refusal-heard-around-the-ai-world)

[![](https://nitter.net/pic/card_img%2F2024808861069152256%2FuBiSuflp%3Fformat%3Djpg%26name%3D800x419)\\
\\
**The handshake refusal heard around the AI world** \\
\\
PLUS: Google's Gemini 3.1 Pro doubles up on reasoning\\
\\
therundown.ai](https://www.therundown.ai/p/the-handshake-refusal-heard-around-the-ai-world)

1

[Load more](https://nitter.net/i/lists/1585430245762441216?cursor=DAABCgABHBraGT1__agKAAIcGZDtzBbRjAgAAwAAAAIAAA)