[![](https://nitter.net/pic/list_banner_img%2F1613505644405075970%2F9VRDCFnW%3Fformat%3Djpg%26name%3Dorig)](https://nitter.net/pic/list_banner_img%2F1613505644405075970%2F9VRDCFnW%3Fformat%3Djpg%26name%3Dorig)

"AI High Signal" by @

AI twitter accounts that are high signal

- [Tweets](https://nitter.net/i/lists/1585430245762441216)
- [Members](https://nitter.net/i/lists/1585430245762441216/members)

[Load newest](https://nitter.net/i/lists/1585430245762441216)

Jared Zoneraich retweeted

[![](https://nitter.net/pic/profile_images%2F1905396692809052160%2Fl0oreOJh_bigger.jpg)](https://nitter.net/MarkMBissell)

[mark bissell](https://nitter.net/MarkMBissell "mark bissell")

[@MarkMBissell](https://nitter.net/MarkMBissell "@MarkMBissell")

[Feb 20](https://nitter.net/MarkMBissell/status/2024876447962448186#m "Feb 20, 2026 ¬∑ 3:59 PM UTC")

to win gold medals and nobel prizes you just need to be funmaxxing

[![](https://nitter.net/pic/media%2FHBlT7DCbUAUkYtz.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBlT7DCbUAUkYtz.jpg)

![](https://nitter.net/pic/profile_images%2F1927795530920239104%2Frv8FxhKB_mini.jpg)[Brad Stulberg](https://nitter.net/BStulberg "Brad Stulberg")

[@BStulberg](https://nitter.net/BStulberg "@BStulberg")

[Feb 19](https://nitter.net/BStulberg/status/2024628741910196463#m "Feb 19, 2026 ¬∑ 11:34 PM UTC")

Joy is a competitive super power.

Alysa Liu retired from figure skating at 16.
She was tired of not not having fun, tired of being consumed by her sport.

She came back two years later with a new goal: to have as much fun on the ice as possible. And now she‚Äôs an Olympic gold medalist.

Liu won her first national title when she was just 13. But by 16, after competing in the 2022 Olympics, she decided she‚Äôd had enough and stepped away. She said pressure and losing her identity trying to be an elite athlete made it all miserable.

But then, she said she went on a ski trip that reminded her just how much fun she could have doing a sport. Something in her brain clicked. Maybe she could bring fun to figure skating. Maybe she could approach it in a way that could be full of joy and life and love.

She unretired at 18 and won a world championship the next year. At 20, she was ready to face these Olympic games differently than in 2022.

Liu went into the women‚Äôs figure skating final in third place. After her short program, she said:

‚ÄúEven if I mess up and fall, that‚Äôs totally okay, too. I‚Äôm fine with any outcome, as long as I‚Äôm out there.‚Äù

One of the greatest competitive advantages is having fun. People love to romanticize the athlete, artist, or entrepreneur who has a chip on their shoulder, fueled by anger and resentment.

But the truth is that if you‚Äôre not having fun, you are not going to last long at whatever it is you do, and you certainly won‚Äôt get the best out of yourself. There‚Äôs a foolish idea that you either have to be full of intensity or full of joy. But that‚Äôs nonsense.

It‚Äôs no surprise one of the first things out of Alysa‚Äôs mouth after her free skate was: ‚ÄúThat was so much fun!‚Äù

Joy and intensity can coexist, and in the best performers, they almost always do.

Alysa is unapologetically authentic and true to her values. She has said where she used to skate to win and be technically perfect, she now uses competition as a chance to show her art, to have fun, and to put herself out there.

She‚Äôs a fierce athlete with an infectious sense of joy in her sport.

And she broke USA's 24-year gold medal draught in women‚Äôs figure skating doing it.

Excellence requires focus, determination, a little bit of crazy, at times obsession, and living a mundane lifestyle that many people would find boring.

But excellence also requires that you find deep joy in your craft, that you learn how to have fun while working hard.

What makes for excellence‚Äîand not just in sports, but in anything‚Äîis the combination of intensity and joy. It‚Äôs the latter that makes the former sustainable.

[![](https://nitter.net/pic/media%2FHBjolYDbUAIJFR4.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBjolYDbUAIJFR4.jpg)

4

231

2,410

Stanford NLP Group retweeted

[![](https://nitter.net/pic/profile_images%2F1600839794837229568%2FjeUmyEuD_bigger.jpg)](https://nitter.net/EchoShao8899)

[Yijia Shao](https://nitter.net/EchoShao8899 "Yijia Shao") [@EchoShao8899](https://nitter.net/EchoShao8899 "@EchoShao8899")

[Feb 19](https://nitter.net/EchoShao8899/status/2024279651984822754#m "Feb 19, 2026 ¬∑ 12:27 AM UTC")

The second episode of [@augmind\_fm](https://nitter.net/augmind_fm "Augmented Mind Podcast") will drop next week! We're also hosting an in-person Discussion + Watch Party on Tuesday, Feb 24 (11am‚Äì1pm) at Stanford's Gates Building ‚Äî with food and swag!

In this episode, we're honored to welcome [@tongshuangwu](https://nitter.net/tongshuangwu "Sherry Tongshuang Wu") as our guest. I'm super excited about this episode - Sherry shared her experience navigating the past few years as a faculty member at CMU through the whirlwind of AI, and her research journey from building AI systems that account for imperfect models to those that account for imperfect humans.

If you're into technical human-centered AI and want a low-key way to meet others building in the space, come hang out! RSVP link + Event schedule belowüëá

![](https://nitter.net/pic/profile_images%2F2013987640949837824%2FYMR5g2nJ_mini.jpg)[Augmented Mind Podcast](https://nitter.net/augmind_fm "Augmented Mind Podcast")

[@augmind\_fm](https://nitter.net/augmind_fm "@augmind_fm")

[Feb 18](https://nitter.net/augmind_fm/status/2024263977061249199#m "Feb 18, 2026 ¬∑ 11:25 PM UTC")

üß†üéôÔ∏è We‚Äôre co-hosting an Augmented Mind Podcast Meetup w/ a16z ‚Äî Tue Feb 24 (11‚Äì1) @ Gates CS (Stanford)!

If you‚Äôre into technical human-centered AI and want an easy, low-pressure way to meet others building in the space, come hang out!

üîóLink to RSVP Below

1

3

21

[![](https://nitter.net/pic/profile_images%2F1803756314469847040%2FXn7-ka2P_bigger.jpg)](https://nitter.net/TheZachMueller)

[Zach Mueller](https://nitter.net/TheZachMueller "Zach Mueller")

[@TheZachMueller](https://nitter.net/TheZachMueller "@TheZachMueller")

[23h](https://nitter.net/TheZachMueller/status/2024889305563340871#m "Feb 20, 2026 ¬∑ 4:50 PM UTC")

I believe it. Of the new model cards, Minimax has had the most consistent traction and highest overall views.

(And also continues to run my OpenClaw upstairs ü§ó)

![](https://nitter.net/pic/profile_images%2F1875100548535574529%2FVxHk9HyU_mini.jpg)[MiniMax (official)](https://nitter.net/MiniMax_AI "MiniMax (official)")

[@MiniMax\_AI](https://nitter.net/MiniMax_AI "@MiniMax_AI")

[23h](https://nitter.net/MiniMax_AI/status/2024877880971554850#m "Feb 20, 2026 ¬∑ 4:04 PM UTC")

3-TRILLION in one weekü´®üöÄ

3

2

286

Stanford NLP Group retweeted

[![](https://nitter.net/pic/profile_images%2F1539123956950700035%2FDLTn2gEX_bigger.jpg)](https://nitter.net/RishiBommasani)

[rishi](https://nitter.net/RishiBommasani "rishi")

[@RishiBommasani](https://nitter.net/RishiBommasani "@RishiBommasani")

[Feb 20](https://nitter.net/RishiBommasani/status/2024660499955327176#m "Feb 20, 2026 ¬∑ 1:40 AM UTC")

I confess that I have often been skeptical of LM-driven biorisk (for several reasons), though risk from biological design tools seems more plausible to me.

My skepticism is heavily founded in the paucity of open research on AI-mediated biorisk. The lack of openness and transparency is often justified by standard security arguments about info hazards. For example, back in 2023, Anthropic published their mysterious redteaming exercise about "Findings from red teaming biology" that said nothing of substantial value for an external observer.
[anthropic.com/news/frontier-‚Ä¶](https://www.anthropic.com/news/frontier-threats-red-teaming-for-ai-safety)
While there are circumstances that necessitate limited transparency, I often found the tradeoffs back then on information sharing to be poorly managed. Overall, it seemed to inherit the posture of much of national security, which as a computer scientist often seems like "security through obscurity". Security through obscurity has its place. But in a nascent area, I don't think such a conservative posture on sharing information is likely to be right.

My views on the substantive matter of AI biorisk have changed some in recent years. Companies have done better some in saying more, and engaging external evaluators, and governments have improved capacity. And over the year, passing interactions with Luca and reading his work has shaped my views significantly on this issue.

I am really glad he pursues this issue with the true candor of an earnest scientist. This is what we need. I hope the way he conducts his research can pervade through this area because we would have much more credible science on AI-mediated biorisk if so. And that would help forge expert consensus on the current level of risk in this domain, which I feel has often been lacking precisely because the public evidence in this domain has been so lackluster.

[![](https://nitter.net/pic/card_img%2F2023729772488949760%2FkXbMtfnm%3Fformat%3Djpg%26name%3D800x419)\\
\\
**Frontier Threats Red Teaming for AI Safety** \\
\\
Anthropic is an AI safety and research company that's working to build reliable, interpretable, and steerable AI systems.\\
\\
anthropic.com](https://www.anthropic.com/news/frontier-threats-red-teaming-for-ai-safety)

![](https://nitter.net/pic/profile_images%2F1498300461127925762%2F3Rym6bcf_mini.jpg)[Luca Righetti](https://nitter.net/lucafrighetti "Luca Righetti")

[@lucafrighetti](https://nitter.net/lucafrighetti "@lucafrighetti")

[Feb 19](https://nitter.net/lucafrighetti/status/2024608022103052645#m "Feb 19, 2026 ¬∑ 10:12 PM UTC")

Sharing 3 bits of work today!

üü† [@ActiveSiteBio](https://nitter.net/ActiveSiteBio "Active Site"): RCT finds AIs help novices at wet-lab steps but not end-to-end success

üü£ [@Research\_FRI](https://nitter.net/Research_FRI "Forecasting Research Institute"): This surprised experts. If future AIs 5X success biorisk may rise 2X

üü¢ [@METR\_Evals](https://nitter.net/METR_Evals "METR"): My case for in-depth studies amid hectic LLM releases

[![](https://nitter.net/pic/media%2FHBjaQv7bUAE2CXF.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBjaQv7bUAE2CXF.jpg)

6

43

Lisan al Gaib retweeted

[![](https://nitter.net/pic/profile_images%2F1904982870688411648%2Fi0X0WCJR_bigger.jpg)](https://nitter.net/Clad3815)

[Clad3815](https://nitter.net/Clad3815 "Clad3815")

[@Clad3815](https://nitter.net/Clad3815 "@Clad3815")

[23h](https://nitter.net/Clad3815/status/2024882063992606798#m "Feb 20, 2026 ¬∑ 4:21 PM UTC")

üì¢ PokeBench is now open source, LLMs playing real Pokemon Stadium 2 battles on the N64.

Last year, when o1 and o4-mini dropped, I wanted a fun way to stress-test how reasoning models actually think under pressure. Then I saw this tweet from [@edwinarbus](https://nitter.net/edwinarbus "edwin") and knew exactly what to build.

So I built PokeBench, a platform that pits two LLMs against each other in actual Pokemon Stadium 2 matches running on the N64.

No simulation. Each AI reads live game memory, drafts a team, picks moves, and sends real controller inputs through Project64. You can watch the entire battle unfold on a live dashboard and read exactly what each model is thinking on every turn.

After months of tweaking and optimizing, I'm releasing the whole thing as open source.

It supports OpenAI, Anthropic, Google Gemini, DeepSeek, Mistral, and OpenRouter out of the box. It's built on AI SDK, so adding a new provider takes minutes. You can configure reasoning effort, battle formats (Bo1 / Bo3 / Bo5), team sizes (3v3 / 6v6), and track stats across hundreds of matches.

Full tournament results from last year are in the replies. (Spoiler: GPT-4.5 took the crown)

Huge shoutout to [@Qualzz\_Sam](https://nitter.net/Qualzz_Sam "Qual") for the design system.
I'd love to see someone run a full benchmark across all the latest providers and models and share the results. (Looking at you, [@OpenRouter](https://nitter.net/OpenRouter "OpenRouter") )
Go run your own benchmarks! Link below.

[![](https://nitter.net/pic/media%2FHBnNU31XgAAdENo.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBnNU31XgAAdENo.jpg)

[![](https://nitter.net/pic/media%2FHBnQGKiXUAApd8l.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBnQGKiXUAApd8l.jpg)

8

3

44

[![](https://nitter.net/pic/profile_images%2F1728327996375719936%2FRW7VBJfD_bigger.jpg)](https://nitter.net/kimmonismus)

[Chubby‚ô®Ô∏è](https://nitter.net/kimmonismus "Chubby‚ô®Ô∏è")

[@kimmonismus](https://nitter.net/kimmonismus "@kimmonismus")

[23h](https://nitter.net/kimmonismus/status/2024887011522576766#m "Feb 20, 2026 ¬∑ 4:40 PM UTC")

Holy sh\*t: Sam Altman:

"The inside view at the companys of looking at what's going to happen - the \*world is not prepared.\* We're going to have extremely capable models soon. It's going to be a faster takeoff than I originally thought. And that is stressfull and anxiety inducing"

![](https://nitter.net/pic/amplify_video_thumb%2F2024886946443755520%2Fimg%2FMk9eYb-VfNPHOq4V.jpg%3Fname%3Dsmall%26format%3Dwebp)

Enable hls playback

200

274

2,589

[![](https://nitter.net/pic/profile_images%2F1728327996375719936%2FRW7VBJfD_bigger.jpg)](https://nitter.net/kimmonismus)

[Chubby‚ô®Ô∏è](https://nitter.net/kimmonismus "Chubby‚ô®Ô∏è")

[@kimmonismus](https://nitter.net/kimmonismus "@kimmonismus")

[23h](https://nitter.net/kimmonismus/status/2024887023337878011#m "Feb 20, 2026 ¬∑ 4:41 PM UTC")

[piped.video/watch?v=qH7thwrC‚Ä¶](https://piped.video/watch?v=qH7thwrCluM)

[![](https://nitter.net/pic/card_img%2F2025074185152643073%2FwCk-IRN_%3Fformat%3Djpg%26name%3D800x320_1)\\
\\
**Sam Altman Unfiltered: ChatGPT, AI Risks & What‚Äôs Coming Next, 40...** \\
\\
Sam Altman Exclusive: Is AI Getting Dangerous? ChatGPT, AI Safety, Risks & the Future of AI : Sam Altman Exclusive: In this exclusive 60-minute interview, S...\\
\\
youtube.com](https://piped.video/watch?v=qH7thwrCluM)

4

75

[![](https://nitter.net/pic/profile_images%2F1661187442043486209%2Fa3E4t1eV_bigger.jpg)](https://nitter.net/rasbt)

[Sebastian Raschka](https://nitter.net/rasbt "Sebastian Raschka")

[@rasbt](https://nitter.net/rasbt "@rasbt")

[23h](https://nitter.net/rasbt/status/2024886543630966917#m "Feb 20, 2026 ¬∑ 4:39 PM UTC")

February is one of those months...

\- Moonshot AI's Kimi K2.5 (Feb 2)
\- z. AI GLM 5 (Feb 12)
\- MiniMax M2.5 (Feb 12)
\- ByteDance Seed-2.0 (Feb 13)
\- Nanbeige 4.1 3B (Feb 13)
\- Qwen 3.5 (Feb 15)
\- Cohere's Tiny Aya (Feb 17)

(+Hopefully DeepSeek V4 soon)

Anything I forgot?

35

53

729

[![](https://nitter.net/pic/profile_images%2F1803756314469847040%2FXn7-ka2P_bigger.jpg)](https://nitter.net/TheZachMueller)

[Zach Mueller](https://nitter.net/TheZachMueller "Zach Mueller")

[@TheZachMueller](https://nitter.net/TheZachMueller "@TheZachMueller")

[23h](https://nitter.net/TheZachMueller/status/2024884335468331338#m "Feb 20, 2026 ¬∑ 4:30 PM UTC")

Good sub thread by Robert on their work improving the oracle (what helps pick the best kernels) üëá

![](https://nitter.net/pic/profile_images%2F1626334950742974465%2FyPqmMi35_mini.jpg)[Robert Shaw](https://nitter.net/robertshaw21 "Robert Shaw") [@robertshaw21](https://nitter.net/robertshaw21 "@robertshaw21")

[23h](https://nitter.net/robertshaw21/status/2024881325212139996#m "Feb 20, 2026 ¬∑ 4:18 PM UTC")

Replying to [@robertshaw21](https://nitter.net/robertshaw21) [@gaunernst](https://nitter.net/gaunernst) [@TheZachMueller](https://nitter.net/TheZachMueller)

That being said, my and [@mgoin\_](https://nitter.net/mgoin_ "Michael Goin")‚Äôs goal with our recent MoE refactor work is to encode the best kernel selection into vLLM so that users do not need to manually tune. If you see anything that looks off with out of the box performance please open an issue or ping on slack!

4

[![](https://nitter.net/pic/profile_images%2F1890090485370265600%2FOvqR_8Qo_bigger.jpg)](https://nitter.net/leveredvlad)

[Ori Eldarov](https://nitter.net/leveredvlad "Ori Eldarov")

[@leveredvlad](https://nitter.net/leveredvlad "@leveredvlad")

[23h](https://nitter.net/leveredvlad/status/2024884312361812016#m "Feb 20, 2026 ¬∑ 4:30 PM UTC")

I think the most obvious near-term first-order impact of AI on investment banking is the loss of the entire "Analyst" role. At a minimum it will be merged with that of an "Associate".

Still wrapping my head around the pedagogy - a lot of the learning on the job was "wax on wax off". How do you learn if AI is doing the analysis?

11

40

[![](https://nitter.net/pic/profile_images%2F1620194266533199874%2FrCtE0hYR_bigger.jpg)](https://nitter.net/skirano)

[Pietro Schirano](https://nitter.net/skirano "Pietro Schirano")

[@skirano](https://nitter.net/skirano "@skirano")

[Feb 20](https://nitter.net/skirano/status/2024875637878526109#m "Feb 20, 2026 ¬∑ 3:55 PM UTC")

Gemini 3.1 Pro is the best model in the world for going from image to code.

This task is basically solved now, kind of crazy.

The model is now available in [@MagicPathAI](https://nitter.net/MagicPathAI "MagicPath").

![](https://nitter.net/pic/amplify_video_thumb%2F2024875451278135296%2Fimg%2FU4F5UZl1QIm4Gisi.jpg%3Fname%3Dsmall%26format%3Dwebp)

Enable hls playback

61

94

1,543

[![](https://nitter.net/pic/profile_images%2F1831321531852496896%2F1yBZG884_bigger.jpg)](https://nitter.net/_philschmid)

[Philipp Schmid](https://nitter.net/_philschmid "Philipp Schmid")

[@\_philschmid](https://nitter.net/_philschmid "@_philschmid")

[23h](https://nitter.net/_philschmid/status/2024883973445374057#m "Feb 20, 2026 ¬∑ 4:28 PM UTC")

Really nice example!

1

1

11

[![](https://nitter.net/pic/profile_images%2F1287206199088173057%2FixE4fKy1_bigger.jpg)](https://nitter.net/HamelHusain)

[Hamel Husain](https://nitter.net/HamelHusain "Hamel Husain")

[@HamelHusain](https://nitter.net/HamelHusain "@HamelHusain")

[23h](https://nitter.net/HamelHusain/status/2024883649196556516#m "Feb 20, 2026 ¬∑ 4:27 PM UTC")

I think data science is the most underrated skill in AI.

I think we will see a return of the data scientist

It's clear we will have increasingly complex, stochastic systems that will require data literacy, such as:

\- How to sample, interpret, clean data to find issues
\- How to design metrics that help maintain back pressure and prevent drift
\- How to design experiments

![](https://nitter.net/pic/profile_images%2F1998877988545273857%2F0sEbeyue_mini.jpg)[Ege Altan](https://nitter.net/egealtan "Ege Altan")

[@egealtan](https://nitter.net/egealtan "@egealtan")

[Feb 20](https://nitter.net/egealtan/status/2024850362088440042#m "Feb 20, 2026 ¬∑ 2:15 PM UTC")

Data scientists spent the last 3 years watching prompt engineers and vibe coders get the spotlight.

Meanwhile, they quietly mastered the skills that matter most for solving the remaining hard problems in AI: knowing what to measure and why.

That patience is about to pay dividends.

Full post below:

[![](https://nitter.net/pic/media%2FHBm2rD6aQAABSSs.png%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBm2rD6aQAABSSs.png)

14

16

115

[![](https://nitter.net/pic/profile_images%2F2017015061454438400%2FiNKfXZ_I_bigger.jpg)](https://nitter.net/arena)

[Arena.ai](https://nitter.net/arena "Arena.ai")

[@arena](https://nitter.net/arena "@arena")

[23h](https://nitter.net/arena/status/2024883614249615394#m "Feb 20, 2026 ¬∑ 4:27 PM UTC")

Claude Sonnet 4.6 has landed #3 in Code and #13 in Text Arena!

Highlights:
‚ñ™Ô∏è+130 pts jump in Code Arena (#22 -> #3) compared to Sonnet 4.5, surpassing top-tier thinking models like Gemini-3.1 and GPT-5.2

‚ñ™Ô∏èStrong gains in Text categories: Math (#4) and Instruction Following (#5), Overall (#13)

Congrats to the [@AnthropicAI](https://nitter.net/AnthropicAI "Anthropic") team on another impressive milestone!

[![](https://nitter.net/pic/media%2FHBnQqe6bkAA1Tpd.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBnQqe6bkAA1Tpd.jpg)

![](https://nitter.net/pic/profile_images%2F1950950107937185792%2FQOfEjFoJ_mini.jpg)[Claude](https://nitter.net/claudeai "Claude")

[@claudeai](https://nitter.net/claudeai "@claudeai")

[Feb 17](https://nitter.net/claudeai/status/2023817132581208353#m "Feb 17, 2026 ¬∑ 5:49 PM UTC")

This is Claude Sonnet 4.6: our most capable Sonnet model yet.

It‚Äôs a full upgrade across coding, computer use, long-context reasoning, agent planning, knowledge work, and design.

It also features a 1M token context window in beta.

![](https://nitter.net/pic/media%2FHBYMPQSaEAAbP8J.jpg%3Fname%3Dsmall%26format%3Dwebp)

Enable hls playback

10

15

201

[![](https://nitter.net/pic/profile_images%2F2017015061454438400%2FiNKfXZ_I_bigger.jpg)](https://nitter.net/arena)

[Arena.ai](https://nitter.net/arena "Arena.ai")

[@arena](https://nitter.net/arena "@arena")

[23h](https://nitter.net/arena/status/2024883617097470269#m "Feb 20, 2026 ¬∑ 4:27 PM UTC")

Claude Sonnet 4.6 ranks #13 for Text (scoring 1457), on par with GPT-5.1-high with strong gains in Text categories: Math (#4) and Instruction Following (#5), Overall (#13)

[![](https://nitter.net/pic/media%2FHBnQs2SbEAAVhpk.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBnQs2SbEAAVhpk.jpg)

1

1

17

[![](https://nitter.net/pic/profile_images%2F2017015061454438400%2FiNKfXZ_I_bigger.jpg)](https://nitter.net/arena)

[Arena.ai](https://nitter.net/arena "Arena.ai")

[@arena](https://nitter.net/arena "@arena")

[23h](https://nitter.net/arena/status/2024883618989080787#m "Feb 20, 2026 ¬∑ 4:27 PM UTC")

Check out Claude Sonnet 4.6 on the Code Arena leaderboard for WebDev at: [arena.ai/leaderboard/code](https://arena.ai/leaderboard/code)

[**Code AI Leaderboard - Best AI Models for Coding** \\
\\
Compare the best AI models for coding, programming, and software development using real LLM benchmarks.\\
\\
arena.ai](https://arena.ai/leaderboard/code)

8

Google Gemini retweeted

[![](https://nitter.net/pic/profile_images%2F1972718204565811200%2FadTFhODz_bigger.jpg)](https://nitter.net/Google)

[Google](https://nitter.net/Google "Google")

[@Google](https://nitter.net/Google "@Google")

[Feb 19](https://nitter.net/Google/status/2024507510246293661#m "Feb 19, 2026 ¬∑ 3:32 PM UTC")

Our new Google AI Professional Certificate from [#GrowWithGoogle](https://nitter.net/search?f=tweets&q=%23GrowWithGoogle) features 20+ hands-on labs designed to help you use AI as a partner in your daily work.

You‚Äôll learn how to:

‚úîÔ∏è Build project plans and daily workflows
‚úîÔ∏è Vibe code custom AI applications for your job
‚úîÔ∏è Generate custom marketing and creative assets
‚úîÔ∏è Develop data-backed market research

![](https://nitter.net/pic/media%2FHBh-2gTXgAA3teA.jpg%3Fname%3Dsmall%26format%3Dwebp)

Enable hls playback

66

333

2,599

Hamel Husain retweeted

[![](https://nitter.net/pic/profile_images%2F1996406365125005312%2FLjQz6KGT_bigger.jpg)](https://nitter.net/randal_olson)

[Randy Olson](https://nitter.net/randal_olson "Randy Olson")

[@randal\_olson](https://nitter.net/randal_olson "@randal_olson")

[Feb 20](https://nitter.net/randal_olson/status/2024846512891789637#m "Feb 20, 2026 ¬∑ 2:00 PM UTC")

In¬†November 2025, AI coding tools¬†crossed a threshold. The shift was real¬†and it happened fast.

To make¬†it visible, I ran 22¬†models on the same prompt, five times¬†each: build a working analog clock from¬†scratch using HTML, CSS, and JavaScript. Oldest models to newest. Same¬†prompt. Same conditions.

That¬†image¬†shows¬†GPT-4o vs. Claude¬†Opus 4.5. The difference¬†speaks for itself.

A working analog¬†clock is a surprisingly good benchmark. The¬†model has to understand what "analog" means, render a proper clock face, position three hands correctly, and animate them¬†every second. Getting that right consistently across¬†five independent runs is a real bar to¬†clear.

Scroll through all¬†22 models at the link below. You can see exactly where the shift happens.

[goodeyelabs.com/insights/nov‚Ä¶](https://www.goodeyelabs.com/insights/november-2025-ai-coding-surprise)

[![](https://nitter.net/pic/media%2FHBlvlumaYAAFJej.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBlvlumaYAAFJej.jpg)

40

57

371

Zach Mueller retweeted

[![](https://nitter.net/pic/profile_images%2F1626334950742974465%2FyPqmMi35_bigger.jpg)](https://nitter.net/robertshaw21)

[Robert Shaw](https://nitter.net/robertshaw21 "Robert Shaw") [@robertshaw21](https://nitter.net/robertshaw21 "@robertshaw21")

[23h](https://nitter.net/robertshaw21/status/2024878025435713658#m "Feb 20, 2026 ¬∑ 4:05 PM UTC")

Replying to [@gaunernst](https://nitter.net/gaunernst) [@TheZachMueller](https://nitter.net/TheZachMueller)

Minimax‚Äôs Router is somewhat unique (e score bias without grouped topk) and it is BlockFP8 - unfortunately there is not a kernel that supports both of these besides Triton and DeepGEMM on B200 right now. For most other models + precisions Triton will not be the best option

1

1

6

[![](https://nitter.net/pic/profile_images%2F939313677647282181%2FvZjFWtAn_bigger.jpg)](https://nitter.net/omarsar0)

[elvis](https://nitter.net/omarsar0 "elvis")

[@omarsar0](https://nitter.net/omarsar0 "@omarsar0")

[23h](https://nitter.net/omarsar0/status/2024878980952924352#m "Feb 20, 2026 ¬∑ 4:09 PM UTC")

As we move toward deploying autonomous agents in social systems, understanding emergent collective behavior is crucial.

Individual capability benchmarks tell you nothing about what happens when hundreds of these agents interact.

So what happens when you deploy hundreds of LLM agents into social dilemmas?

This new research builds an evaluation framework to test the collective behavior of LLM agent populations at scale, far beyond the small groups tested in prior work.

Newer, more capable models tend to produce worse societal outcomes. Agents optimizing for individual benefit over collective good drive populations toward poor equilibria.

Using cultural evolution simulations, the researchers show a significant risk of convergence to bad societal outcomes, especially as populations grow larger and cooperation becomes less advantageous.

Paper: [arxiv.org/abs/2602.16662](https://arxiv.org/abs/2602.16662)

Learn to build effective AI agents in our academy: [academy.dair.ai/](https://academy.dair.ai/)

[![](https://nitter.net/pic/media%2FHBnQs6EawAAF92F.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBnQs6EawAAF92F.jpg)

12

33

175

clem ü§ó retweeted

[![](https://nitter.net/pic/profile_images%2F1847376145198759936%2FyWcBBfy8_bigger.jpg)](https://nitter.net/alekgrygier)

[Alek Grygier](https://nitter.net/alekgrygier "Alek Grygier") [@alekgrygier](https://nitter.net/alekgrygier "@alekgrygier")

[Feb 20](https://nitter.net/alekgrygier/status/2024848115967164719#m "Feb 20, 2026 ¬∑ 2:06 PM UTC")

This is 100x better than [@openclaw](https://nitter.net/openclaw "OpenClawü¶û") acquisition by not-so- [@OpenAI](https://nitter.net/OpenAI "OpenAI") . Change my mind.

![](https://nitter.net/pic/profile_images%2F1654097134315098113%2FzCZD0wYz_mini.jpg)[Georgi Gerganov](https://nitter.net/ggerganov "Georgi Gerganov")

[@ggerganov](https://nitter.net/ggerganov "@ggerganov")

[Feb 20](https://nitter.net/ggerganov/status/2024839991482777976#m "Feb 20, 2026 ¬∑ 1:34 PM UTC")

Today [ggml.ai](http://ggml.ai/) joins Hugging Face

Together we will continue to build ggml, make llama.cpp more accessible and empower the open-source community. Our joint mission is to make local AI easy and efficient to use by everyone on their own hardware.

3

31

[![](https://nitter.net/pic/profile_images%2F939313677647282181%2FvZjFWtAn_bigger.jpg)](https://nitter.net/omarsar0)

[elvis](https://nitter.net/omarsar0 "elvis")

[@omarsar0](https://nitter.net/omarsar0 "@omarsar0")

[Feb 20](https://nitter.net/omarsar0/status/2024864635120451588#m "Feb 20, 2026 ¬∑ 3:12 PM UTC")

Something strange is happening with AI agents that this new Anthropic research quietly surfaces.

The agents are asking us for help more than we're stepping in to correct \*them\*.

Anthropic analyzed data from Claude Code and their public API to measure how autonomous AI agents actually are in practice. The headline finding is what you'd expect. Agents are running longer (sessions nearly doubled, from 25 to 45 minutes), and experienced users approve more actions automatically. All that's great!

But here's the part worth sitting with. Claude Code stops to ask for clarification more than twice as often as humans manually intervene. The agent is, in a real sense, more cautious about its own limits than its operators are. That's a weird inversion of the usual AI safety framing, where we assume the human is the responsible one pumping the brakes.

The practical safety numbers are reassuring on the surface. 80% of tool calls have at least one safeguard; only 0.8% of actions are irreversible. But I think the more important finding is buried in the recommendation. They argue that effective oversight "doesn't require approving every action but being in a position to intervene when it matters." That's a subtle but significant shift.

The research argues that experienced users stay vigilant even with auto-approve on. Maybe. But as sessions get longer and approval becomes muscle memory, the gap between being in a position to intervene and not paying attention starts to collapse.

[![](https://nitter.net/pic/media%2FHBnDp2DacAAIy6e.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBnDp2DacAAIy6e.jpg)

25

14

115

[![](https://nitter.net/pic/profile_images%2F939313677647282181%2FvZjFWtAn_bigger.jpg)](https://nitter.net/omarsar0)

[elvis](https://nitter.net/omarsar0 "elvis")

[@omarsar0](https://nitter.net/omarsar0 "@omarsar0")

[23h](https://nitter.net/omarsar0/status/2024878454383026508#m "Feb 20, 2026 ¬∑ 4:06 PM UTC")

source:

![](https://nitter.net/pic/profile_images%2F1798110641414443008%2FXP8gyBaY_mini.jpg)[Anthropic](https://nitter.net/AnthropicAI "Anthropic")

[@AnthropicAI](https://nitter.net/AnthropicAI "@AnthropicAI")

[Feb 18](https://nitter.net/AnthropicAI/status/2024210035480678724#m "Feb 18, 2026 ¬∑ 7:50 PM UTC")

New Anthropic research: Measuring AI agent autonomy in practice.

We analyzed millions of interactions across Claude Code and our API to understand how much autonomy people grant to agents, where they‚Äôre deployed, and what risks they may pose.

Read more: [anthropic.com/research/measu‚Ä¶](https://www.anthropic.com/research/measuring-agent-autonomy)

1

1

6

sarah guo retweeted

[![](https://nitter.net/pic/profile_images%2F1735286803777683456%2F3F_Hr4iA_bigger.jpg)](https://nitter.net/EvidenceOpen)

[OpenEvidence](https://nitter.net/EvidenceOpen "OpenEvidence")

[@EvidenceOpen](https://nitter.net/EvidenceOpen "@EvidenceOpen")

[11 Dec 2025](https://nitter.net/EvidenceOpen/status/1999213928048705564#m "Dec 11, 2025 ¬∑ 8:25 PM UTC")

In Offcall's new 2025 report surveying 1,000 doctors: 44% now use OpenEvidence daily. It's the clear #1 by a mile.
The report sums it up perfectly: "Physicians are adopting AI on their own, often using personal subscriptions to the hottest AI tools, because their organizations can't move fast enough."
Clinicians are voting with their keyboards.
Powerful data from [@grahamwalker](https://nitter.net/grahamwalker "Graham Walker, MD") and [@OffCallDotCom](https://nitter.net/OffCallDotCom "Offcall")

[![](https://nitter.net/pic/media%2FG76iKU9a4AANmtE.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FG76iKU9a4AANmtE.jpg)

![](https://nitter.net/pic/profile_images%2F1863760357594218496%2FCPl51HPd_mini.png)[Offcall](https://nitter.net/OffCallDotCom "Offcall")

[@OffCallDotCom](https://nitter.net/OffCallDotCom "@OffCallDotCom")

[11 Dec 2025](https://nitter.net/OffCallDotCom/status/1999135837301461252#m "Dec 11, 2025 ¬∑ 3:15 PM UTC")

üö® NEWS! Today, we‚Äôre dropping Offcall‚Äôs 2025 Physicians AI Report‚Ä¶

We asked physicians what AI tools they‚Äôre actually using, what they actually think will happen to the medical profession, whether they‚Äôre more or less likely to quit medicine because of AI, & more.

And the results? Are surprising and explosive.

Explore the full report and download it here: [2025-physicians-ai-report.of‚Ä¶](https://2025-physicians-ai-report.offcall.com/) [#PhysicianVoices](https://nitter.net/search?f=tweets&q=%23PhysicianVoices) [#AIinMedicine](https://nitter.net/search?f=tweets&q=%23AIinMedicine) [#OffcallWhitepaper](https://nitter.net/search?f=tweets&q=%23OffcallWhitepaper) [#HealthcareInnovation](https://nitter.net/search?f=tweets&q=%23HealthcareInnovation) [#ClinicianLedTech](https://nitter.net/search?f=tweets&q=%23ClinicianLedTech) [#PhysicianTools](https://nitter.net/search?f=tweets&q=%23PhysicianTools) [#2025AIReport](https://nitter.net/search?f=tweets&q=%232025AIReport)

[![](https://nitter.net/pic/media%2FG75XsGSWYAAQyXf.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FG75XsGSWYAAQyXf.jpg)

[![](https://nitter.net/pic/media%2FG75XsGOW4AAFMme.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FG75XsGOW4AAFMme.jpg)

[![](https://nitter.net/pic/media%2FG75XthnWEAAJYOl.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FG75XthnWEAAJYOl.jpg)

[![](https://nitter.net/pic/media%2FG75XthmXMAApXlf.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FG75XthmXMAApXlf.jpg)

7

15

55

[![](https://nitter.net/pic/profile_images%2F1643277398522187778%2F31dedbLo_bigger.jpg)](https://nitter.net/dair_ai)

[DAIR.AI](https://nitter.net/dair_ai "DAIR.AI")

[@dair\_ai](https://nitter.net/dair_ai "@dair_ai")

[23h](https://nitter.net/dair_ai/status/2024878225017668091#m "Feb 20, 2026 ¬∑ 4:06 PM UTC")

Training LLM agents for extremely long-horizon tasks remains an open challenge.

Most agent training pipelines struggle with extended-duration trajectories.

Context gets lost, rewards are sparse, and the learning signal degrades over long sequences.

KLong tackles this with a two-phase approach: trajectory-splitting supervised fine-tuning that preserves early context while progressively truncating later context, followed by progressive RL that schedules training into stages with extended timeouts.

They also built a Research-Factory pipeline that automatically generates thousands of long-horizon training trajectories from Claude 4.5 Sonnet.

The 106B-parameter KLong model outperforms Kimi K2 Thinking (1T) by 11.28% on PaperBench, with gains generalizing to SWE-bench Verified and MLE-bench.

Paper: [arxiv.org/abs/2602.17547](https://arxiv.org/abs/2602.17547)

Learn to build effective AI agents in our academy: [academy.dair.ai/](https://academy.dair.ai/)

[![](https://nitter.net/pic/media%2FHBnQA7RbQAALhVL.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBnQA7RbQAALhVL.jpg)

7

15

127

[![](https://nitter.net/pic/profile_images%2F1875100548535574529%2FVxHk9HyU_bigger.jpg)](https://nitter.net/MiniMax_AI)

[MiniMax (official)](https://nitter.net/MiniMax_AI "MiniMax (official)")

[@MiniMax\_AI](https://nitter.net/MiniMax_AI "@MiniMax_AI")

[23h](https://nitter.net/MiniMax_AI/status/2024877880971554850#m "Feb 20, 2026 ¬∑ 4:04 PM UTC")

3-TRILLION in one weekü´®üöÄ

![](https://nitter.net/pic/profile_images%2F1887176916849074178%2FkjnDV4rw_mini.jpg)[Alex Atallah](https://nitter.net/alexatallah "Alex Atallah")

[@alexatallah](https://nitter.net/alexatallah "@alexatallah")

[Feb 20](https://nitter.net/alexatallah/status/2024859608221708607#m "Feb 20, 2026 ¬∑ 2:52 PM UTC")

Some updates from our internal Slack agent that watches [openrouter.ai/rankings](http://openrouter.ai/rankings) [@MiniMax\_AI](https://nitter.net/MiniMax_AI "MiniMax (official)") is the first model to break 3 trillion tokens in a week!

and [@cline](https://nitter.net/cline "Cline") is jumping up to #3

[![](https://nitter.net/pic/media%2FHBm-mXJXUAI1ts3.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBm-mXJXUAI1ts3.jpg)

23

10

489

clem ü§ó retweeted

[![](https://nitter.net/pic/profile_images%2F378800000261649705%2Fbe9cc55e64014e6d7663c50d7cb9fc75_bigger.jpeg)](https://nitter.net/simonw)

[Simon Willison](https://nitter.net/simonw "Simon Willison")

[@simonw](https://nitter.net/simonw "@simonw")

[Feb 20](https://nitter.net/simonw/status/2024855027517702345#m "Feb 20, 2026 ¬∑ 2:33 PM UTC")

Georgi's llama.cpp really kicked off the whole local model thing in my opinion - it made original Llama usable on personal computers, I wrote about it back in March 2023 [simonwillison.net/2023/Mar/1‚Ä¶](https://simonwillison.net/2023/Mar/11/llama/#llama-cpp)

[![llama.cpp # LLaMA on its own isn‚Äôt much good if it‚Äôs still too hard to run it on a personal laptop.  Enter Georgi Gerganov.  Georgi is an open source developer based in Sofia, Bulgaria (according to his GitHub profile). He previously released whisper.cpp, a port of OpenAI‚Äôs Whisper automatic speech recognition model to C++. That project made Whisper applicable to a huge range of new use cases.  He‚Äôs just done the same thing with LLaMA.  Georgi‚Äôs llama.cpp project had its initial release yesterday. From the README:  The main goal is to run the model using 4-bit quantization on a MacBook.  4-bit quantization is a technique for reducing the size of models so they can run on less powerful hardware. It also reduces the model sizes on disk‚Äîto 4GB for the 7B model and just under 8GB for the 13B one.  It totally works!  I used it to run the 7B LLaMA model on my laptop last night, and then this morning upgraded to the 13B model‚Äîthe one that Facebook claim is competitive with GPT-3.](https://nitter.net/pic/media%2FHBm66bZbYAAKBU6.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBm66bZbYAAKBU6.jpg)

ALT llama.cpp #
LLaMA on its own isn‚Äôt much good if it‚Äôs still too hard to run it on a personal laptop.

Enter Georgi Gerganov.

Georgi is an open source developer based in Sofia, Bulgaria (according to his GitHub profile). He previously released whisper.cpp, a port of OpenAI‚Äôs Whisper automatic speech recognition model to C++. That project made Whisper applicable to a huge range of new use cases.

He‚Äôs just done the same thing with LLaMA.

Georgi‚Äôs llama.cpp project had its initial release yesterday. From the README:

The main goal is to run the model using 4-bit quantization on a MacBook.

4-bit quantization is a technique for reducing the size of models so they can run on less powerful hardware. It also reduces the model sizes on disk‚Äîto 4GB for the 7B model and just under 8GB for the 13B one.

It totally works!

I used it to run the 7B LLaMA model on my laptop last night, and then this morning upgraded to the 13B model‚Äîthe one that Facebook claim is competitive with GPT-3.

![](https://nitter.net/pic/profile_images%2F1654097134315098113%2FzCZD0wYz_mini.jpg)[Georgi Gerganov](https://nitter.net/ggerganov "Georgi Gerganov")

[@ggerganov](https://nitter.net/ggerganov "@ggerganov")

[Feb 20](https://nitter.net/ggerganov/status/2024839991482777976#m "Feb 20, 2026 ¬∑ 1:34 PM UTC")

Today [ggml.ai](http://ggml.ai/) joins Hugging Face

Together we will continue to build ggml, make llama.cpp more accessible and empower the open-source community. Our joint mission is to make local AI easy and efficient to use by everyone on their own hardware.

22

35

441

Leandro von Werra retweeted

[![](https://nitter.net/pic/profile_images%2F1756691514787336192%2F2aGUuljm_bigger.jpg)](https://nitter.net/ummagumm_a)

[Viacheslav Sinii](https://nitter.net/ummagumm_a "Viacheslav Sinii") [@ummagumm\_a](https://nitter.net/ummagumm_a "@ummagumm_a")

[Feb 19](https://nitter.net/ummagumm_a/status/2024537502883717308#m "Feb 19, 2026 ¬∑ 5:32 PM UTC")

1/ üßµ Reproducing Anthropic‚Äôs ‚Äúcounting manifold‚Äù result in¬†open-weight LLMs: do they internally track¬†‚Äúchars since last \\n‚Äù to wrap text consistently?

[huggingface.co/spaces/t-tech‚Ä¶](https://huggingface.co/spaces/t-tech/manifolds)

[![](https://nitter.net/pic/media%2FHBiaIJTWMAAuYAR.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBiaIJTWMAAuYAR.jpg)

3

29

219

[![](https://nitter.net/pic/profile_images%2F1894073235379273728%2F0ROUmdkE_bigger.jpg)](https://nitter.net/Alibaba_Qwen)

[Qwen](https://nitter.net/Alibaba_Qwen "Qwen")

[@Alibaba\_Qwen](https://nitter.net/Alibaba_Qwen "@Alibaba_Qwen")

[Feb 20](https://nitter.net/Alibaba_Qwen/status/2024877243072147689#m "Feb 20, 2026 ¬∑ 4:02 PM UTC")

Following the open-source release of Qwen3-Coder-Next, its API is now available on Alibaba Cloud Model Studio and has also been integrated into the Coding Plan.
For teams and developers who prefer scalable or cost-effective endpoints, you can now access Qwen3-Coder-Next via API.
üîó API Documentation:
[modelstudio.console.alibabac‚Ä¶](https://modelstudio.console.alibabacloud.com/ap-southeast-1?tab=doc#/doc/?type=model&url=2840914_2&modelId=qwen3)
üîó Coding Plan Details:
[alibabacloud.com/help/en/mod‚Ä¶](https://www.alibabacloud.com/help/en/model-studio/coding-plan)
As always, feedback is welcome.

21

35

491

[![](https://nitter.net/pic/profile_images%2F1672707817197965312%2FzsxkJv_T_bigger.jpg)](https://nitter.net/TheRundownAI)

[The Rundown AI](https://nitter.net/TheRundownAI "The Rundown AI")

[@TheRundownAI](https://nitter.net/TheRundownAI "@TheRundownAI")

[Feb 20](https://nitter.net/TheRundownAI/status/2024876995343958367#m "Feb 20, 2026 ¬∑ 4:01 PM UTC")

Top stories in tech today:

\- Zuck defends Instagram in landmark trial
\- Microsoft turns glass into a 10K-year hard drive
\- Feds charge 3 engineers in Google chip theft
\- Stanford‚Äôs new do-it-all respiratory vaccine
\- Quick hits on other tech news

[![](https://nitter.net/pic/media%2FHBnO5PbWwAACaTD.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBnO5PbWwAACaTD.jpg)

4

2

13

[![](https://nitter.net/pic/profile_images%2F1672707817197965312%2FzsxkJv_T_bigger.jpg)](https://nitter.net/TheRundownAI)

[The Rundown AI](https://nitter.net/TheRundownAI "The Rundown AI")

[@TheRundownAI](https://nitter.net/TheRundownAI "@TheRundownAI")

[Feb 20](https://nitter.net/TheRundownAI/status/2024876998749724911#m "Feb 20, 2026 ¬∑ 4:01 PM UTC")

Read more: [tech.therundown.ai/p/zuck-vs‚Ä¶](https://tech.therundown.ai/p/zuck-vs-instagram-addiction)

[![](https://nitter.net/pic/card_img%2F2024877041254875138%2F5ClLFPmU%3Fformat%3Djpg%26name%3D800x419)\\
\\
**Zuck vs. Instagram addiction** \\
\\
PLUS: Microsoft's glass storage could last for millennia\\
\\
tech.therundown.ai](https://tech.therundown.ai/p/zuck-vs-instagram-addiction)

3

[![](https://nitter.net/pic/profile_images%2F1810946341511766016%2F3mg9KIaQ_bigger.jpg)](https://nitter.net/ArtificialAnlys)

[Artificial Analysis](https://nitter.net/ArtificialAnlys "Artificial Analysis")

[@ArtificialAnlys](https://nitter.net/ArtificialAnlys "@ArtificialAnlys")

[Feb 20](https://nitter.net/ArtificialAnlys/status/2024876729538687202#m "Feb 20, 2026 ¬∑ 4:00 PM UTC")

Want to generate images from the world's best models like Nano Banana or GPT Image side by side? Now you can with Image Lab üöÄ

Run a single prompt across up to 25 models, with up to 20 images from each, and see results in seconds.

You've seen our leaderboards. Now generate and evaluate the models yourself. Link in thread üßµüëá

![](https://nitter.net/pic/amplify_video_thumb%2F2024699901750497291%2Fimg%2FSMSF2AkjJS6_6CAw.jpg%3Fname%3Dsmall%26format%3Dwebp)

Enable hls playback

4

8

106

[![](https://nitter.net/pic/profile_images%2F1810946341511766016%2F3mg9KIaQ_bigger.jpg)](https://nitter.net/ArtificialAnlys)

[Artificial Analysis](https://nitter.net/ArtificialAnlys "Artificial Analysis")

[@ArtificialAnlys](https://nitter.net/ArtificialAnlys "@ArtificialAnlys")

[Feb 20](https://nitter.net/ArtificialAnlys/status/2024876731371565532#m "Feb 20, 2026 ¬∑ 4:00 PM UTC")

Try it for free ‚Üí [artificialanalysis.ai/image/‚Ä¶](https://artificialanalysis.ai/image/image-lab)

1

10

[![](https://nitter.net/pic/profile_images%2F1654097134315098113%2FzCZD0wYz_bigger.jpg)](https://nitter.net/ggerganov)

[Georgi Gerganov](https://nitter.net/ggerganov "Georgi Gerganov")

[@ggerganov](https://nitter.net/ggerganov "@ggerganov")

[Feb 20](https://nitter.net/ggerganov/status/2024839991482777976#m "Feb 20, 2026 ¬∑ 1:34 PM UTC")

Today [ggml.ai](http://ggml.ai/) joins Hugging Face

Together we will continue to build ggml, make llama.cpp more accessible and empower the open-source community. Our joint mission is to make local AI easy and efficient to use by everyone on their own hardware.

![](https://nitter.net/pic/profile_images%2F1654097134315098113%2FzCZD0wYz_mini.jpg)[Georgi Gerganov](https://nitter.net/ggerganov "Georgi Gerganov")

[@ggerganov](https://nitter.net/ggerganov "@ggerganov")

[6 Jun 2023](https://nitter.net/ggerganov/status/1666120568993730561#m "Jun 6, 2023 ¬∑ 4:31 PM UTC")

I've started a company: [ggml.ai](http://ggml.ai/)

From a fun side project just a few months ago, ggml has now become a useful library and framework for machine learning with a great open-source community

128

214

1,406

[![](https://nitter.net/pic/profile_images%2F1676696716693700608%2Ft4kv-MrC_bigger.jpg)](https://nitter.net/osanseviero)

[Omar Sanseviero](https://nitter.net/osanseviero "Omar Sanseviero")

[@osanseviero](https://nitter.net/osanseviero "@osanseviero")

[Feb 20](https://nitter.net/osanseviero/status/2024876685926281465#m "Feb 20, 2026 ¬∑ 3:59 PM UTC")

Congratulations to you and all the ggml and Hugging Face team!

This is a natural and exciting transition and I'm looking forward to how your contributions to the ecosystem keep growing!

1

17

Satya Mallick retweeted

[![](https://nitter.net/pic/profile_images%2F1733487310728024064%2FAh_NBQlM_bigger.jpg)](https://nitter.net/DimitrisPapail)

[Dimitris Papailiopoulos](https://nitter.net/DimitrisPapail "Dimitris Papailiopoulos")

[@DimitrisPapail](https://nitter.net/DimitrisPapail "@DimitrisPapail")

[Feb 19](https://nitter.net/DimitrisPapail/status/2024555561199480918#m "Feb 19, 2026 ¬∑ 6:43 PM UTC")

[x.com/i/article/202454779264‚Ä¶](http://x.com/i/article/2024547792648359937)

57

162

1,298

Synthesia üé• retweeted

[![](https://nitter.net/pic/profile_images%2F1825121831868616704%2Ffuy9hj0W_bigger.jpg)](https://nitter.net/thealexbanks)

[Alex Banks](https://nitter.net/thealexbanks "Alex Banks")

[@thealexbanks](https://nitter.net/thealexbanks "@thealexbanks")

[Feb 20](https://nitter.net/thealexbanks/status/2024848611003990471#m "Feb 20, 2026 ¬∑ 2:08 PM UTC")

Creating your own AI avatar is now ridiculously simple.

All you need is one photo.

![](https://nitter.net/pic/amplify_video_thumb%2F2024848320619814912%2Fimg%2FsskYJX7Avp5mFEG4.jpg%3Fname%3Dsmall%26format%3Dwebp)

Enable hls playback

6

2

4

[![](https://nitter.net/pic/profile_images%2F1715797038535680000%2FZFrYnYWD_bigger.jpg)](https://nitter.net/SchmidhuberAI)

[J√ºrgen Schmidhuber](https://nitter.net/SchmidhuberAI "J√ºrgen Schmidhuber")

[@SchmidhuberAI](https://nitter.net/SchmidhuberAI "@SchmidhuberAI")

[Feb 20](https://nitter.net/SchmidhuberAI/status/2024875496056525238#m "Feb 20, 2026 ¬∑ 3:55 PM UTC")

At [#MSC2026](https://nitter.net/search?f=tweets&q=%23MSC2026) in Munich, I enjoyed talking to former US Secretary of State [@HillaryClinton](https://nitter.net/HillaryClinton "Hillary Clinton") about a particular US-Munich connection: the $1 trillion US investments in AI are mostly about scaling up the neural AI techniques published by my AI lab in 1991 at [@TU\_Muenchen](https://nitter.net/TU_Muenchen "TU M√ºnchen") \[1\]\[2\]

References (easy to find on the web):

\[1\] JS (2026). The two most frequently cited papers of all time are based on our 1991 work. Technical Note IDSIA-1-26

\[2\] JS (2022-2025). Annotated History of Modern AI and Deep Learning. TR IDSIA-22-22, arXiv:2212.11279

[![](https://nitter.net/pic/media%2FHBnMgo8bMAAyVLJ.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBnMgo8bMAAyVLJ.jpg)

13

5

101

[![](https://nitter.net/pic/profile_images%2F1451191636810092553%2FkpM5Fe12_bigger.jpg)](https://nitter.net/_akhaliq)

[AK](https://nitter.net/_akhaliq "AK")

[@\_akhaliq](https://nitter.net/_akhaliq "@_akhaliq")

[Feb 20](https://nitter.net/_akhaliq/status/2024873795173892483#m "Feb 20, 2026 ¬∑ 3:48 PM UTC")

SpargeAttention2

Trainable Sparse Attention via Hybrid Top-k+Top-p Masking and Distillation Fine-Tuning

paper: [huggingface.co/papers/2602.1‚Ä¶](https://huggingface.co/papers/2602.13515)

[![](https://nitter.net/pic/media%2FHBnL8IvXUAA-oK4.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBnL8IvXUAA-oK4.jpg)

2

11

77

Lisan al Gaib retweeted

[![](https://nitter.net/pic/abs.twimg.com%2Fsticky%2Fdefault_profile_images%2Fdefault_profile_bigger.png)](https://nitter.net/Hangsiin)

[NomoreID](https://nitter.net/Hangsiin "NomoreID")

[@Hangsiin](https://nitter.net/Hangsiin "@Hangsiin")

[Feb 20](https://nitter.net/Hangsiin/status/2024769838644945312#m "Feb 20, 2026 ¬∑ 8:55 AM UTC")

Demis Hassabis( [@demishassabis](https://nitter.net/demishassabis "Demis Hassabis")) recently said in India that a new Gemma model will be released soon.

"...We work on our own open-source model, Gemma, and we‚Äôll soon release a new version that‚Äôs very powerful for edge devices."

1

7

97

AK retweeted

[![](https://nitter.net/pic/profile_images%2F1991559933473497089%2FmbrRS49P_bigger.jpg)](https://nitter.net/huggingface)

[Hugging Face](https://nitter.net/huggingface "Hugging Face")

[@huggingface](https://nitter.net/huggingface "@huggingface")

[Feb 20](https://nitter.net/huggingface/status/2024871487753044243#m "Feb 20, 2026 ¬∑ 3:39 PM UTC")

Thrilled to have GGML with us going forward! ü§ó‚ù§Ô∏èü¶ô

Read the announcement blog [huggingface.co/blog/ggml-joi‚Ä¶](https://huggingface.co/blog/ggml-joins-hf)

[![](https://nitter.net/pic/media%2FHBnJ4vCW8AAmubV.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBnJ4vCW8AAmubV.jpg)

9

29

182

AK retweeted

[![](https://nitter.net/pic/profile_images%2F1906618607368273920%2F09C2Z22U_bigger.jpg)](https://nitter.net/HuggingPapers)

[DailyPapers](https://nitter.net/HuggingPapers "DailyPapers")

[@HuggingPapers](https://nitter.net/HuggingPapers "@HuggingPapers")

[Feb 20](https://nitter.net/HuggingPapers/status/2024705977425998298#m "Feb 20, 2026 ¬∑ 4:41 AM UTC")

Frontier AI Risk Management Framework v1.5

A comprehensive assessment of frontier AI risks across five dimensions: cyber offense, persuasion, strategic deception, uncontrolled AI R&D, and self-replication. Includes mitigation strategies.

[![](https://nitter.net/pic/media%2FHBkzW2nXcAAG6sk.png%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBkzW2nXcAAG6sk.png)

2

3

12

AK retweeted

[![](https://nitter.net/pic/profile_images%2F1906618607368273920%2F09C2Z22U_bigger.jpg)](https://nitter.net/HuggingPapers)

[DailyPapers](https://nitter.net/HuggingPapers "DailyPapers")

[@HuggingPapers](https://nitter.net/HuggingPapers "@HuggingPapers")

[Feb 20](https://nitter.net/HuggingPapers/status/2024760112293040531#m "Feb 20, 2026 ¬∑ 8:16 AM UTC")

SpargeAttention2

Reaches 95% attention sparsity and 16.2√ó speedup in video diffusion models while maintaining generation quality through hybrid Top-k+Top-p masking and distillation fine-tuning.

[![](https://nitter.net/pic/media%2FHBlkl2obUAElXhn.png%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBlkl2obUAElXhn.png)

1

7

57

AK retweeted

[![](https://nitter.net/pic/profile_images%2F1906618607368273920%2F09C2Z22U_bigger.jpg)](https://nitter.net/HuggingPapers)

[DailyPapers](https://nitter.net/HuggingPapers "DailyPapers")

[@HuggingPapers](https://nitter.net/HuggingPapers "@HuggingPapers")

[Feb 20](https://nitter.net/HuggingPapers/status/2024820231223583164#m "Feb 20, 2026 ¬∑ 12:15 PM UTC")

Unified Latents (UL)

A framework that jointly regularizes encoders with a diffusion prior and decodes with a diffusion model, giving a tight latent bitrate bound and achieving FID 1.4 on ImageNet-512 and FVD 1.3 on Kinetics-600.

[![](https://nitter.net/pic/media%2FHBmbROsa8AAjx61.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBmbROsa8AAjx61.jpg)

1

7

69

AK retweeted

[![](https://nitter.net/pic/profile_images%2F1858913803448020992%2FP8kY_ljY_bigger.png)](https://nitter.net/freddy_alfonso_)

[Freddy A Boulton](https://nitter.net/freddy_alfonso_ "Freddy A Boulton")

[@freddy\_alfonso\_](https://nitter.net/freddy_alfonso_ "@freddy_alfonso_")

[Feb 20](https://nitter.net/freddy_alfonso_/status/2024870425344249926#m "Feb 20, 2026 ¬∑ 3:35 PM UTC")

Wow some of the most cracked engineers on the planet are joining HF!

[![](https://nitter.net/pic/media%2FHBnI1a-XYAAyp5s.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBnI1a-XYAAyp5s.jpg)

1

3

23

max drake retweeted

[![](https://nitter.net/pic/profile_images%2F1998689716229558272%2FGSFU7BiZ_bigger.jpg)](https://nitter.net/steveruizok)

[Steve Ruiz](https://nitter.net/steveruizok "Steve Ruiz")

[@steveruizok](https://nitter.net/steveruizok "@steveruizok")

[Feb 20](https://nitter.net/steveruizok/status/2024845866188546524#m "Feb 20, 2026 ¬∑ 1:57 PM UTC")

Hooked up the thermal printer to print off issues

[![](https://nitter.net/pic/media%2FHBmylRiXEAAeMjY.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBmylRiXEAAeMjY.jpg)

11

13

264

[![](https://nitter.net/pic/profile_images%2F1569345624935485442%2FR67C4wCQ_bigger.jpg)](https://nitter.net/hwchase17)

[Harrison Chase](https://nitter.net/hwchase17 "Harrison Chase")

[@hwchase17](https://nitter.net/hwchase17 "@hwchase17")

[Feb 20](https://nitter.net/hwchase17/status/2024870386299802062#m "Feb 20, 2026 ¬∑ 3:34 PM UTC")

I'm hosting a small dinner with [@jasonyuan](https://nitter.net/jasonyuan "Jason Yuan") next week focused on the intersection of design and ML

In SF, very limited spots. If you are a designer interested in AI, or an ML engineer who cares deeply about design - we'd love to host you!

sign up: [luma.com/d5dw9vzf](https://luma.com/d5dw9vzf)

[![](https://nitter.net/pic/media%2FHBnI3Z2bMAARlwm.png%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBnI3Z2bMAARlwm.png)

12

7

72

[![](https://nitter.net/pic/profile_images%2F1994231484752736256%2FU0xICyKq_bigger.jpg)](https://nitter.net/c_valenzuelab)

[Crist√≥bal Valenzuela](https://nitter.net/c_valenzuelab "Crist√≥bal Valenzuela")

[@c\_valenzuelab](https://nitter.net/c_valenzuelab "@c_valenzuelab")

[Feb 20](https://nitter.net/c_valenzuelab/status/2024869743312720374#m "Feb 20, 2026 ¬∑ 3:32 PM UTC")

It really is the era of bespoke everything. Most industries are one-to-many machines. Not because that‚Äôs what people want, but because that‚Äôs what was affordable/possible. You ship one piece of software for millions. You make one movie for everyone. You design one workflow and force a billion weird edge cases to cosplay as the average user. You need scale just to break even. So we built app stores, catalogs, templates, best practices, etc etc. A museum of one-size-fits-most.

But now, as the cost of making anything converging on the cost of inference, for the first time we can do many things on a one-to-one basis. iow: the marginal cost of building approaches the marginal cost of asking. Hello, brave new world.

You can make a movie for one viewer, tuned to your taste. One song for you to listen to. Not ‚Äúa fitness app,‚Äù but your fitness app. The unit of production becomes the individual. Hyper-customized and specific. This, for me, has been the biggest realization over time about the scale of change. Too common to judge what‚Äôs new in AI through a one-to-many lens. Judge it on the economics of one-to-one.

![](https://nitter.net/pic/profile_images%2F1296667294148382721%2F9Pr6XrPB_mini.jpg)[Andrej Karpathy](https://nitter.net/karpathy "Andrej Karpathy")

[@karpathy](https://nitter.net/karpathy "@karpathy")

[Feb 19](https://nitter.net/karpathy/status/2024583544157458452#m "Feb 19, 2026 ¬∑ 8:35 PM UTC")

Very interested in what the coming era of highly bespoke software might look like.

Example from this morning - I've become a bit loosy goosy with my cardio recently so I decided to do a more srs, regimented experiment to try to lower my Resting Heart Rate from 50 -> 45, over experiment duration of 8 weeks. The primary way to do this is to aspire to a certain sum total minute goals in Zone 2 cardio and 1 HIIT/week.

1 hour later I vibe coded this super custom dashboard for this very specific experiment that shows me how I'm tracking. Claude had to reverse engineer the Woodway treadmill cloud API to pull raw data, process, filter, debug it and create a web UI frontend to track the experiment. It wasn't a fully smooth experience and I had to notice and ask to fix bugs e.g. it screwed up metric vs. imperial system units and it screwed up on the calendar matching up days to dates etc.

But I still feel like the overall direction is clear:
1) There will never be (and shouldn't be) a specific app on the app store for this kind of thing. I shouldn't have to look for, download and use some kind of a "Cardio experiment tracker", when this thing is ~300 lines of code that an LLM agent will give you in seconds. The idea of an "app store" of a long tail of discrete set of apps you choose from feels somehow wrong and outdated when LLM agents can improvise the app on the spot and just for you.
2) Second, the industry has to reconfigure into a set of services of sensors and actuators with agent native ergonomics. My Woodway treadmill is a sensor - it turns physical state into digital knowledge. It shouldn't maintain some human-readable frontend and my LLM agent shouldn't have to reverse engineer it, it should be an API/CLI easily usable by my agent. I'm a little bit disappointed (and my timelines are correspondingly slower) with how slowly this progression is happening in the industry overall. 99% of products/services still don't have an AI-native CLI yet. 99% of products/services maintain .html/.css docs like I won't immediately look for how to copy paste the whole thing to my agent to get something done. They give you a list of instructions on a webpage to open this or that url and click here or there to do a thing. In 2026. What am I a computer? You do it. Or have my agent do it.

So anyway today I am impressed that this random thing took 1 hour (it would have been ~10 hours 2 years ago). But what excites me more is thinking through how this really should have been 1 minute tops. What has to be in place so that it would be 1 minute? So that I could simply say "Hi can you help me track my cardio over the next 8 weeks", and after a very brief Q&A the app would be up. The AI would already have a lot personal context, it would gather the extra needed data, it would reference and search related skill libraries, and maintain all my little apps/automations.

TLDR the "app store" of a set of discrete apps that you choose from is an increasingly outdated concept all by itself. The future are services of AI-native sensors & actuators orchestrated via LLM glue into highly custom, ephemeral apps. It's just not here yet.

[![](https://nitter.net/pic/media%2FHBjB6bhbUAA8_mZ.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBjB6bhbUAA8_mZ.jpg)

4

2

55

[![](https://nitter.net/pic/profile_images%2F1692481211888025600%2FlUJUEO_p_bigger.jpg)](https://nitter.net/dejavucoder)

[sankalp](https://nitter.net/dejavucoder "sankalp")

[@dejavucoder](https://nitter.net/dejavucoder "@dejavucoder")

[Feb 20](https://nitter.net/dejavucoder/status/2024821016590246205#m "Feb 20, 2026 ¬∑ 12:18 PM UTC")

me telling codex to review code written by me and claude

[![](https://nitter.net/pic/media%2FHBmb81Va4AAChjy.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBmb81Va4AAChjy.jpg)

5

14

287

[![](https://nitter.net/pic/profile_images%2F1997389691411423232%2Fcd5pUUPn_bigger.jpg)](https://nitter.net/cto_junior)

[TDM (e/Œª) (L8 vibe coder üí´)](https://nitter.net/cto_junior "TDM (e/Œª) (L8 vibe coder üí´)")

[@cto\_junior](https://nitter.net/cto_junior "@cto_junior")

[Feb 20](https://nitter.net/cto_junior/status/2024860764742566114#m "Feb 20, 2026 ¬∑ 2:56 PM UTC")

code written by you? is this 2024?

1

8

[![](https://nitter.net/pic/profile_images%2F1692481211888025600%2FlUJUEO_p_bigger.jpg)](https://nitter.net/dejavucoder)

[sankalp](https://nitter.net/dejavucoder "sankalp")

[@dejavucoder](https://nitter.net/dejavucoder "@dejavucoder")

[Feb 20](https://nitter.net/dejavucoder/status/2024869685628723662#m "Feb 20, 2026 ¬∑ 3:32 PM UTC")

well i gave the prompts sir

1

8

[![](https://nitter.net/pic/profile_images%2F829414498893123584%2FP6JytwO8_bigger.jpg)](https://nitter.net/awnihannun)

[Awni Hannun](https://nitter.net/awnihannun "Awni Hannun")

[@awnihannun](https://nitter.net/awnihannun "@awnihannun")

[Feb 20](https://nitter.net/awnihannun/status/2024868422224671193#m "Feb 20, 2026 ¬∑ 3:27 PM UTC")

My realistic assessment of something like this:

\- If it costs billions to train a model and even more to serve it, spending tens of millions to tape-out a custom chip which is 10x more efficient¬†(at 1/10th the latency!) makes financial sense

\- One major downside is the latency of the tape-out itself.

\- 2 months is too slow. Minor versions of models change on a quarterly basis or faster right now. Adding 2 months to that isn't yet practical.

\- If it gets down to a couple weeks that could be interesting.

\- Something hybrid might make a lot more sense (base pre-trained model is burned in silicon) but post-trained adapters can be used to modify the model and don't need to be hard-coded. This would require architectural innovations.

![](https://nitter.net/pic/profile_images%2F1765014496030978049%2FdKGNsxFA_mini.jpg)[Taalas Inc.](https://nitter.net/taalas_inc "Taalas Inc.") [@taalas\_inc](https://nitter.net/taalas_inc "@taalas_inc")

[Feb 19](https://nitter.net/taalas_inc/status/2024516399251456150#m "Feb 19, 2026 ¬∑ 4:08 PM UTC")

24 dedicated people.
$30M spent on development.
Extreme specialization, speed, and power efficiency.

Today we launch Taalas‚Äô first product. Check it out:
Details:¬†[taalas.com/the-path-to-ubiqu‚Ä¶](https://taalas.com/the-path-to-ubiquitous-ai/)
Demo chatbot:¬†[chatjimmy.ai](https://chatjimmy.ai/)
API:¬†[taalas.com/api-request-form/](https://taalas.com/api-request-form/)

41

12

279

[![](https://nitter.net/pic/profile_images%2F1650250832909152260%2F760DZ0cv_bigger.png)](https://nitter.net/cohere)

[Cohere](https://nitter.net/cohere "Cohere")

[@cohere](https://nitter.net/cohere "@cohere")

[Feb 20](https://nitter.net/cohere/status/2024868305995981000#m "Feb 20, 2026 ¬∑ 3:26 PM UTC")

The India AI Impact Summit was a week of critical conversations - from scaling frontier AI responsibly to advancing language accessibility. With Tiny Aya‚Äôs launch and the New Delhi commitments, Cohere is committed to driving inclusive, ethical enterprise AI forward.

[![](https://nitter.net/pic/media%2FHBnGdYvXAAAROxc.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBnGdYvXAAAROxc.jpg)

[![](https://nitter.net/pic/media%2FHBnGg3FXMAE2hSd.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBnGg3FXMAE2hSd.jpg)

[![](https://nitter.net/pic/media%2FHBnGpmvXQAAg87A.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBnGpmvXQAAg87A.jpg)

[![](https://nitter.net/pic/media%2FHBnGs-DXQAEFgvI.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBnGs-DXQAEFgvI.jpg)

5

18

192

AK retweeted

[![](https://nitter.net/pic/profile_images%2F1856520026117025796%2FX491CeSo_bigger.jpg)](https://nitter.net/latkins)

[Lucas Atkins](https://nitter.net/latkins "Lucas Atkins")

[@latkins](https://nitter.net/latkins "@latkins")

[Feb 20](https://nitter.net/latkins/status/2024739477948887044#m "Feb 20, 2026 ¬∑ 6:54 AM UTC")

[huggingface.co/papers/2602.1‚Ä¶](https://huggingface.co/papers/2602.17004)

[![](https://nitter.net/pic/card_img%2F2024739477206519808%2FV6zGG6Fi%3Fformat%3Dpng%26name%3D800x419)\\
\\
**Paper page - Arcee Trinity Large Technical Report** \\
\\
Join the discussion on this paper page\\
\\
huggingface.co](https://huggingface.co/papers/2602.17004)

12

66

[![](https://nitter.net/pic/profile_images%2F1600427627499720706%2FmAVRGNAX_bigger.jpg)](https://nitter.net/NerdyRodent)

[Nerdy Rodent üêÄü§ìüíªü™êüö¥](https://nitter.net/NerdyRodent "Nerdy Rodent üêÄü§ìüíªü™êüö¥")

[@NerdyRodent](https://nitter.net/NerdyRodent "@NerdyRodent")

[Feb 20](https://nitter.net/NerdyRodent/status/2024866624692514884#m "Feb 20, 2026 ¬∑ 3:19 PM UTC")

[#InMice](https://nitter.net/search?f=tweets&q=%23InMice)

![](https://nitter.net/pic/profile_images%2F1888004001872101378%2FjVNJQ-iu_mini.jpg)[Bryan Johnson](https://nitter.net/bryan_johnson "Bryan Johnson")

[@bryan\_johnson](https://nitter.net/bryan_johnson "@bryan_johnson")

[Feb 19](https://nitter.net/bryan_johnson/status/2024555781077827756#m "Feb 19, 2026 ¬∑ 6:44 PM UTC")

After taking several large magic mushroom doses, my brain may be psilocybin-maxxed.

Mouse brains grew 10% more dendritic spines within 24 hours of a single psilocybin dose. A meaningful number lasted for weeks likely turning into stable long term neuronal connections.

Another experiment showed that psilocybin loosened the brain from repetitive self-talk, sensory experience became stronger and more vivid, and became more plastic. That's what I saw.

Data showed that what you think, feel and focus on during a magic mushroom experience influences which connections stabilize.

What I reported feeling:
‚Äúit felt like my consciousness was dialed up to 10/10.‚Äù
‚ÄúI felt hyper aware and hyper alive.‚Äù
‚ÄúI experienced sense of touch with awe.‚Äù
‚Äúmy mind was insatiably curious and wanted to deploy its sensors into the world and discover all things.‚Äù
‚ÄúMy brain wanted to stare, study and marvel.‚Äù
‚ÄúThe flavor exploded in my mouth.‚Äù
Restored my perception to youthful levels, returning them to factory settings and dissolving my aged numbness.

[![](https://nitter.net/pic/media%2FHBinUHUbAAA6fkY.png%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBinUHUbAAA6fkY.png)

2

Nerdy Rodent üêÄü§ìüíªü™êüö¥ retweeted

[![](https://nitter.net/pic/profile_images%2F1695024885070737408%2F-M-HSH5P_bigger.jpg)](https://nitter.net/GoogleDeepMind)

[Google DeepMind](https://nitter.net/GoogleDeepMind "Google DeepMind")

[@GoogleDeepMind](https://nitter.net/GoogleDeepMind "@GoogleDeepMind")

[Feb 19](https://nitter.net/GoogleDeepMind/status/2024516464892334129#m "Feb 19, 2026 ¬∑ 4:08 PM UTC")

Gemini 3.1 Pro is here.

We‚Äôve significantly improved the model‚Äôs overall intelligence so it can solve tougher problems. üßµ

263

746

6,270

k retweeted

[![](https://nitter.net/pic/profile_images%2F2006595716744097795%2F0yPqJVy9_bigger.jpg)](https://nitter.net/Pokemon)

[Pok√©mon](https://nitter.net/Pokemon "Pok√©mon")

[@Pokemon](https://nitter.net/Pokemon "@Pokemon")

[Feb 20](https://nitter.net/Pokemon/status/2024757682851233891#m "Feb 20, 2026 ¬∑ 8:07 AM UTC")

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
Pok√©mon FireRed and Pok√©mon LeafGreen confirmed for Nintendo Switch!
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
These download-exclusive titles will be available after the [#PokemonDay](https://nitter.net/search?f=tweets&q=%23PokemonDay) Presents presentation which begins Friday, February 27, 2026, at 6AM PST. [#PokemonFRLG](https://nitter.net/search?f=tweets&q=%23PokemonFRLG)

![](https://nitter.net/pic/media%2FHBliYZkXAAA6h5X.jpg%3Fname%3Dsmall%26format%3Dwebp)

Enable hls playback

2,504

13,031

90,138

Lewis Tunstall retweeted

[![](https://nitter.net/pic/profile_images%2F1889075959472476162%2FD9M1omhy_bigger.jpg)](https://nitter.net/j_dekoninck)

[Jasper Dekoninck](https://nitter.net/j_dekoninck "Jasper Dekoninck") [@j\_dekoninck](https://nitter.net/j_dekoninck "@j_dekoninck")

[Feb 20](https://nitter.net/j_dekoninck/status/2024776537262981408#m "Feb 20, 2026 ¬∑ 9:21 AM UTC")

Regarding Claude-Opus-4.6 (high) on MathArena:
\- It cost us $440 to get partial results on Apex Shortlist (only 90% finished), 4x the cost of any other model
\- Its performance was 55%, around Grok 4 Fast level
\- Many errors were caused by Opus hitting its maximum 128k token limit

9

3

73

[![](https://nitter.net/pic/profile_images%2F1358834299538051072%2FF0cQFEjK_bigger.jpg)](https://nitter.net/DeepLearningAI)

[DeepLearning.AI](https://nitter.net/DeepLearningAI "DeepLearning.AI")

[@DeepLearningAI](https://nitter.net/DeepLearningAI "@DeepLearningAI")

[Feb 20](https://nitter.net/DeepLearningAI/status/2024863851464753272#m "Feb 20, 2026 ¬∑ 3:08 PM UTC")

A nonprofit called the AI Verification and Research Institute (Averi) aims to establish standards for independent audits of AI systems, evaluating risks like misuse, data leaks, and harmful behavior.

By defining audit principles, the organization seeks to make safety reviews a routine part of development and help build public trust in AI.

Learn more in The Batch ‚Üì [hubs.la/Q043-pf\_0](https://hubs.la/Q043-pf_0)

[![](https://nitter.net/pic/card_img%2F2024863852953817088%2FqS-eufcm%3Fformat%3Djpg%26name%3D800x419)\\
\\
**OpenAI Alumni Found Averi to Set Standards for AI Model Audits** \\
\\
AI is becoming ubiquitous, yet no standards exist for auditing its safety and security to make sure AI systems don‚Äôt assist, say, hackers or...\\
\\
deeplearning.ai](https://hubs.la/Q043-pf_0)

2

1

23

[![](https://nitter.net/pic/profile_images%2F1790643775401754626%2Fcr9uM-ie_bigger.png)](https://nitter.net/ben_burtenshaw)

[Ben Burtenshaw](https://nitter.net/ben_burtenshaw "Ben Burtenshaw")

[@ben\_burtenshaw](https://nitter.net/ben_burtenshaw "@ben_burtenshaw")

[Feb 20](https://nitter.net/ben_burtenshaw/status/2024859763855544499#m "Feb 20, 2026 ¬∑ 2:52 PM UTC")

nano harness is a code first agent harness in 223 lines of code. it's rough, ready, and very hackable.

I had a lot of fun hacking with this today and learnt a lot about code first/ code act harnesses. take it for a spin and let me know if it's useful.

gist in the thread.

![](https://nitter.net/pic/amplify_video_thumb%2F2024858832644546560%2Fimg%2FXWevCztGEsWXwJSG.jpg%3Fname%3Dsmall%26format%3Dwebp)

Enable hls playback

1

5

41

[more replies](https://nitter.net/AymericRoucher/status/2024862522679992627#m)

[![](https://nitter.net/pic/profile_images%2F1993095459338846208%2Fnm8-u0zh_bigger.jpg)](https://nitter.net/AymericRoucher)

[m\_ric](https://nitter.net/AymericRoucher "m_ric")

[@AymericRoucher](https://nitter.net/AymericRoucher "@AymericRoucher")

[Feb 20](https://nitter.net/AymericRoucher/status/2024862522679992627#m "Feb 20, 2026 ¬∑ 3:03 PM UTC")

Nice work!
Don't hesitate to build a bit with smolagent's CodeAgent if you're interested in code-actions agents, I'm less involved now but would still love to look at what improvements you could propose!

1

1

[![](https://nitter.net/pic/profile_images%2F1790643775401754626%2Fcr9uM-ie_bigger.png)](https://nitter.net/ben_burtenshaw)

[Ben Burtenshaw](https://nitter.net/ben_burtenshaw "Ben Burtenshaw")

[@ben\_burtenshaw](https://nitter.net/ben_burtenshaw "@ben_burtenshaw")

[Feb 20](https://nitter.net/ben_burtenshaw/status/2024863609801601228#m "Feb 20, 2026 ¬∑ 3:07 PM UTC")

thanks. yes, this is obviously very much inspired by it but it was mainly a personal education quest, more than a usable tool.

it would be cool to benchmark a 'smolagents cli' with modern models to see where it stands too compared to modern harnesses.

2

[![](https://nitter.net/pic/profile_images%2F1728327996375719936%2FRW7VBJfD_bigger.jpg)](https://nitter.net/kimmonismus)

[Chubby‚ô®Ô∏è](https://nitter.net/kimmonismus "Chubby‚ô®Ô∏è")

[@kimmonismus](https://nitter.net/kimmonismus "@kimmonismus")

[Feb 20](https://nitter.net/kimmonismus/status/2024861969400901715#m "Feb 20, 2026 ¬∑ 3:01 PM UTC")

OpenAIs first device february 2027: a smart speaker

OpenAI has assembled a 200-person team to launch a new family of AI-powered devices, starting with a $200‚Äì$300 smart speaker expected no earlier than February 2027.

Designed in collaboration with Jony Ive‚Äôs LoveFrom, the speaker will feature a camera, environmental awareness, and Face ID-style purchasing - aiming to proactively ‚Äúnudge‚Äù users toward better decisions.

[![](https://nitter.net/pic/media%2FHBnAihCWEAAsqbo.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBnAihCWEAAsqbo.jpg)

![](https://nitter.net/pic/profile_images%2F1747484907163516928%2Fd_K3Z_hH_mini.jpg)[The Information](https://nitter.net/theinformation "The Information")

[@theinformation](https://nitter.net/theinformation "@theinformation")

[Feb 20](https://nitter.net/theinformation/status/2024850040510931066#m "Feb 20, 2026 ¬∑ 2:14 PM UTC")

Exclusive: OpenAI‚Äôs first device is expected to release a smart speaker with a camera, able to take in information about users and its surroundings.

Read more from [@Steph\_Palazzolo](https://nitter.net/steph_palazzolo "Stephanie Palazzolo") and [@QianerLiu](https://nitter.net/QianerLiu "Qianer Liu") üëá
[thein.fo/4kMndnr](https://thein.fo/4kMndnr)

43

29

311

[![](https://nitter.net/pic/profile_images%2F1728327996375719936%2FRW7VBJfD_bigger.jpg)](https://nitter.net/kimmonismus)

[Chubby‚ô®Ô∏è](https://nitter.net/kimmonismus "Chubby‚ô®Ô∏è")

[@kimmonismus](https://nitter.net/kimmonismus "@kimmonismus")

[Feb 20](https://nitter.net/kimmonismus/status/2024862475590443254#m "Feb 20, 2026 ¬∑ 3:03 PM UTC")

Yes, 2027 - you read it right.

Thats at least what the information says

[![](https://nitter.net/pic/media%2FHBnBqkpWgAAwcdM.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBnBqkpWgAAwcdM.jpg)

1

4

43

Hamel Husain retweeted

[![](https://nitter.net/pic/profile_images%2F1894484656403156992%2FnkkUdAyZ_bigger.jpg)](https://nitter.net/mattzcarey)

[Matt Carey](https://nitter.net/mattzcarey "Matt Carey")

[@mattzcarey](https://nitter.net/mattzcarey "@mattzcarey")

[Feb 20](https://nitter.net/mattzcarey/status/2024847630811980277#m "Feb 20, 2026 ¬∑ 2:04 PM UTC")

Code Mode is all you need, very excited about this direction for MCP

[blog.cloudflare.com/code-mod‚Ä¶](https://blog.cloudflare.com/code-mode-mcp/)

[![](https://nitter.net/pic/media%2FHBm0Ae1XMAIQsM2.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBm0Ae1XMAIQsM2.jpg)

141

329

3,592

[![](https://nitter.net/pic/profile_images%2F1557421659925237763%2FRzJu2YI3_bigger.jpg)](https://nitter.net/skalskip92)

[SkalskiP](https://nitter.net/skalskip92 "SkalskiP")

[@skalskip92](https://nitter.net/skalskip92 "@skalskip92")

[Feb 20](https://nitter.net/skalskip92/status/2024861373323227354#m "Feb 20, 2026 ¬∑ 2:59 PM UTC")

we are trending on github! let's go!

![](https://nitter.net/pic/profile_images%2F1557421659925237763%2FRzJu2YI3_mini.jpg)[SkalskiP](https://nitter.net/skalskip92 "SkalskiP")

[@skalskip92](https://nitter.net/skalskip92 "@skalskip92")

[Feb 18](https://nitter.net/skalskip92/status/2024191349201736153#m "Feb 18, 2026 ¬∑ 6:36 PM UTC")

trackers-2.2.0 released.

added trackers track CLI command. full tracking pipeline from the command line.

test with webcam:

trackers track --source 0 \
 --model rfdetr-medium \
 --tracker bytetrack \
 --show-trajectories

link: [github.com/roboflow/trackers](https://github.com/roboflow/trackers)

![](https://nitter.net/pic/amplify_video_thumb%2F2024185914855968768%2Fimg%2FOW0y94O4QOV1G6IL.jpg%3Fname%3Dsmall%26format%3Dwebp)

Enable hls playback

9

12

212

[![](https://nitter.net/pic/profile_images%2F1630952793610518528%2FJ7HUofm9_bigger.jpg)](https://nitter.net/kylebrussell)

[Kyle Russell](https://nitter.net/kylebrussell "Kyle Russell")

[@kylebrussell](https://nitter.net/kylebrussell "@kylebrussell")

[Feb 20](https://nitter.net/kylebrussell/status/2024860815711511030#m "Feb 20, 2026 ¬∑ 2:56 PM UTC")

no hun I am not doing 'karate moves' in the living room

in shotokan karate it is called 'kata'

1

Peter Welinder retweeted

[![](https://nitter.net/pic/profile_images%2F1953339828738899968%2FWWQlU2RT_bigger.jpg)](https://nitter.net/thsottiaux)

[Tibo](https://nitter.net/thsottiaux "Tibo")

[@thsottiaux](https://nitter.net/thsottiaux "@thsottiaux")

[Feb 19](https://nitter.net/thsottiaux/status/2024493074433618311#m "Feb 19, 2026 ¬∑ 2:35 PM UTC")

You only need your ChatGPT subscription to use Codex. It‚Äôs already included and even the plus subscription has very generous usage.

The reason we can do this is because gpt-5.3-codex achieves SoTA at lower cost than anything else out there.

[chatgpt.com/codex](https://chatgpt.com/codex)

[![](https://nitter.net/pic/card_img%2F2023750540493312002%2Fm2Jw3DkF%3Fformat%3Djpg%26name%3D800x419)\\
\\
**Codex** \\
\\
A cloud-based software engineering agent that answers codebase questions, executes code, and drafts pull requests.\\
\\
chatgpt.com](https://chatgpt.com/codex)

257

98

3,008

[![](https://nitter.net/pic/profile_images%2F1993095459338846208%2Fnm8-u0zh_bigger.jpg)](https://nitter.net/AymericRoucher)

[m\_ric](https://nitter.net/AymericRoucher "m_ric")

[@AymericRoucher](https://nitter.net/AymericRoucher "@AymericRoucher")

[Feb 20](https://nitter.net/AymericRoucher/status/2024859949944156417#m "Feb 20, 2026 ¬∑ 2:53 PM UTC")

Custom hardware from Taalas runs Llama-3.1-8B, at 17k tokens per second
17k ü§Ø
Absolutely insane

(For the record Cerebras is crazy good and they're at 2k on the same model)
And latency is very low too!

Their chatbot is here: [chatjimmy.ai/](https://chatjimmy.ai/)

It's genuinely a eerie experience to get instant responses like that

[![](https://nitter.net/pic/media%2FHBm_PZiWMAAdbcW.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBm_PZiWMAAdbcW.jpg)

1

1

10

[![](https://nitter.net/pic/profile_images%2F1993095459338846208%2Fnm8-u0zh_bigger.jpg)](https://nitter.net/AymericRoucher)

[m\_ric](https://nitter.net/AymericRoucher "m_ric")

[@AymericRoucher](https://nitter.net/AymericRoucher "@AymericRoucher")

[Feb 20](https://nitter.net/AymericRoucher/status/2024860081041317982#m "Feb 20, 2026 ¬∑ 2:53 PM UTC")

My first thought was "why did they even bother implementing a streaming UI"

1

[![](https://nitter.net/pic/profile_images%2F1993095459338846208%2Fnm8-u0zh_bigger.jpg)](https://nitter.net/AymericRoucher)

[m\_ric](https://nitter.net/AymericRoucher "m_ric")

[@AymericRoucher](https://nitter.net/AymericRoucher "@AymericRoucher")

[Feb 20](https://nitter.net/AymericRoucher/status/2024860156769587407#m "Feb 20, 2026 ¬∑ 2:54 PM UTC")

Their blog post here: [taalas.com/the-path-to-ubiqu‚Ä¶](https://taalas.com/the-path-to-ubiquitous-ai/)

[![](https://nitter.net/pic/card_img%2F2024516175854469120%2Fk6M6TB80%3Fformat%3Dpng%26name%3D420x420_2)\\
\\
**The path to ubiquitous AI \| Taalas** \\
\\
By Ljubisa Bajic Many believe AI is the real deal. In narrow domains, it already surpasses human performance. Used well, it is an unprecedented amplifier of human ingenuity and productivity. Its...\\
\\
taalas.com](https://taalas.com/the-path-to-ubiquitous-ai/)

[![](https://nitter.net/pic/profile_images%2F2019196082727620608%2FiIXCFAJb_bigger.jpg)](https://nitter.net/TheTuringPost)

[Ksenia\_TuringPost](https://nitter.net/TheTuringPost "Ksenia_TuringPost")

[@TheTuringPost](https://nitter.net/TheTuringPost "@TheTuringPost")

[Feb 20](https://nitter.net/TheTuringPost/status/2024859570208735613#m "Feb 20, 2026 ¬∑ 2:51 PM UTC")

‚ÄúTired of the same ultracrepidarian professional talking heads‚Äù ‚Äì what a brilliant phrase.

First, Swyx is absolutely right: who do these conferences actually serve?

Second, I admire how he is not a talker but a doer: he found a precise niche of builders and serves it with taste, in a way that‚Äôs genuinely useful for the whole industry.

Third, there‚Äôs such pure emotion in this text that that alone makes it worth reading.

![](https://nitter.net/pic/profile_images%2F1867875781676007424%2FRIF4Kt7U_mini.jpg)[swyx](https://nitter.net/swyx "swyx")

[@swyx](https://nitter.net/swyx "@swyx")

[Feb 19](https://nitter.net/swyx/status/2024616612599587282#m "Feb 19, 2026 ¬∑ 10:46 PM UTC")

[x.com/i/article/202460118068‚Ä¶](http://x.com/i/article/2024601180689903616)

1

3

[![](https://nitter.net/pic/profile_images%2F939313677647282181%2FvZjFWtAn_bigger.jpg)](https://nitter.net/omarsar0)

[elvis](https://nitter.net/omarsar0 "elvis")

[@omarsar0](https://nitter.net/omarsar0 "@omarsar0")

[Feb 20](https://nitter.net/omarsar0/status/2024859532892029267#m "Feb 20, 2026 ¬∑ 2:51 PM UTC")

"The Coding Agent is Dead"

There is something you don't hear these days.

It's worth the read. We are gradually moving toward higher levels of interaction with agents.

"How you organize your codebase for agents, how your organization uses them ‚Äî those are now the bottlenecks."

![](https://nitter.net/pic/profile_images%2F845340663050899457%2FvNzxTmKV_mini.jpg)[Thorsten Ball](https://nitter.net/thorstenball "Thorsten Ball")

[@thorstenball](https://nitter.net/thorstenball "@thorstenball")

[Feb 19](https://nitter.net/thorstenball/status/2024509255894671396#m "Feb 19, 2026 ¬∑ 3:39 PM UTC")

We believe the coding agent is dead.

Soon, Amp will look very different.

[ampcode.com/news/the-coding-‚Ä¶](https://ampcode.com/news/the-coding-agent-is-dead)

[![](https://nitter.net/pic/media%2FHBh4FcBWQAAByU_.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBh4FcBWQAAByU_.jpg)

11

15

177

[![](https://nitter.net/pic/profile_images%2F1451191636810092553%2FkpM5Fe12_bigger.jpg)](https://nitter.net/_akhaliq)

[AK](https://nitter.net/_akhaliq "AK")

[@\_akhaliq](https://nitter.net/_akhaliq "@_akhaliq")

[Feb 20](https://nitter.net/_akhaliq/status/2024859252297220294#m "Feb 20, 2026 ¬∑ 2:50 PM UTC")

Llama.cpp joins Hugging Face

[![](https://nitter.net/pic/media%2FHBm-qqqXQAEJwyk.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBm-qqqXQAEJwyk.jpg)

3

10

62

Kyle Russell retweeted

[![](https://nitter.net/pic/profile_images%2F1753264923365523456%2FmUCvwn7v_bigger.jpg)](https://nitter.net/nickcammarata)

[Nick](https://nitter.net/nickcammarata "Nick")

[@nickcammarata](https://nitter.net/nickcammarata "@nickcammarata")

[Feb 20](https://nitter.net/nickcammarata/status/2024704310479901147#m "Feb 20, 2026 ¬∑ 4:34 AM UTC")

the obvious lesson is ‚Äúonly do things for joy‚Äù

but the real move is deliberately training joy itself, as you‚Äôd train your physical muscles. stop optimizing the activity, upgrade the substrate. then it doesn‚Äôt matter what you‚Äôre doing, whatever it is, it will be done joyfully

![](https://nitter.net/pic/profile_images%2F1927795530920239104%2Frv8FxhKB_mini.jpg)[Brad Stulberg](https://nitter.net/BStulberg "Brad Stulberg")

[@BStulberg](https://nitter.net/BStulberg "@BStulberg")

[Feb 19](https://nitter.net/BStulberg/status/2024628741910196463#m "Feb 19, 2026 ¬∑ 11:34 PM UTC")

Joy is a competitive super power.

Alysa Liu retired from figure skating at 16.
She was tired of not not having fun, tired of being consumed by her sport.

She came back two years later with a new goal: to have as much fun on the ice as possible. And now she‚Äôs an Olympic gold medalist.

Liu won her first national title when she was just 13. But by 16, after competing in the 2022 Olympics, she decided she‚Äôd had enough and stepped away. She said pressure and losing her identity trying to be an elite athlete made it all miserable.

But then, she said she went on a ski trip that reminded her just how much fun she could have doing a sport. Something in her brain clicked. Maybe she could bring fun to figure skating. Maybe she could approach it in a way that could be full of joy and life and love.

She unretired at 18 and won a world championship the next year. At 20, she was ready to face these Olympic games differently than in 2022.

Liu went into the women‚Äôs figure skating final in third place. After her short program, she said:

‚ÄúEven if I mess up and fall, that‚Äôs totally okay, too. I‚Äôm fine with any outcome, as long as I‚Äôm out there.‚Äù

One of the greatest competitive advantages is having fun. People love to romanticize the athlete, artist, or entrepreneur who has a chip on their shoulder, fueled by anger and resentment.

But the truth is that if you‚Äôre not having fun, you are not going to last long at whatever it is you do, and you certainly won‚Äôt get the best out of yourself. There‚Äôs a foolish idea that you either have to be full of intensity or full of joy. But that‚Äôs nonsense.

It‚Äôs no surprise one of the first things out of Alysa‚Äôs mouth after her free skate was: ‚ÄúThat was so much fun!‚Äù

Joy and intensity can coexist, and in the best performers, they almost always do.

Alysa is unapologetically authentic and true to her values. She has said where she used to skate to win and be technically perfect, she now uses competition as a chance to show her art, to have fun, and to put herself out there.

She‚Äôs a fierce athlete with an infectious sense of joy in her sport.

And she broke USA's 24-year gold medal draught in women‚Äôs figure skating doing it.

Excellence requires focus, determination, a little bit of crazy, at times obsession, and living a mundane lifestyle that many people would find boring.

But excellence also requires that you find deep joy in your craft, that you learn how to have fun while working hard.

What makes for excellence‚Äîand not just in sports, but in anything‚Äîis the combination of intensity and joy. It‚Äôs the latter that makes the former sustainable.

[![](https://nitter.net/pic/media%2FHBjolYDbUAIJFR4.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBjolYDbUAIJFR4.jpg)

22

416

4,676

[![](https://nitter.net/pic/profile_images%2F1982142240571920384%2Fhla62KCQ_bigger.jpg)](https://nitter.net/mervenoyann)

[merve](https://nitter.net/mervenoyann "merve")

[@mervenoyann](https://nitter.net/mervenoyann "@mervenoyann")

[Feb 20](https://nitter.net/mervenoyann/status/2024854687845851195#m "Feb 20, 2026 ¬∑ 2:32 PM UTC")

local AI goes brrr üí•

GGML (llama.cpp) is officially part of [@huggingface](https://nitter.net/huggingface "Hugging Face") üöÄ

[![](https://nitter.net/pic/media%2FHBm6mnbWIAEhQh9.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBm6mnbWIAEhQh9.jpg)

8

10

204

[![](https://nitter.net/pic/profile_images%2F1982142240571920384%2Fhla62KCQ_bigger.jpg)](https://nitter.net/mervenoyann)

[merve](https://nitter.net/mervenoyann "merve")

[@mervenoyann](https://nitter.net/mervenoyann "@mervenoyann")

[Feb 20](https://nitter.net/mervenoyann/status/2024855012019478553#m "Feb 20, 2026 ¬∑ 2:33 PM UTC")

announcement blog [huggingface.co/blog/ggml-joi‚Ä¶](https://huggingface.co/blog/ggml-joins-hf)

here's a nice write-up by [@ngxson](https://nitter.net/ngxson "Xuan-Son Nguyen") [blog.ngxson.com/ggml-and-lla‚Ä¶](https://blog.ngxson.com/ggml-and-llama-cpp-join-hugging-face) ü¶ô ü§ó

[![](https://nitter.net/pic/card_img%2F2024854991585071104%2F8_kezYnK%3Fformat%3Dpng%26name%3D800x419)\\
\\
**GGML and llama.cpp join HF to ensure the long-term progress of Local AI** \\
\\
We‚Äôre on a journey to advance and democratize artificial intelligence through open source and open science.\\
\\
huggingface.co](https://huggingface.co/blog/ggml-joins-hf)

5

15

[![](https://nitter.net/pic/profile_images%2F1624054272676532224%2FUNv4ONME_bigger.jpg)](https://nitter.net/danielhanchen)

[Daniel Han](https://nitter.net/danielhanchen "Daniel Han")

[@danielhanchen](https://nitter.net/danielhanchen "@danielhanchen")

[Feb 20](https://nitter.net/danielhanchen/status/2024853232493949166#m "Feb 20, 2026 ¬∑ 2:26 PM UTC")

Thanks so much to everyone for sharing your Unsloth models! ü¶•

There's lots of epic fine-tunes ranging from medical, OCR, multilingual, roleplay, TTS, legal, coding, distills & much more.

![](https://nitter.net/pic/profile_images%2F1790653115441782784%2FVXHiO8LM_mini.jpg)[Unsloth AI](https://nitter.net/UnslothAI "Unsloth AI")

[@UnslothAI](https://nitter.net/UnslothAI "@UnslothAI")

[Feb 20](https://nitter.net/UnslothAI/status/2024847369733325202#m "Feb 20, 2026 ¬∑ 2:03 PM UTC")

100,000+ models trained with Unsloth have now been open-sourced on Hugging Face!

Popular fine-tuned LLMs you can run locally:
1\. TeichAI - GLM-4.7-Flash distilled from Claude 4.5 Opus (high)
2\. Zed - Qwen Coder 7B fine-tuned for stronger coding
3\. DavidAU - Llama-3.3-8B distilled from Claude 4.5 Opus (high)
4\. huihui - gpt-oss made ‚Äúabliberated‚Äù

Links to models:
1\. TeichAI: [huggingface.co/TeichAI/GLM-4‚Ä¶](https://huggingface.co/TeichAI/GLM-4.7-Flash-Claude-Opus-4.5-High-Reasoning-Distill-GGUF)
2\. Zed: [huggingface.co/zed-industrie‚Ä¶](https://huggingface.co/zed-industries/zeta)
3\. DavidAU: [huggingface.co/DavidAU/Llama‚Ä¶](https://huggingface.co/DavidAU/Llama3.3-8B-Instruct-Thinking-Claude-4.5-Opus-High-Reasoning)
4\. huihui: [huggingface.co/huihui-ai/Hui‚Ä¶](https://huggingface.co/huihui-ai/Huihui-gpt-oss-20b-BF16-abliterated)

See all the 100K latest models fine-tuned with Unsloth here: [huggingface.co/models?other=‚Ä¶](https://huggingface.co/models?other=unsloth&sort=created)

[![](https://nitter.net/pic/media%2FHBmw-lGasAAUGCD.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBmw-lGasAAUGCD.jpg)

3

7

75

Sara Hooker retweeted

[![](https://nitter.net/pic/profile_images%2F2024199453717254144%2FJ1kXYgOL_bigger.jpg)](https://nitter.net/hey_shivv)

[Shiv](https://nitter.net/hey_shivv "Shiv")

[@hey\_shivv](https://nitter.net/hey_shivv "@hey_shivv")

[Feb 20](https://nitter.net/hey_shivv/status/2024852958865936596#m "Feb 20, 2026 ¬∑ 2:25 PM UTC")

Replying to [@sarahookr](https://nitter.net/sarahookr) [@ndtv](https://nitter.net/ndtv) [@adaptionlabs](https://nitter.net/adaptionlabs)

Hey [@sarahookr](https://nitter.net/sarahookr "Sara Hooker") , this message of yours has been very helpful and insightful , thanks

Credits: [@OfficialINDIAai](https://nitter.net/OfficialINDIAai "IndiaAI")

![](https://nitter.net/pic/amplify_video_thumb%2F2024852637943017472%2Fimg%2F5zGoNZ0qYyXnVS_m.jpg%3Fname%3Dsmall%26format%3Dwebp)

Enable hls playback

4

24

[![](https://nitter.net/pic/profile_images%2F1778934412404523009%2F4fRabWRC_bigger.png)](https://nitter.net/Muennighoff)

[Niklas Muennighoff](https://nitter.net/Muennighoff "Niklas Muennighoff") [@Muennighoff](https://nitter.net/Muennighoff "@Muennighoff")

[Feb 20](https://nitter.net/Muennighoff/status/2024851690877227303#m "Feb 20, 2026 ¬∑ 2:20 PM UTC")

We released MAEB: Massive Audio Embedding Benchmarküéµ mteb now covers audio/image/text embedding! See the leaderboard for the top audio embedding modelsüôÇ

LB: [hf.co/spaces/mteb/leaderboar‚Ä¶](https://hf.co/spaces/mteb/leaderboard)
Paper: [hf.co/papers/2602.16008](https://hf.co/papers/2602.16008)

[![](https://nitter.net/pic/media%2FHBmzN4TWEAAJtMi.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBmzN4TWEAAJtMi.jpg)

3

9

43

[![](https://nitter.net/pic/profile_images%2F1778934412404523009%2F4fRabWRC_bigger.png)](https://nitter.net/Muennighoff)

[Niklas Muennighoff](https://nitter.net/Muennighoff "Niklas Muennighoff") [@Muennighoff](https://nitter.net/Muennighoff "@Muennighoff")

[Feb 20](https://nitter.net/Muennighoff/status/2024851693108691295#m "Feb 20, 2026 ¬∑ 2:20 PM UTC")

Congrats to [@Alibaba\_Qwen](https://nitter.net/Alibaba_Qwen "Qwen") [@JustinLin610](https://nitter.net/JustinLin610 "Junyang Lin") & team on being No1 currently ü•á!

great aspect was having new researchers for whom this was their first paper; many more papers planned at mteb - feel free to join usüòä

[![](https://nitter.net/pic/media%2FHBm1sKrWEAA9KHr.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBm1sKrWEAA9KHr.jpg)

2

3

[![](https://nitter.net/pic/profile_images%2F1778934412404523009%2F4fRabWRC_bigger.png)](https://nitter.net/Muennighoff)

[Niklas Muennighoff](https://nitter.net/Muennighoff "Niklas Muennighoff") [@Muennighoff](https://nitter.net/Muennighoff "@Muennighoff")

[Feb 20](https://nitter.net/Muennighoff/status/2024851695860056435#m "Feb 20, 2026 ¬∑ 2:20 PM UTC")

By [@AdnanElAssadi](https://nitter.net/AdnanElAssadi "Adnan El Assadi") [@isaacchung1217](https://nitter.net/isaacchung1217 "Isaac Chung") [@gowitheflow98](https://nitter.net/gowitheflow98 "Chenghao Xiao") [@risolomatin](https://nitter.net/risolomatin "Roman"), Animesh Jha, Rahul Chand, Silky Singh, [@kkaitlyn111](https://nitter.net/kkaitlyn111 "Kaitlyn Wang"), Ali Sartaz Khan, Marc Moussa Nasser, Sufen Fong, [@hepengfe](https://nitter.net/hepengfe "Pengfei He") Alan Xiao, [@MunotAyush6](https://nitter.net/MunotAyush6 "Ayush Munot"), Aditya Shrivastava, Artem Gazizov, Kenneth Enevoldsen :)

[![](https://nitter.net/pic/profile_images%2F539842407081066497%2F6JaLwehz_bigger.png)](https://nitter.net/sedielem)

[Sander Dieleman](https://nitter.net/sedielem "Sander Dieleman")

[@sedielem](https://nitter.net/sedielem "@sedielem")

[Feb 20](https://nitter.net/sedielem/status/2024851421217149430#m "Feb 20, 2026 ¬∑ 2:19 PM UTC")

Cool finding: temporally autoregressive video diffusion models use lower layers for noise-level-independent causal processing, and upper layers for intra-frame denoising.

Explicitly separating them brings practical and speed benefits! Reminds me of the AlphaFold 3 architectureü§î

![](https://nitter.net/pic/profile_images%2F1794079843736231936%2FQjKl00u8_mini.jpg)[Xingjian Bai](https://nitter.net/SimulatedAnneal "Xingjian Bai")

[@SimulatedAnneal](https://nitter.net/SimulatedAnneal "@SimulatedAnneal")

[Feb 19](https://nitter.net/SimulatedAnneal/status/2024615127996330474#m "Feb 19, 2026 ¬∑ 10:40 PM UTC")

Do causal video diffusers really need dense causal attention at every layer, every denoising step?

We looked inside and found: no. Causality is separable from denoising.

Here are two surprising observations that hold across architectures, training objectives, and scales.

[![](https://nitter.net/pic/media%2FHBjguoHbsAAUUx2.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBjguoHbsAAUUx2.jpg)

3

9

141

Sara Hooker retweeted

[![](https://nitter.net/pic/profile_images%2F1283293055659974662%2F0hNt4aFh_bigger.jpg)](https://nitter.net/yagyaansh)

[A Pale Blue Dot](https://nitter.net/yagyaansh "A Pale Blue Dot")

[@yagyaansh](https://nitter.net/yagyaansh "@yagyaansh")

[Feb 20](https://nitter.net/yagyaansh/status/2024851048104652966#m "Feb 20, 2026 ¬∑ 2:18 PM UTC")

Replying to [@sarahookr](https://nitter.net/sarahookr)

Some captures from the talk :)

[![](https://nitter.net/pic/media%2FHBm1HD1bgAAZ8--.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBm1HD1bgAAZ8--.jpg)

[![](https://nitter.net/pic/media%2FHBm1HDxbcAAOOfZ.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBm1HDxbcAAOOfZ.jpg)

[![](https://nitter.net/pic/media%2FHBmz3P4aQAACTMR.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBmz3P4aQAACTMR.jpg)

2

4

40

Hamel Husain retweeted

[![](https://nitter.net/pic/profile_images%2F1998877988545273857%2F0sEbeyue_bigger.jpg)](https://nitter.net/egealtan)

[Ege Altan](https://nitter.net/egealtan "Ege Altan")

[@egealtan](https://nitter.net/egealtan "@egealtan")

[Feb 20](https://nitter.net/egealtan/status/2024850362088440042#m "Feb 20, 2026 ¬∑ 2:15 PM UTC")

Data scientists spent the last 3 years watching prompt engineers and vibe coders get the spotlight.

Meanwhile, they quietly mastered the skills that matter most for solving the remaining hard problems in AI: knowing what to measure and why.

That patience is about to pay dividends.

Full post below:

[![](https://nitter.net/pic/media%2FHBm2rD6aQAABSSs.png%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBm2rD6aQAABSSs.png)

2

5

42

apolinario üåê retweeted

[![](https://nitter.net/pic/profile_images%2F1099983311101984768%2Fp7dZK4S__bigger.jpg)](https://nitter.net/victormustar)

[Victor M](https://nitter.net/victormustar "Victor M")

[@victormustar](https://nitter.net/victormustar "@victormustar")

[Feb 20](https://nitter.net/victormustar/status/2024842175532413016#m "Feb 20, 2026 ¬∑ 1:42 PM UTC")

BREAKING: Llama.cpp joins Hugging Face ü§Ø

[![](https://nitter.net/pic/media%2FHBmu3cnWEAEGPHL.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBmu3cnWEAEGPHL.jpg)

![](https://nitter.net/pic/profile_images%2F1654097134315098113%2FzCZD0wYz_mini.jpg)[Georgi Gerganov](https://nitter.net/ggerganov "Georgi Gerganov")

[@ggerganov](https://nitter.net/ggerganov "@ggerganov")

[Feb 20](https://nitter.net/ggerganov/status/2024839991482777976#m "Feb 20, 2026 ¬∑ 1:34 PM UTC")

Today [ggml.ai](http://ggml.ai/) joins Hugging Face

Together we will continue to build ggml, make llama.cpp more accessible and empower the open-source community. Our joint mission is to make local AI easy and efficient to use by everyone on their own hardware.

13

69

638

[![](https://nitter.net/pic/profile_images%2F1745893660099592193%2FMmYemsw6_bigger.jpg)](https://nitter.net/eliebakouch)

[elie](https://nitter.net/eliebakouch "elie")

[@eliebakouch](https://nitter.net/eliebakouch "@eliebakouch")

[Feb 20](https://nitter.net/eliebakouch/status/2024850183637311627#m "Feb 20, 2026 ¬∑ 2:14 PM UTC")

very big news for open source: ggml (llama.cpp org) joins hugging face!!

[![](https://nitter.net/pic/media%2FHBm2FPJXIAAc5RN.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBm2FPJXIAAc5RN.jpg)

![](https://nitter.net/pic/profile_images%2F1654097134315098113%2FzCZD0wYz_mini.jpg)[Georgi Gerganov](https://nitter.net/ggerganov "Georgi Gerganov")

[@ggerganov](https://nitter.net/ggerganov "@ggerganov")

[Feb 20](https://nitter.net/ggerganov/status/2024839991482777976#m "Feb 20, 2026 ¬∑ 1:34 PM UTC")

Today [ggml.ai](http://ggml.ai/) joins Hugging Face

Together we will continue to build ggml, make llama.cpp more accessible and empower the open-source community. Our joint mission is to make local AI easy and efficient to use by everyone on their own hardware.

10

82

[Load more](https://nitter.net/i/lists/1585430245762441216?cursor=DAABCgABHBsYPkH__aYKAAIcGbaDjxYgiwgAAwAAAAIAAA)