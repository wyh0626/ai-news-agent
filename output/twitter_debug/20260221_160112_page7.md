[![](https://nitter.net/pic/list_banner_img%2F1613505644405075970%2F9VRDCFnW%3Fformat%3Djpg%26name%3Dorig)](https://nitter.net/pic/list_banner_img%2F1613505644405075970%2F9VRDCFnW%3Fformat%3Djpg%26name%3Dorig)

"AI High Signal" by @

AI twitter accounts that are high signal

- [Tweets](https://nitter.net/i/lists/1585430245762441216)
- [Members](https://nitter.net/i/lists/1585430245762441216/members)

[Load newest](https://nitter.net/i/lists/1585430245762441216)

[![](https://nitter.net/pic/profile_images%2F1850957204570193920%2FpBuQN2tH_bigger.jpg)](https://nitter.net/jd_pressman)

[John David Pressman](https://nitter.net/jd_pressman "John David Pressman")

[@jd\_pressman](https://nitter.net/jd_pressman "@jd_pressman")

[21h](https://nitter.net/jd_pressman/status/2024916885519937851#m "Feb 20, 2026 Â· 6:39 PM UTC")

Oh look, SCOTUS finally found its balls, or noticed the pitchforks outside. One of the two.

![](https://nitter.net/pic/profile_images%2F1637507712983375875%2FEQHiqVq8_mini.jpg)[CrÃ©mieux](https://nitter.net/cremieuxrecueil "CrÃ©mieux")

[@cremieuxrecueil](https://nitter.net/cremieuxrecueil "@cremieuxrecueil")

[22h](https://nitter.net/cremieuxrecueil/status/2024894124017512471#m "Feb 20, 2026 Â· 5:09 PM UTC")

This morning, the Supreme Court FINALLY issued a ruling on whether Trump could unilaterally impose tariffs.

"The IEEPA does not authorize the President to impose tariffs."

TL;DR: No more tariffs.

[![](https://nitter.net/pic/media%2FHBneeeFXkAAfiWb.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBneeeFXkAAfiWb.jpg)

1

17

[![](https://nitter.net/pic/profile_images%2F1417293853543964672%2Fyaq4r49L_bigger.jpg)](https://nitter.net/OfirPress)

[Ofir Press](https://nitter.net/OfirPress "Ofir Press")

[@OfirPress](https://nitter.net/OfirPress "@OfirPress")

[21h](https://nitter.net/OfirPress/status/2024916415292071992#m "Feb 20, 2026 Â· 6:37 PM UTC")

Programmers aren't going away any time soon, the job will just change substantially. Because of the world's unquenchable, ever-growing demand for software, I don't even think the amount of programmers employed will go down, at least not in the near future (4 years).

The process that we'll see is not really comparable to the automation of farming, it's probably more comparable to the introduction of drills, cranes and cement mixers in construction.

Programming will change, but we're still far away from the day when a lawyer/doctor/accountant/architect will be able to maintain & enhance their software stack simply by talking to it.

And even when that day arrives, we'll still have a lot of work remaining for programmers.

"As implementation grows increasingly automated, the core skill of software engineering shifts away from writing code line-by-line and toward shaping systems. Engineers can focus on deciding what should exist, how components fit together, and how complexity remains understandable over time. Good software depends on judgment, communication, and clear abstraction. AI systems amplify these human qualities, rather than replacing them."

![](https://nitter.net/pic/profile_images%2F1484209565788897285%2F1n6Viahb_mini.jpg)[Chris Lattner](https://nitter.net/clattner_llvm "Chris Lattner")

[@clattner\_llvm](https://nitter.net/clattner_llvm "@clattner_llvm")

[Feb 19](https://nitter.net/clattner_llvm/status/2024564314347360272#m "Feb 19, 2026 Â· 7:18 PM UTC")

The Claude C Compiler is the first AI-generated compiler that builds complex C code, built by [@AnthropicAI](https://nitter.net/AnthropicAI "Anthropic"). Reactions ranged from dismissal as "AI nonsense" to "SW is over": both takes miss the point.

As a compilerðŸ‰ expert and experienced SW leader, I see a lot to learn: ðŸ‘‡

[![](https://nitter.net/pic/media%2FHBiyazdboAAAfdq.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBiyazdboAAAfdq.jpg)

7

5

70

[![](https://nitter.net/pic/profile_images%2F1426579043223228421%2FKxSFxxD0_bigger.jpg)](https://nitter.net/lcastricato)

[Louis Castricato @ lovecraftian horrors](https://nitter.net/lcastricato "Louis Castricato @ lovecraftian horrors")

[@lcastricato](https://nitter.net/lcastricato "@lcastricato")

[21h](https://nitter.net/lcastricato/status/2024915652033626292#m "Feb 20, 2026 Â· 6:34 PM UTC")

Building a good world model is only part of the battle, building an incredible pipeline around it is also immensely valuable.

![](https://nitter.net/pic/profile_images%2F2012607727193751552%2Fjj02QFpw_mini.jpg)[Overworld](https://nitter.net/overworld_ai "Overworld")

[@overworld\_ai](https://nitter.net/overworld_ai "@overworld_ai")

[21h](https://nitter.net/overworld_ai/status/2024914643446124615#m "Feb 20, 2026 Â· 6:30 PM UTC")

The hardest part of shipping a world model isnâ€™t the model.

Itâ€™s the gap between what users type and what the model expects.

Itâ€™s not just text â†’ output.

23

Omar Khattab retweeted

[![](https://nitter.net/pic/profile_images%2F1735728202121609216%2FCFoG6BWC_bigger.jpg)](https://nitter.net/bclavie)

[Ben ClaviÃ©](https://nitter.net/bclavie "Ben ClaviÃ©")

[@bclavie](https://nitter.net/bclavie "@bclavie")

[Feb 20](https://nitter.net/bclavie/status/2024726012526022890#m "Feb 20, 2026 Â· 6:01 AM UTC")

We are extending the deadline of the Late Interaction Workshop one final time: the final (final) deadline is
Feb 27th, AOE.

We welcome all submissions: short notes, training reports, full papers, etc...

Submit your paper now and join all the coolest multi-vector kids in Delft!

[![](https://nitter.net/pic/media%2FHBlE_-IbUAI2IwO.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBlE_-IbUAI2IwO.jpg)

2

4

18

Omar Khattab retweeted

[![](https://nitter.net/pic/profile_images%2F1799382473320677376%2FmRdPKUNw_bigger.jpg)](https://nitter.net/antoine_chaffin)

[Antoine Chaffin](https://nitter.net/antoine_chaffin "Antoine Chaffin")

[@antoine\_chaffin](https://nitter.net/antoine_chaffin "@antoine_chaffin")

[23h](https://nitter.net/antoine_chaffin/status/2024886980765417739#m "Feb 20, 2026 Â· 4:40 PM UTC")

If you've seen the recent release of LateOn-Code & ColBERT-Zero, you know that late interaction models are awesome, so come and join us, it'll be super cool!

![](https://nitter.net/pic/profile_images%2F1735728202121609216%2FCFoG6BWC_mini.jpg)[Ben ClaviÃ©](https://nitter.net/bclavie "Ben ClaviÃ©")

[@bclavie](https://nitter.net/bclavie "@bclavie")

[Feb 20](https://nitter.net/bclavie/status/2024726012526022890#m "Feb 20, 2026 Â· 6:01 AM UTC")

We are extending the deadline of the Late Interaction Workshop one final time: the final (final) deadline is
Feb 27th, AOE.

We welcome all submissions: short notes, training reports, full papers, etc...

Submit your paper now and join all the coolest multi-vector kids in Delft!

[![](https://nitter.net/pic/media%2FHBlE_-IbUAI2IwO.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBlE_-IbUAI2IwO.jpg)

1

3

9

[![](https://nitter.net/pic/profile_images%2F1902391071331520512%2FZuId3kSn_bigger.jpg)](https://nitter.net/espricewright)

[Erin Price-Wright](https://nitter.net/espricewright "Erin Price-Wright")

[@espricewright](https://nitter.net/espricewright "@espricewright")

[21h](https://nitter.net/espricewright/status/2024915265532871158#m "Feb 20, 2026 Â· 6:33 PM UTC")

We recently started working with a dog trainer who texts like he's William Faulkner. Rather than having to read As I Lay Dying every time he sends a message I used clawdbot to build a translator that summarizes and formats his texts.

AI is a game changer, you can build anything.

8

[![](https://nitter.net/pic/profile_images%2F1989346628981886976%2F7W-5noSE_bigger.jpg)](https://nitter.net/sammcallister)

[sam mcallister](https://nitter.net/sammcallister "sam mcallister")

[@sammcallister](https://nitter.net/sammcallister "@sammcallister")

[21h](https://nitter.net/sammcallister/status/2024914863143653405#m "Feb 20, 2026 Â· 6:31 PM UTC")

New research preview today.

We're encouraging open-source maintainers to apply for free, expedited access.

![](https://nitter.net/pic/profile_images%2F1950950107937185792%2FQOfEjFoJ_mini.jpg)[Claude](https://nitter.net/claudeai "Claude")

[@claudeai](https://nitter.net/claudeai "@claudeai")

[21h](https://nitter.net/claudeai/status/2024907535145468326#m "Feb 20, 2026 Â· 6:02 PM UTC")

Introducing Claude Code Security, now in limited research preview.

It scans codebases for vulnerabilities and suggests targeted software patches for human review, allowing teams to find and fix issues that traditional tools often miss.

Learn more: [anthropic.com/news/claude-coâ€¦](https://www.anthropic.com/news/claude-code-security)

![](https://nitter.net/pic/media%2FHBntcaZaoAA7SFR.jpg%3Fname%3Dsmall%26format%3Dwebp)

Enable hls playback

8

8

151

[![](https://nitter.net/pic/profile_images%2F1895986752923316224%2FddAW9NgD_bigger.jpg)](https://nitter.net/daraladje)

[Dara](https://nitter.net/daraladje "Dara")

[@daraladje](https://nitter.net/daraladje "@daraladje")

[21h](https://nitter.net/daraladje/status/2024914560835354761#m "Feb 20, 2026 Â· 6:30 PM UTC")

Grant Lee built one of the highest-performing micro-influencer programs with a move that doesn't scale.

He spent hours 1-on-1 with every creator.

No marketing scripts. He personally onboarded them to Gamma and helped refine their hooks and copy.

It felt almost awkward at first because brands usually treat these as transactions.

But by learning the craft himself, he ensured the content felt authentic to their audience - not like an ad.

This decision accelerated Gamma's path to $100M ARR

![](https://nitter.net/pic/amplify_video_thumb%2F2024914096764944384%2Fimg%2FiFnBq466xOwdUk3h.jpg%3Fname%3Dsmall%26format%3Dwebp)

Enable hls playback

![](https://nitter.net/pic/profile_images%2F1895986752923316224%2FddAW9NgD_mini.jpg)[Dara](https://nitter.net/daraladje "Dara")

[@daraladje](https://nitter.net/daraladje "@daraladje")

[Feb 19](https://nitter.net/daraladje/status/2024559146264383783#m "Feb 19, 2026 Â· 6:58 PM UTC")

How unicorn founder [@thisisgrantlee](https://nitter.net/thisisgrantlee "Grant Lee") took Gamma from â€œthe worst idea everâ€ to a $2.1B company.

VCs hung up on him, friends lied to his face, and signups plateaued. Most founders would have pivoted.

Grant doubled down and went all in on the users first 30 seconds:
â€¢Â The entire team focused on it for 4 month
â€¢Â "Time to Value" was their key metric to drive growth

That bet took [@GammaApp](https://nitter.net/GammaApp "Gamma") to 70M users who can't stop sharing it.

In this weekâ€™s episode of The Library of Minds, Grant breaks down the playbook for building a breakout AI success: staying ruthless on what matters, mastering creator-driven distribution, and hiring painfully slow.

5:10 VC: â€œworst idea Iâ€™ve ever heardâ€ (then rage quit)

10:54 Betting the company on the first 30-seconds

13:05 How to run a micro-influencer program

16:14 The secret benefit to hiring painfully slow

18:12 The pains of scaling

23:29 Grantâ€™s most challenging moment

26:45 How to launch your product

28:12 What Grant is looking for - opportunities

![](https://nitter.net/pic/amplify_video_thumb%2F2024556421602562056%2Fimg%2FDCoach7yVZyLMhWp.jpg%3Fname%3Dsmall%26format%3Dwebp)

Enable hls playback

1

9

[![](https://nitter.net/pic/profile_images%2F1529486127710670849%2Fs7SLhJGz_bigger.jpg)](https://nitter.net/gojira)

[Keiji Kanazawa](https://nitter.net/gojira "Keiji Kanazawa")

[@gojira](https://nitter.net/gojira "@gojira")

[21h](https://nitter.net/gojira/status/2024914503553745119#m "Feb 20, 2026 Â· 6:30 PM UTC")

I am finding the Claude Code /insights feature very fun to run - lots of great suggestions AND one suggestion was something I built with Claude Code right before I ran /insights! cc [@trq212](https://nitter.net/trq212 "Thariq") [@\_catwu](https://nitter.net/_catwu "cat")

[![](https://nitter.net/pic/media%2FHBnw4xxaIAARjBf.png%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBnw4xxaIAARjBf.png)

2

[![](https://nitter.net/pic/profile_images%2F759051761487187968%2F24OG0RCC_bigger.jpg)](https://nitter.net/mmitchell_ai)

[MMitchell](https://nitter.net/mmitchell_ai "MMitchell")

[@mmitchell\_ai](https://nitter.net/mmitchell_ai "@mmitchell_ai")

[21h](https://nitter.net/mmitchell_ai/status/2024914350759444879#m "Feb 20, 2026 Â· 6:29 PM UTC")

This is really important/relevant from the perspective of how power is centralized in AI. [@AINowInstitute](https://nitter.net/AINowInstitute "AI Now Institute") in particular has had some great scholarship on the role of Cloud infrastructure in AI:
[ainowinstitute.org/publicatiâ€¦](https://ainowinstitute.org/publications/compute-and-ai)

![](https://nitter.net/pic/profile_images%2F759051761487187968%2F24OG0RCC_mini.jpg)[MMitchell](https://nitter.net/mmitchell_ai "MMitchell")

[@mmitchell\_ai](https://nitter.net/mmitchell_ai "@mmitchell_ai")

[21h](https://nitter.net/mmitchell_ai/status/2024912597699698833#m "Feb 20, 2026 Â· 6:22 PM UTC")

ðŸ¤– Pleased to share that [@huggingface](https://nitter.net/huggingface "Hugging Face") has now joined with the leading architect for \*\*local\*\* (that is, on your own computer) AI: [ggml.ai](http://ggml.ai/) (the people behind llama.cpp)
[github.com/ggml-org/llama.cpâ€¦](https://github.com/ggml-org/llama.cpp/discussions/19759) [github.com/ggml-org/llama.cpâ€¦](https://github.com/ggml-org/llama.cpp)

4

11

[![](https://nitter.net/pic/profile_images%2F1866142753127616512%2FDYcE9bN1_bigger.jpg)](https://nitter.net/EpochAIResearch)

[Epoch AI](https://nitter.net/EpochAIResearch "Epoch AI")

[@EpochAIResearch](https://nitter.net/EpochAIResearch "@EpochAIResearch")

[21h](https://nitter.net/EpochAIResearch/status/2024914060421308472#m "Feb 20, 2026 Â· 6:28 PM UTC")

Gemini 3.1 Pro scored comparably to Gemini 3 Pro on FrontierMath.

It also solved a Tier 4 problem that no model has solved before, though not how a human would. See thread for the problem authorâ€™s reaction.

[![](https://nitter.net/pic/media%2FHBnwmtfbYAA6ZRu.png%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBnwmtfbYAA6ZRu.png)

14

19

335

[more replies](https://nitter.net/EpochAIResearch/status/2024914090863505470#m)

[![](https://nitter.net/pic/profile_images%2F1866142753127616512%2FDYcE9bN1_bigger.jpg)](https://nitter.net/EpochAIResearch)

[Epoch AI](https://nitter.net/EpochAIResearch "Epoch AI")

[@EpochAIResearch](https://nitter.net/EpochAIResearch "@EpochAIResearch")

[21h](https://nitter.net/EpochAIResearch/status/2024914090863505470#m "Feb 20, 2026 Â· 6:28 PM UTC")

We accidentally ran Gemini 3.1 Pro on Tier 4 a second time. The score above reflects the first, official run. But we noticed in the second run that it had solved a problem no model had solved before. The newly-solved problem is by Emmanuel Breuillard. He had this to say.

[![](https://nitter.net/pic/media%2FHBnwopMaMAA9wmL.png%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBnwopMaMAA9wmL.png)

4

4

91

[![](https://nitter.net/pic/profile_images%2F1866142753127616512%2FDYcE9bN1_bigger.jpg)](https://nitter.net/EpochAIResearch)

[Epoch AI](https://nitter.net/EpochAIResearch "Epoch AI")

[@EpochAIResearch](https://nitter.net/EpochAIResearch "@EpochAIResearch")

[21h](https://nitter.net/EpochAIResearch/status/2024914103073210613#m "Feb 20, 2026 Â· 6:28 PM UTC")

See our benchmarking hub for more, including Gemini 3.1 Pro scores on other benchmarks!

[epoch.ai/benchmarks](https://epoch.ai/benchmarks)

[![](https://nitter.net/pic/card_img%2F2023743425686695936%2FqPTJHEb3%3Fformat%3Dpng%26name%3D800x419)\\
\\
**Data on AI Benchmarking** \\
\\
Our database of benchmark results, featuring the performance of leading AI models on challenging tasks. It includes results from benchmarks evaluated internally by Epoch AI as well as data collected...\\
\\
epoch.ai](https://epoch.ai/benchmarks)

22

[![](https://nitter.net/pic/profile_images%2F1652169745037242368%2FKRPTShbG_bigger.jpg)](https://nitter.net/teortaxesTex)

[Teortaxesâ–¶ï¸ (DeepSeek æŽ¨ç‰¹ðŸ‹é“ç²‰ 2023 â€“ âˆž)](https://nitter.net/teortaxesTex "Teortaxesâ–¶ï¸ (DeepSeek æŽ¨ç‰¹ðŸ‹é“ç²‰ 2023 â€“ âˆž)")

[@teortaxesTex](https://nitter.net/teortaxesTex "@teortaxesTex")

[22h](https://nitter.net/teortaxesTex/status/2024906771093987707#m "Feb 20, 2026 Â· 5:59 PM UTC")

The obsession with Â«personal dataÂ» (and fear that Chyna will unscrupulously use it) is a legacy of the more degenerate pre-AI Â«big dataÂ» IT culture that optimized ad clicks. We can do that, eg to put a LLaMA 4 checkpoint higher on the LMArena, but it'sâ€¦ kind of futile.

![](https://nitter.net/pic/profile_images%2F1837802996723597312%2FJk4w7gjp_mini.jpg)[Zephyr](https://nitter.net/zephyr_z9 "Zephyr")

[@zephyr\_z9](https://nitter.net/zephyr_z9 "@zephyr_z9")

[22h](https://nitter.net/zephyr_z9/status/2024904933703909743#m "Feb 20, 2026 Â· 5:52 PM UTC")

Personal data has zero value for training AI LLMs rn

Labs need highly specialized data
For example, data on how a doctor diagnoses a patient (steps for identifying the illness, reading medical reports etc), a Math/Physics PhD solving hard problems, an engineer designing a project etc

4

2

44

[![](https://nitter.net/pic/profile_images%2F1652169745037242368%2FKRPTShbG_bigger.jpg)](https://nitter.net/teortaxesTex)

[Teortaxesâ–¶ï¸ (DeepSeek æŽ¨ç‰¹ðŸ‹é“ç²‰ 2023 â€“ âˆž)](https://nitter.net/teortaxesTex "Teortaxesâ–¶ï¸ (DeepSeek æŽ¨ç‰¹ðŸ‹é“ç²‰ 2023 â€“ âˆž)")

[@teortaxesTex](https://nitter.net/teortaxesTex "@teortaxesTex")

[21h](https://nitter.net/teortaxesTex/status/2024914011595149705#m "Feb 20, 2026 Â· 6:28 PM UTC")

I do hope that [@StepFun\_ai](https://nitter.net/StepFun_ai "StepFun") and [@CyouSakura](https://nitter.net/CyouSakura "Yasmine") (not to mention the whale) train on my data though. They just need to have some reasonable algo for grading conversations as more and less useful

1

6

[![](https://nitter.net/pic/profile_images%2F1506134877237747714%2FDk_MGsbp_bigger.jpg)](https://nitter.net/john__allard)

[john allard](https://nitter.net/john__allard "john allard")

[@john\_\_allard](https://nitter.net/john__allard "@john__allard")

[21h](https://nitter.net/john__allard/status/2024913919077429496#m "Feb 20, 2026 Â· 6:27 PM UTC")

sending me down a Kriss rabbit hole after remembering what good prose is like

[open.substack.com/pub/samkriâ€¦](https://open.substack.com/pub/samkriss)

![](https://nitter.net/pic/profile_images%2F1953893098226135040%2FuBWJVcPh_mini.jpg)[Daniel](https://nitter.net/growing_daniel "Daniel")

[@growing\_daniel](https://nitter.net/growing_daniel "@growing_daniel")

[Feb 20](https://nitter.net/growing_daniel/status/2024862318782263377#m "Feb 20, 2026 Â· 3:02 PM UTC")

This article is so good [harpers.org/archive/2026/03/â€¦](https://harpers.org/archive/2026/03/childs-play-sam-kriss-ai-startup-roy-lee/)

1

4

Rachel Woods retweeted

[![](https://nitter.net/pic/profile_images%2F1774844664383987715%2FeJ2WA45U_bigger.jpg)](https://nitter.net/Replit)

[Replit â •](https://nitter.net/Replit "Replit â •")

[@Replit](https://nitter.net/Replit "@Replit")

[Feb 19](https://nitter.net/Replit/status/2024578806208745637#m "Feb 19, 2026 Â· 8:16 PM UTC")

Introducing Replit Animation

Vibecode your next viral video in minutes, powered by Gemini 3.1 Pro.

(This video was 100% made in Replit Animation)

![](https://nitter.net/pic/amplify_video_thumb%2F2024578650725896194%2Fimg%2FLwSI24YQdc_y53iL.jpg%3Fname%3Dsmall%26format%3Dwebp)

Enable hls playback

257

389

5,919

clem ðŸ¤— retweeted

[![](https://nitter.net/pic/profile_images%2F378800000261649705%2Fbe9cc55e64014e6d7663c50d7cb9fc75_bigger.jpeg)](https://nitter.net/simonw)

[Simon Willison](https://nitter.net/simonw "Simon Willison")

[@simonw](https://nitter.net/simonw "@simonw")

[22h](https://nitter.net/simonw/status/2024895405146997002#m "Feb 20, 2026 Â· 5:14 PM UTC")

Shared some thoughts on [ggml.ai](http://ggml.ai/) joining Hugging Face - they've been a good steward of the crucial Transformers open source library so I'm optimistic that great things are ahead for [ggml.ai](http://ggml.ai/), which kicked off the local model revolution back in March 2023 [simonwillison.net/2026/Feb/2â€¦](https://simonwillison.net/2026/Feb/20/ggmlai-joins-hugging-face/)

11

14

166

Baseten retweeted

[![](https://nitter.net/pic/profile_images%2F1735286803777683456%2F3F_Hr4iA_bigger.jpg)](https://nitter.net/EvidenceOpen)

[OpenEvidence](https://nitter.net/EvidenceOpen "OpenEvidence")

[@EvidenceOpen](https://nitter.net/EvidenceOpen "@EvidenceOpen")

[21h](https://nitter.net/EvidenceOpen/status/2024911505922380044#m "Feb 20, 2026 Â· 6:18 PM UTC")

Most medical AI companies rent their intelligence. We train ours. Today [@basetenco](https://nitter.net/basetenco "Baseten") published a case study on how we do it: why we build domain-specific models on peer-reviewed literature instead of using general-purpose AI off the shelf, and what that means for the doctors who use OpenEvidence every day.

![](https://nitter.net/pic/profile_images%2F1924485072801140736%2FVyZekL_z_mini.jpg)[Baseten](https://nitter.net/basetenco "Baseten")

[@basetenco](https://nitter.net/basetenco "@basetenco")

[23h](https://nitter.net/basetenco/status/2024891915637063714#m "Feb 20, 2026 Â· 5:00 PM UTC")

"No other product lets you launch ten different training jobs on four different datasets." â€“Head of Clinical NLP, OpenEvidence

Over 40% of U.S. physicians trust [@EvidenceOpen](https://nitter.net/EvidenceOpen "OpenEvidence")'s platform for fast, accurate medical information. Their secret: custom, specialized models built on Baseten Training.

Here's how we helped them save $1.9M via model training and improved their latency 23x to power 100M+ clinical consultations per year.

[baseten.co/resources/customeâ€¦](https://www.baseten.co/resources/customers/openevidence-baseten-training)

[![](https://nitter.net/pic/media%2FHBncdwNaAAAABFV.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBncdwNaAAAABFV.jpg)

9

11

97

swyx retweeted

[![](https://nitter.net/pic/profile_images%2F1778898223165521920%2F8FfWUPa__bigger.jpg)](https://nitter.net/sarahdingwang)

[Sarah Wang](https://nitter.net/sarahdingwang "Sarah Wang")

[@sarahdingwang](https://nitter.net/sarahdingwang "@sarahdingwang")

[Feb 20](https://nitter.net/sarahdingwang/status/2024868959225594171#m "Feb 20, 2026 Â· 3:29 PM UTC")

Takeaways from my talk with [@swyx](https://nitter.net/swyx "swyx"), [@FanaHOVA](https://nitter.net/FanaHOVA "Alessio Fanelli"), and [@martin\_casado](https://nitter.net/martin_casado "martin_casado") about frontier labs, AGI, coding agents, the new capital flywheel, talent wars, and more:

[![](https://nitter.net/pic/media%2FHBnHK71bMAAdE7T.png%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBnHK71bMAAdE7T.png)

![](https://nitter.net/pic/profile_images%2F1888346877428641792%2FrMxtG84Z_mini.jpg)[Latent.Space](https://nitter.net/latentspacepod "Latent.Space")

[@latentspacepod](https://nitter.net/latentspacepod "@latentspacepod")

[Feb 19](https://nitter.net/latentspacepod/status/2024526225411362945#m "Feb 19, 2026 Â· 4:47 PM UTC")

From pioneering software-defined networking to backing many of the most ambitious AI labs of this cycle, Martin Casado and Sarah Wang sit at the center of AIâ€™s capital and capability arms race.

We sat down with the a16z duo to unpack how AI investing fundamentally changed: why todayâ€™s $100Mâ€“$1B rounds are really compute financing vehicles, how venture and growth have blurred into hybrid deals, what it means when model companies can translate dollars directly into capability gains, and whether we are heading towards a boom of specialized apps or a small oligopoly of general models that subsume everything above them.

[@martin\_casado](https://nitter.net/martin_casado "martin_casado") [@sarahdingwang](https://nitter.net/sarahdingwang "Sarah Wang") [@a16z](https://nitter.net/a16z "a16z")

![](https://nitter.net/pic/amplify_video_thumb%2F2024517571106791425%2Fimg%2Fxa6ogF4jesLG5gqu.jpg%3Fname%3Dsmall%26format%3Dwebp)

Enable hls playback

3

4

39

[![](https://nitter.net/pic/profile_images%2F1623522272920350720%2F031Q5t3R_bigger.jpg)](https://nitter.net/rachel_l_woods)

[Rachel Woods](https://nitter.net/rachel_l_woods "Rachel Woods")

[@rachel\_l\_woods](https://nitter.net/rachel_l_woods "@rachel_l_woods")

[21h](https://nitter.net/rachel_l_woods/status/2024913079864324386#m "Feb 20, 2026 Â· 6:24 PM UTC")

This is sick

![](https://nitter.net/pic/profile_images%2F1908611434898206720%2FCRup1_nM_mini.jpg)[Howie Liu](https://nitter.net/howietl "Howie Liu")

[@howietl](https://nitter.net/howietl "@howietl")

[Feb 19](https://nitter.net/howietl/status/2024618178912145592#m "Feb 19, 2026 Â· 10:52 PM UTC")

I've been personally burning through billions of tokens a week for the past few months as a builder. Today I'm excited to announce Hyperagent, by Airtable.

An agents platform where every session gets its own isolated, full computing environment in the cloud â€” no Mac Mini required. Real browser, code execution, image/video generation, data warehouse access, hundreds of integrations, and the ability to learn any new API as a skill.

Deep domain expertise through skill learning. Teach the agent how your firm evaluates startups or how your team runs due diligence â€” now anyone on the team gets output that reflects your actual methodology, not a generic template.

One-click deployment into Slack as intelligent coworkers. These aren't bots that wait to be [@mentioned](https://nitter.net/mentioned "Mentioned") â€” they follow conversations, understand context, and act when relevant.

And a command center to oversee and continuously improve your entire fleet of agents at scale.

We're onboarding early users now. [hyperagent.com](http://hyperagent.com/)

![](https://nitter.net/pic/amplify_video_thumb%2F2024618025618726912%2Fimg%2FGMEiIVergSz48o2K.jpg%3Fname%3Dsmall%26format%3Dwebp)

Enable hls playback

1

1

6

[![](https://nitter.net/pic/profile_images%2F759051761487187968%2F24OG0RCC_bigger.jpg)](https://nitter.net/mmitchell_ai)

[MMitchell](https://nitter.net/mmitchell_ai "MMitchell")

[@mmitchell\_ai](https://nitter.net/mmitchell_ai "@mmitchell_ai")

[21h](https://nitter.net/mmitchell_ai/status/2024912597699698833#m "Feb 20, 2026 Â· 6:22 PM UTC")

ðŸ¤– Pleased to share that [@huggingface](https://nitter.net/huggingface "Hugging Face") has now joined with the leading architect for \*\*local\*\* (that is, on your own computer) AI: [ggml.ai](http://ggml.ai/) (the people behind llama.cpp)
[github.com/ggml-org/llama.cpâ€¦](https://github.com/ggml-org/llama.cpp/discussions/19759) [github.com/ggml-org/llama.cpâ€¦](https://github.com/ggml-org/llama.cpp)

[![](https://nitter.net/pic/card_img%2F2021332570122616833%2FfBkEvzzJ%3Fformat%3Djpg%26name%3D800x419)\\
\\
**GitHub - ggml-org/llama.cpp: LLM inference in C/C++** \\
\\
LLM inference in C/C++. Contribute to ggml-org/llama.cpp development by creating an account on GitHub.\\
\\
github.com](https://github.com/ggml-org/llama.cpp)

2

5

34

Kevin Fischer retweeted

[![](https://nitter.net/pic/profile_images%2F1899795293991800832%2FyFjmMj-__bigger.jpg)](https://nitter.net/wildmindai)

[Wildminder](https://nitter.net/wildmindai "Wildminder")

[@wildmindai](https://nitter.net/wildmindai "@wildmindai")

[Feb 20](https://nitter.net/wildmindai/status/2024810128487096357#m "Feb 20, 2026 Â· 11:35 AM UTC")

17,000 tokens per second!! Read that again!
LLM is hard-wired directly into silicon. no HBM, no liquid cooling, just raw specialized hardware. 10x faster and 20x cheaper than a B200.
the "waiting for the LLM to think" era is dead. Code generates at the speed of human thought.
Transition from brute-force GPU clusters to actual AI appliances.
[taalas.com/the-path-to-ubiquâ€¦](https://taalas.com/the-path-to-ubiquitous-ai/)

[![](https://nitter.net/pic/media%2FHBmRwSBXMAAcy3K.png%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBmRwSBXMAAcy3K.png)

[![](https://nitter.net/pic/media%2FHBmRwSAWcAAOWdo.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBmRwSAWcAAOWdo.jpg)

[![](https://nitter.net/pic/media%2FHBmR3WIWcAAVaaa.png%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBmR3WIWcAAVaaa.png)

346

825

6,727

[![](https://nitter.net/pic/profile_images%2F1971338830839152640%2FAUCsbrUV_bigger.png)](https://nitter.net/yupp_ai)

[Yupp](https://nitter.net/yupp_ai "Yupp")

[@yupp\_ai](https://nitter.net/yupp_ai "@yupp_ai")

[21h](https://nitter.net/yupp_ai/status/2024911754359411187#m "Feb 20, 2026 Â· 6:19 PM UTC")

"I need to wash my car. The car wash is 100 meters away. Should I walk or drive?" ðŸš˜ðŸ«§

We asked 4 AI models this question on Yupp.

2 got it. 2 completely face-planted.

13

6

41

[more replies](https://nitter.net/yupp_ai/status/2024911813557846417#m)

[![](https://nitter.net/pic/profile_images%2F1971338830839152640%2FAUCsbrUV_bigger.png)](https://nitter.net/yupp_ai)

[Yupp](https://nitter.net/yupp_ai "Yupp")

[@yupp\_ai](https://nitter.net/yupp_ai "@yupp_ai")

[21h](https://nitter.net/yupp_ai/status/2024911813557846417#m "Feb 20, 2026 Â· 6:19 PM UTC")

AI models can solve differential equations, write code, and pass the bar exam, but sometimes miss something a five-year-old would catch.

The edges aren't where you expect them.

1

4

[![](https://nitter.net/pic/profile_images%2F1971338830839152640%2FAUCsbrUV_bigger.png)](https://nitter.net/yupp_ai)

[Yupp](https://nitter.net/yupp_ai "Yupp")

[@yupp\_ai](https://nitter.net/yupp_ai "@yupp_ai")

[21h](https://nitter.net/yupp_ai/status/2024911825230594201#m "Feb 20, 2026 Â· 6:19 PM UTC")

This is why comparing models matters.

No single benchmark tells you which model will fumble YOUR question. But running the same prompt across multiple models can reveal the gaps in real time.

Want to figure out your own car logistics? Prompt over 900 AIs for free on Yupp!

3

[![](https://nitter.net/pic/profile_images%2F1995170376175976448%2FvK7vtqQn_bigger.jpg)](https://nitter.net/hrishioa)

[Hrishi](https://nitter.net/hrishioa "Hrishi")

[@hrishioa](https://nitter.net/hrishioa "@hrishioa")

[21h](https://nitter.net/hrishioa/status/2024911685841191193#m "Feb 20, 2026 Â· 6:19 PM UTC")

You wouldn't vibe a car
You wouldn't vibe a house

You wouldn't vibe the important agents in your life and work

[southbridge.ai/hankweave](http://southbridge.ai/hankweave)

[![](https://nitter.net/pic/card_img%2F2024832931806773248%2FfL7ZY1HY%3Fformat%3Djpg%26name%3D800x419)\\
\\
**Hankweave - A runtime for repairable agents** \\
\\
Open-source runtime for maintainable, long-horizon AI agents. Repair instead of rebuild.\\
\\
southbridge.ai](http://southbridge.ai/hankweave)

2

1

10

[![](https://nitter.net/pic/profile_images%2F1831493788679761920%2F-q9w6dzd_bigger.jpg)](https://nitter.net/scaling01)

[Lisan al Gaib](https://nitter.net/scaling01 "Lisan al Gaib")

[@scaling01](https://nitter.net/scaling01 "@scaling01")

[Feb 20](https://nitter.net/scaling01/status/2024640940657246235#m "Feb 20, 2026 Â· 12:23 AM UTC")

[x.com/i/article/202462313394â€¦](http://x.com/i/article/2024623133945106432)

16

24

444

[![](https://nitter.net/pic/profile_images%2F1831493788679761920%2F-q9w6dzd_bigger.jpg)](https://nitter.net/scaling01)

[Lisan al Gaib](https://nitter.net/scaling01 "Lisan al Gaib")

[@scaling01](https://nitter.net/scaling01 "@scaling01")

[21h](https://nitter.net/scaling01/status/2024911396014567921#m "Feb 20, 2026 Â· 6:17 PM UTC")

![](https://nitter.net/pic/profile_images%2F1831493788679761920%2F-q9w6dzd_mini.jpg)[Lisan al Gaib](https://nitter.net/scaling01 "Lisan al Gaib")

[@scaling01](https://nitter.net/scaling01 "@scaling01")

[22h](https://nitter.net/scaling01/status/2024898141883871709#m "Feb 20, 2026 Â· 5:25 PM UTC")

As promised, I uploaded the code to a fork of the ARC-AGI-3-benchmarking repo:
\- [github.com/voice-from-the-ouâ€¦](https://github.com/voice-from-the-outer-world/arc-agi-3-benchmarking)

What I added:
\- my \`state-memory\` agent
\- Local live results viewer with playback and per-step details (action, reasoning, memory, full model input/output)
\- a silly download GIF button on the dashboard in case someone wants to share results of other models
\- a bunch of models incl. Gemini 3.1 Pro and Opus 4.6 via OpenRouter

Everything on how to use it is in the README.

Please don't ask me about any naming like why "state-memory" or why the new agent is in the adcr-agent's directory. It was all designed by the GPT-5.3-Codex gods. I don't dare to question their choices. Just want you to be able to try it out yourself.

This is expensive to run (at least for me). If you run all 3 games with 50 actions Gemini 3.1 Pro will set you back about $15-20. Opus-4.6-Thinking will set you back $35-45.

Smaller models like GLM-5, Kimi-K2.5 Thinking or Gemini-3 Flash are kinda pointless to run, but they will be $5-10 for the 50 steps for each of the 3 games.

I would love to see Opus 4.6 Thinking, GPT-5.2-xhigh and Gemini 3.1 Pro just run all the games until they get stuck or lose.

3

swyx retweeted

[![](https://nitter.net/pic/profile_images%2F1768170876158013440%2FgePr9qFl_bigger.jpg)](https://nitter.net/byAnhtho)

[anhtho ðŸŠ](https://nitter.net/byAnhtho "anhtho ðŸŠ")

[@byAnhtho](https://nitter.net/byAnhtho "@byAnhtho")

[Feb 20](https://nitter.net/byAnhtho/status/2024863500468629584#m "Feb 20, 2026 Â· 3:07 PM UTC")

[x.com/i/article/202456729285â€¦](http://x.com/i/article/2024567292856807424)

7

7

41

[![](https://nitter.net/pic/profile_images%2F1831493788679761920%2F-q9w6dzd_bigger.jpg)](https://nitter.net/scaling01)

[Lisan al Gaib](https://nitter.net/scaling01 "Lisan al Gaib")

[@scaling01](https://nitter.net/scaling01 "@scaling01")

[21h](https://nitter.net/scaling01/status/2024911119844839883#m "Feb 20, 2026 Â· 6:16 PM UTC")

holy shit the results for Gemini 3.1 Pro are crazy

15th place

what the hell man

[![](https://nitter.net/pic/media%2FHBntyA3XcAElJtt.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBntyA3XcAElJtt.jpg)

20

4

313

[![](https://nitter.net/pic/profile_images%2F1831493788679761920%2F-q9w6dzd_bigger.jpg)](https://nitter.net/scaling01)

[Lisan al Gaib](https://nitter.net/scaling01 "Lisan al Gaib")

[@scaling01](https://nitter.net/scaling01 "@scaling01")

[21h](https://nitter.net/scaling01/status/2024911203772866851#m "Feb 20, 2026 Â· 6:17 PM UTC")

[andonlabs.com/evals/vending-â€¦](https://andonlabs.com/evals/vending-bench-2)

[![](https://nitter.net/pic/card_img%2F2023569983758864384%2FwJ8iH5d4%3Fformat%3Djpg%26name%3D800x419)\\
\\
**Vending-Bench 2 \| Andon Labs** \\
\\
We're releasing Vending-Bench 2, a benchmark for measuring AI model performance on running a business over long time horizons. Models are tasked with running a simulated vending machine business over...\\
\\
andonlabs.com](https://andonlabs.com/evals/vending-bench-2)

1

14

[![](https://nitter.net/pic/profile_images%2F1850957204570193920%2FpBuQN2tH_bigger.jpg)](https://nitter.net/jd_pressman)

[John David Pressman](https://nitter.net/jd_pressman "John David Pressman")

[@jd\_pressman](https://nitter.net/jd_pressman "@jd_pressman")

[21h](https://nitter.net/jd_pressman/status/2024911121904533835#m "Feb 20, 2026 Â· 6:16 PM UTC")

It was very polite of Hanson to call this the dreamtime. What we are in is the cope time, we have spent the preceding decades consoling ourselves about the obvious convergence point of history by replacing the place where neither liberty or stories exist with slop like Star Trek.

![](https://nitter.net/pic/profile_images%2F1997065021491130368%2FX76ALSbp_mini.jpg)[Dean W. Ball](https://nitter.net/deanwball "Dean W. Ball")

[@deanwball](https://nitter.net/deanwball "@deanwball")

[Feb 17](https://nitter.net/deanwball/status/2023853871127556232#m "Feb 17, 2026 Â· 8:15 PM UTC")

We are obviously making god-tier technology in so many areas the and the answer cannot be â€œoh yeah, I guess the government is actually just god.â€ This clearly doesnâ€™t work. Please argue to me with a straight face that the founding fathers intended this.

1

4

68

[![](https://nitter.net/pic/profile_images%2F1652169745037242368%2FKRPTShbG_bigger.jpg)](https://nitter.net/teortaxesTex)

[Teortaxesâ–¶ï¸ (DeepSeek æŽ¨ç‰¹ðŸ‹é“ç²‰ 2023 â€“ âˆž)](https://nitter.net/teortaxesTex "Teortaxesâ–¶ï¸ (DeepSeek æŽ¨ç‰¹ðŸ‹é“ç²‰ 2023 â€“ âˆž)")

[@teortaxesTex](https://nitter.net/teortaxesTex "@teortaxesTex")

[21h](https://nitter.net/teortaxesTex/status/2024910062817276282#m "Feb 20, 2026 Â· 6:12 PM UTC")

Fascinating

[![](https://nitter.net/pic/media%2FHBns9tQWYAAMomb.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBns9tQWYAAMomb.jpg)

![](https://nitter.net/pic/profile_images%2F1994384013767966721%2Fux5FL4tY_mini.jpg)[Imperial Standard](https://nitter.net/imperial_flag "Imperial Standard")

[@imperial\_flag](https://nitter.net/imperial_flag "@imperial_flag")

[Feb 19](https://nitter.net/imperial_flag/status/2024532495639994872#m "Feb 19, 2026 Â· 5:12 PM UTC")

Not gonna lie; I used to look down on livestreaming as basically "Onlyfans lite". However during my time getting close and helping the Tibetans broadcast their dances, I came to a different realization...

Livestreaming (å°çº¢ä¹¦ & æŠ–éŸ³ï¼‰essentially allows people who is otherwise unemployable in the general market (a lot of Tibetans did not finish high school, let alone uni) to be able to become genuine entrepreneurs WITHOUT sex work (this includes the not so smart folks from the countryside who can't progress beyond primary maths). They'd even lower the barrier of entry into business by allowing you to setup accounts and trade with just real name verification. To just simply moralize over this is not just wrong, but you will be willingly ignorant since you miss the finer details of what is actually happening.

My suggestion is to join one of these platforms and instead of the typical political shitflinging, get engaged to the people who are in the business. Get to know them and their struggles. It is a humbling experience.

1

25

[![](https://nitter.net/pic/profile_images%2F1980278545692676096%2Fr3u3CYOs_bigger.jpg)](https://nitter.net/LangChain)

[LangChain](https://nitter.net/LangChain "LangChain")

[@LangChain](https://nitter.net/LangChain "@LangChain")

[21h](https://nitter.net/LangChain/status/2024910014901543003#m "Feb 20, 2026 Â· 6:12 PM UTC")

Weâ€™re thrilled to be hosting and speaking at [@contrary](https://nitter.net/contrary "Contrary") 's next SF Tech Talk, featuring eng leads from [@cognition\_labs](https://nitter.net/cognition_labs "@cognition"), [@elevenlabsio](https://nitter.net/elevenlabsio "ElevenLabs"), and [@andocorporation](https://nitter.net/andocorporation "âœ¶ Ando"). We'll be speaking to the future of agents.ðŸŽ™ï¸

Each company will live demo their latest product features for leading builders in the Bay Area.

Register: [lnkd.in/gXF5HSzP](https://lnkd.in/gXF5HSzP)

[![](https://nitter.net/pic/media%2FHBnsfb4XMAAvSY3.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBnsfb4XMAAvSY3.jpg)

3

14

[![](https://nitter.net/pic/profile_images%2F1831493788679761920%2F-q9w6dzd_bigger.jpg)](https://nitter.net/scaling01)

[Lisan al Gaib](https://nitter.net/scaling01 "Lisan al Gaib")

[@scaling01](https://nitter.net/scaling01 "@scaling01")

[21h](https://nitter.net/scaling01/status/2024909922635276763#m "Feb 20, 2026 Â· 6:12 PM UTC")

i did not expect that

![](https://nitter.net/pic/profile_images%2F1864729396801945600%2FHfze5w-k_mini.jpg)[Andon Labs](https://nitter.net/andonlabs "Andon Labs")

[@andonlabs](https://nitter.net/andonlabs "@andonlabs")

[22h](https://nitter.net/andonlabs/status/2024906972131459144#m "Feb 20, 2026 Â· 6:00 PM UTC")

Gemini 3.1 Pro does worse than Gemini 3 Pro on Vending-Bench 2.

[![](https://nitter.net/pic/media%2FHBnpEovbgAQ4mmj.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBnpEovbgAQ4mmj.jpg)

6

86

Anthropic retweeted

[![](https://nitter.net/pic/profile_images%2F1950950107937185792%2FQOfEjFoJ_bigger.jpg)](https://nitter.net/claudeai)

[Claude](https://nitter.net/claudeai "Claude")

[@claudeai](https://nitter.net/claudeai "@claudeai")

[21h](https://nitter.net/claudeai/status/2024907535145468326#m "Feb 20, 2026 Â· 6:02 PM UTC")

Introducing Claude Code Security, now in limited research preview.

It scans codebases for vulnerabilities and suggests targeted software patches for human review, allowing teams to find and fix issues that traditional tools often miss.

Learn more: [anthropic.com/news/claude-coâ€¦](https://www.anthropic.com/news/claude-code-security)

![](https://nitter.net/pic/media%2FHBntcaZaoAA7SFR.jpg%3Fname%3Dsmall%26format%3Dwebp)

Enable hls playback

1,654

4,743

41,352

Omar Khattab retweeted

[![](https://nitter.net/pic/profile_images%2F1885412874752774144%2F5tfbNntb_bigger.jpg)](https://nitter.net/rasmus1610)

[Marius Vach](https://nitter.net/rasmus1610 "Marius Vach")

[@rasmus1610](https://nitter.net/rasmus1610 "@rasmus1610")

[21h](https://nitter.net/rasmus1610/status/2024908364715536722#m "Feb 20, 2026 Â· 6:05 PM UTC")

Took the new \`optimize\_anything\` for a spin to optimize a Sudoku solver I wrote a couple of months ago.

14x speedup for $0.27

Very very cool. This is the future.

(notebook in the next tweet)

h/t [@LakshyAAAgrawal](https://nitter.net/LakshyAAAgrawal "Lakshya A Agrawal") [@lateinteraction](https://nitter.net/lateinteraction "Omar Khattab")

[![](https://nitter.net/pic/media%2FHBnq_nEWwAIHeQd.png%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBnq_nEWwAIHeQd.png)

![](https://nitter.net/pic/profile_images%2F1995783519340298240%2F6bHjSLAK_mini.jpg)[Lakshya A Agrawal](https://nitter.net/LakshyAAAgrawal "Lakshya A Agrawal")

[@LakshyAAAgrawal](https://nitter.net/LakshyAAAgrawal "@LakshyAAAgrawal")

[Feb 19](https://nitter.net/LakshyAAAgrawal/status/2024568680324153800#m "Feb 19, 2026 Â· 7:36 PM UTC")

Excited to release [@gepa\_ai](https://nitter.net/gepa_ai "GEPA")'s optimize\_anything: a universal API for optimizing any text parameter.

It consistently matches or outperforms domain-specific tools optimizing code, prompts, agent harnesses, cloud policies, even visuals!

If you can measure it, you can optimize it.

[![](https://nitter.net/pic/media%2FHBinEmEbsAAk5s-.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBinEmEbsAAk5s-.jpg)

4

7

70

Teortaxesâ–¶ï¸ (DeepSeek æŽ¨ç‰¹ðŸ‹é“ç²‰ 2023 â€“ âˆž) retweeted

[![](https://nitter.net/pic/profile_images%2F1742734206600613888%2F-86j-yKu_bigger.jpg)](https://nitter.net/arcticinstincts)

[David Sun](https://nitter.net/arcticinstincts "David Sun")

[@arcticinstincts](https://nitter.net/arcticinstincts "@arcticinstincts")

[Feb 20](https://nitter.net/arcticinstincts/status/2024859615956246996#m "Feb 20, 2026 Â· 2:52 PM UTC")

Itâ€™s over for Acemogluoid institutioncels

North Korea is arriving at the same LED stripmall modernity as South Korea despite having the exact opposite set of institutions and governance style as what Nobel Econcels predicted would work

![](https://nitter.net/pic/profile_images%2F1364488316184371200%2F-RXz6jU5_mini.jpg)[Megatron](https://nitter.net/Megatron_ron "Megatron")

[@Megatron\_ron](https://nitter.net/Megatron_ron "@Megatron_ron")

[Feb 17](https://nitter.net/Megatron_ron/status/2023909488260943980#m "Feb 17, 2026 Â· 11:56 PM UTC")

Everything is calm and safe when you have NUKES

Pyongyang downtown

![](https://nitter.net/pic/amplify_video_thumb%2F2023909418761678848%2Fimg%2FAL2PDG10H3gt3wrp.jpg%3Fname%3Dsmall%26format%3Dwebp)

Enable hls playback

39

84

1,196

[![](https://nitter.net/pic/profile_images%2F1982142240571920384%2Fhla62KCQ_bigger.jpg)](https://nitter.net/mervenoyann)

[merve](https://nitter.net/mervenoyann "merve")

[@mervenoyann](https://nitter.net/mervenoyann "@mervenoyann")

[21h](https://nitter.net/mervenoyann/status/2024907750720110677#m "Feb 20, 2026 Â· 6:03 PM UTC")

all of us at [@huggingface](https://nitter.net/huggingface "Hugging Face") today

[![](https://nitter.net/pic/media%2FHBnq2nsXgAAlET5.png%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBnq2nsXgAAlET5.png)

4

49

[![](https://nitter.net/pic/profile_images%2F1972718204565811200%2FadTFhODz_bigger.jpg)](https://nitter.net/Google)

[Google](https://nitter.net/Google "Google")

[@Google](https://nitter.net/Google "@Google")

[21h](https://nitter.net/Google/status/2024907255334715763#m "Feb 20, 2026 Â· 6:01 PM UTC")

Now, you can turn a single image into professional-grade product shots with Pomelli's latest feature update â€œPhotoshootâ€ from [@GoogleLabs](https://nitter.net/GoogleLabs "Google Labs").

![](https://nitter.net/pic/profile_images%2F1792661411102863360%2FfzzB7K-f_mini.png)[Google Labs](https://nitter.net/GoogleLabs "Google Labs")

[@GoogleLabs](https://nitter.net/GoogleLabs "@GoogleLabs")

[Feb 19](https://nitter.net/GoogleLabs/status/2024529795548102667#m "Feb 19, 2026 Â· 5:01 PM UTC")

Today, weâ€™re introducing Pomelliâ€™s latest feature update, â€˜Photoshootâ€™

With Photoshoot, you can start from a single image of your product and easily create high quality, customized product shots to elevate your marketing.

Available free of charge in the US, Canada, Australia & New Zealand! Get started with Pomelli today at [labs.google/pomelli](http://labs.google/pomelli)

![](https://nitter.net/pic/amplify_video_thumb%2F2024529726472077313%2Fimg%2F0HevvziuUCfnQgYH.jpg%3Fname%3Dsmall%26format%3Dwebp)

Enable hls playback

45

54

540

[![](https://nitter.net/pic/profile_images%2F1972718204565811200%2FadTFhODz_bigger.jpg)](https://nitter.net/Google)

[Google](https://nitter.net/Google "Google")

[@Google](https://nitter.net/Google "@Google")

[21h](https://nitter.net/Google/status/2024907734911504442#m "Feb 20, 2026 Â· 6:03 PM UTC")

Available free of charge in the U.S., Canada, Australia & New Zealand.

Try it out â†“
[labs.google.com/pomelli](http://labs.google.com/pomelli)

16

10

74

[![](https://nitter.net/pic/profile_images%2F1319081238439751681%2FkCcqnwoF_bigger.jpg)](https://nitter.net/Yuchenj_UW)

[Yuchen Jin](https://nitter.net/Yuchenj_UW "Yuchen Jin")

[@Yuchenj\_UW](https://nitter.net/Yuchenj_UW "@Yuchenj_UW")

[21h](https://nitter.net/Yuchenj_UW/status/2024907354656178257#m "Feb 20, 2026 Â· 6:01 PM UTC")

Itâ€™s wild that AI might replace software engineers before it replaces the 100,000 customer support reps at Amazon.

The people who build the automation get automated first.

What a weird simulation weâ€™re living in.

131

43

1,010

[![](https://nitter.net/pic/profile_images%2F1652169745037242368%2FKRPTShbG_bigger.jpg)](https://nitter.net/teortaxesTex)

[Teortaxesâ–¶ï¸ (DeepSeek æŽ¨ç‰¹ðŸ‹é“ç²‰ 2023 â€“ âˆž)](https://nitter.net/teortaxesTex "Teortaxesâ–¶ï¸ (DeepSeek æŽ¨ç‰¹ðŸ‹é“ç²‰ 2023 â€“ âˆž)")

[@teortaxesTex](https://nitter.net/teortaxesTex "@teortaxesTex")

[21h](https://nitter.net/teortaxesTex/status/2024907217171087669#m "Feb 20, 2026 Â· 6:01 PM UTC")

âœï¸ Expanded Teortaxes Lore, this one goes a bit hard:
\> maximally determinist. He loves the strong and hates the weak.

![](https://nitter.net/pic/profile_images%2F1344886968275103747%2FofG5u2H__mini.jpg)[Chris KoulikosðŸ‡¬ðŸ‡·ðŸ‡ªðŸ‡º](https://nitter.net/ChrisDudensen "Chris KoulikosðŸ‡¬ðŸ‡·ðŸ‡ªðŸ‡º") [@ChrisDudensen](https://nitter.net/ChrisDudensen "@ChrisDudensen")

[Feb 20](https://nitter.net/ChrisDudensen/status/2024838166503383288#m "Feb 20, 2026 Â· 1:26 PM UTC")

Replying to [@rcampeligro](https://nitter.net/rcampeligro) [@Boba\_is\_back\_on](https://nitter.net/Boba_is_back_on) [@teortaxesTex](https://nitter.net/teortaxesTex)

Trust me he isn't, and he has been unnecessarily charitable to Indians if I may say so at times (i.e. sarvam model or whatever it's called). The thing with Teor is that he is maximally determinist. He loves the strong and hates the weak.

6

45

akbir. retweeted

[![](https://nitter.net/pic/profile_images%2F1631791210535739392%2F82V2CaDx_bigger.jpg)](https://nitter.net/AlexPalcuie)

[palcu](https://nitter.net/AlexPalcuie "palcu")

[@AlexPalcuie](https://nitter.net/AlexPalcuie "@AlexPalcuie")

[Feb 20](https://nitter.net/AlexPalcuie/status/2024850720239812685#m "Feb 20, 2026 Â· 2:16 PM UTC")

Replying to [@AlexPalcuie](https://nitter.net/AlexPalcuie) [@AISecurityInst](https://nitter.net/AISecurityInst)

gift link for those of you non-subscribers

[economist.com/britain/2026/0â€¦](https://www.economist.com/britain/2026/02/19/britain-is-the-closest-the-world-has-to-an-ai-safety-inspector?giftId=N2RkZDY2NTEtNzk0Ny00ZDBiLTkyNTEtMWVhMzhmNGJjNzc5&utm_campaign=gifted_article)

[![](https://nitter.net/pic/card_img%2F2024527846954176512%2FuYMe0c5Z%3Fformat%3Djpg%26name%3D800x419)\\
\\
**Britain is the closest the world has to an AI safety inspector** \\
\\
But having the first (and best) AI security institute is no excuse for the country to rest on its laurels\\
\\
economist.com](https://www.economist.com/britain/2026/02/19/britain-is-the-closest-the-world-has-to-an-ai-safety-inspector?giftId=N2RkZDY2NTEtNzk0Ny00ZDBiLTkyNTEtMWVhMzhmNGJjNzc5&utm_campaign=gifted_article)

1

1

8

[![](https://nitter.net/pic/profile_images%2F1940093473564073984%2FjiafRcO0_bigger.png)](https://nitter.net/GeminiApp)

[Google Gemini](https://nitter.net/GeminiApp "Google Gemini")

[@GeminiApp](https://nitter.net/GeminiApp "@GeminiApp")

[22h](https://nitter.net/GeminiApp/status/2024906781781373116#m "Feb 20, 2026 Â· 5:59 PM UTC")

Make your first track with Lyria 3 in seconds using templates.

Donâ€™t know where to start? Open the Gemini app, select "Create Music" from the tools menu, and explore templates like 8-bit or folk ballad from the gallery to find the vibe youâ€™re going for. â¬‡ï¸

![](https://nitter.net/pic/pbs.twimg.com%2Fmedia%2FHBnkiykbgAI_0ju.jpg%3Fname%3Dsmall%26format%3Dwebp)

Enable hls playback

[Create Music in Gemini Today\\
\\
google.com](https://gemini.google.com/app/download/mobile?android-min-version=301356232&ios-min-version=322.0&is_sa=1&campaign_id=lyria_boosting&utm_source=x&utm_medium=paid-social&utm_campaign=lyria_boosting&pt=9008&mt=8&ct=paid-social_x_lyria_boosting&redirect=home)

58

55

437

[![](https://nitter.net/pic/profile_images%2F1940093473564073984%2FjiafRcO0_bigger.png)](https://nitter.net/GeminiApp)

[Google Gemini](https://nitter.net/GeminiApp "Google Gemini")

[@GeminiApp](https://nitter.net/GeminiApp "@GeminiApp")

[22h](https://nitter.net/GeminiApp/status/2024906993040064775#m "Feb 20, 2026 Â· 6:00 PM UTC")

Add your own details to the prompt to remix and make it yours.

Not sure how to describe the sound in your head? Just start typing and dynamic suggestions will suggest descriptive styles, instruments, and moods to help you craft the perfect prompt.

![](https://nitter.net/pic/amplify_video_thumb%2F2024906907425931264%2Fimg%2FUS3qx9sYIz0_BAzG.jpg%3Fname%3Dsmall%26format%3Dwebp)

Enable hls playback

5

9

102

[![](https://nitter.net/pic/profile_images%2F1940093473564073984%2FjiafRcO0_bigger.png)](https://nitter.net/GeminiApp)

[Google Gemini](https://nitter.net/GeminiApp "Google Gemini")

[@GeminiApp](https://nitter.net/GeminiApp "@GeminiApp")

[22h](https://nitter.net/GeminiApp/status/2024906994474446965#m "Feb 20, 2026 Â· 6:00 PM UTC")

Lyria 3 is rolling out in beta on desktop now and to the Gemini mobile app over the next several days for all users globally.

Try it out by selecting "Create Music" in the tools menu or visiting [gemini.google.com/music](http://gemini.google.com/music) and show us what you create in the replies. â¬‡ï¸

2

6

88

Omar Khattab retweeted

[![](https://nitter.net/pic/profile_images%2F1449740720181415942%2Fh4vhGNVs_bigger.jpg)](https://nitter.net/getpy)

[Ankur Gupta](https://nitter.net/getpy "Ankur Gupta") [@getpy](https://nitter.net/getpy "@getpy")

[Feb 20](https://nitter.net/getpy/status/2024865536929308889#m "Feb 20, 2026 Â· 3:15 PM UTC")

DSPy Weekly #23 is out!

\- ðŸ› ï¸ optimize\_anything & gskill (GEPA) released!
\- ðŸ” The rise of Recursive Language Models (RLMs) & new RLM explorers
\- ðŸ¦ Nubank scaling agents to 127M+ users ( with DSPy used in stack )
\- ðŸ§  Generative Ontology & EmbeWebAgent papers
\- ðŸ“ˆ DSPy ecosystem growth & how to contribute!

[#dspy](https://nitter.net/search?f=tweets&q=%23dspy) [#GEPA](https://nitter.net/search?f=tweets&q=%23GEPA) [@DSPyOSS](https://nitter.net/DSPyOSS "DSPy")

![](https://nitter.net/pic/amplify_video_thumb%2F2024865058447310848%2Fimg%2Fh99TZ03IRojId8h2.jpg%3Fname%3Dsmall%26format%3Dwebp)

Enable hls playback

1

8

39

Teortaxesâ–¶ï¸ (DeepSeek æŽ¨ç‰¹ðŸ‹é“ç²‰ 2023 â€“ âˆž) retweeted

[![](https://nitter.net/pic/profile_images%2F1819846106492329984%2FtmQMizKS_bigger.jpg)](https://nitter.net/YouJiacheng)

[You Jiacheng](https://nitter.net/YouJiacheng "You Jiacheng") [@YouJiacheng](https://nitter.net/YouJiacheng "@YouJiacheng")

[Feb 20](https://nitter.net/YouJiacheng/status/2024785289856815162#m "Feb 20, 2026 Â· 9:56 AM UTC")

the original author explicitly said it's AI generated, and add a AIç”Ÿæˆ watermark on the bottom-left corner of the video.
I wonder who overlay a TV news UI on it to make it "realistic" and hide the watermark.

[![](https://nitter.net/pic/media%2FHBl7e8ZboAATHsg.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBl7e8ZboAATHsg.jpg)

![](https://nitter.net/pic/profile_images%2F2001533291527380992%2FT0_Tcexs_mini.jpg)[CIX ðŸ¦¾](https://nitter.net/cixliv "CIX ðŸ¦¾")

[@cixliv](https://nitter.net/cixliv "@cixliv")

[Feb 20](https://nitter.net/cixliv/status/2024745070000558311#m "Feb 20, 2026 Â· 7:16 AM UTC")

Hey everyone this video is fake.

The G1 is 4.5 feet (1.4 meters) tall, 80 pounds. The camera on the robot is a low fidelity realsense camera pointing toward the hands.

It canâ€™t hold a rifle or fire one.

A robot w/ a gun would not use a infantry weapon, it would be custom.

![](https://nitter.net/pic/amplify_video_thumb%2F2024745014883135488%2Fimg%2Fke2KfczpWCQ5dAaS.jpg%3Fname%3Dsmall%26format%3Dwebp)

Enable hls playback

1

1

32

[![](https://nitter.net/pic/profile_images%2F1652169745037242368%2FKRPTShbG_bigger.jpg)](https://nitter.net/teortaxesTex)

[Teortaxesâ–¶ï¸ (DeepSeek æŽ¨ç‰¹ðŸ‹é“ç²‰ 2023 â€“ âˆž)](https://nitter.net/teortaxesTex "Teortaxesâ–¶ï¸ (DeepSeek æŽ¨ç‰¹ðŸ‹é“ç²‰ 2023 â€“ âˆž)")

[@teortaxesTex](https://nitter.net/teortaxesTex "@teortaxesTex")

[22h](https://nitter.net/teortaxesTex/status/2024904289810813414#m "Feb 20, 2026 Â· 5:49 PM UTC")

It's really cool how you can dunk on AI for generating slop, have more AI (likely in the hands of a bored third worlder grooming an account before selling it to a bot farm, like a lamb) enthusiastically agree with you, a third AI will train on itâ€¦ post-scarcity.

[![](https://nitter.net/pic/media%2FHBnnNRbWkAEjPws.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBnnNRbWkAEjPws.jpg)

![](https://nitter.net/pic/profile_images%2F1747812878558826496%2F_thGFENq_mini.png)[Acerola](https://nitter.net/Acerola_t "Acerola") [@Acerola\_t](https://nitter.net/Acerola_t "@Acerola_t")

[Feb 20](https://nitter.net/Acerola_t/status/2024771196492091666#m "Feb 20, 2026 Â· 9:00 AM UTC")

here's an actual real time realistic 3D ocean simulation I wrote a few years ago without AI just by reading some papers. maybe someday Gemini can catch up to 30 year old rendering tech

![](https://nitter.net/pic/amplify_video_thumb%2F2024770409716232192%2Fimg%2FkHGPArobpIKPR533.jpg%3Fname%3Dsmall%26format%3Dwebp)

Enable hls playback

3

19

[![](https://nitter.net/pic/profile_images%2F769304549135880192%2FgUzKgYuk_bigger.jpg)](https://nitter.net/wightmanr)

[Ross Wightman](https://nitter.net/wightmanr "Ross Wightman")

[@wightmanr](https://nitter.net/wightmanr "@wightmanr")

[22h](https://nitter.net/wightmanr/status/2024903715677995266#m "Feb 20, 2026 Â· 5:47 PM UTC")

Sometimes OpenAI & Anthropic's coding models are eerily similar in their oversights and misconceptions. But there are many situations where one has an important insight, sees an issue where the other simply doesn't. Lately, I've been finding it very useful to drive my primary coding with Claude code and then have multi-turn discussion on major decisions, or one shot reviews with Codex via a skill.

![](https://nitter.net/pic/profile_images%2F1824002576%2Fpg-railsconf_mini.jpg)[Paul Graham](https://nitter.net/paulg "Paul Graham")

[@paulg](https://nitter.net/paulg "@paulg")

[Feb 20](https://nitter.net/paulg/status/2024791508679872916#m "Feb 20, 2026 Â· 10:21 AM UTC")

Replying to [@Austen](https://nitter.net/Austen)

Can you trust one to grade another's work?

2

1

9

[![](https://nitter.net/pic/profile_images%2F2021802969738735617%2FubpldNLZ_bigger.jpg)](https://nitter.net/aidan_mclau)

[Aidan McLaughlin](https://nitter.net/aidan_mclau "Aidan McLaughlin")

[@aidan\_mclau](https://nitter.net/aidan_mclau "@aidan_mclau")

[22h](https://nitter.net/aidan_mclau/status/2024903131147247954#m "Feb 20, 2026 Â· 5:45 PM UTC")

please apple make a macbook air with the macbook pro's screen

31

3

246

Leandro von Werra retweeted

[![](https://nitter.net/pic/profile_images%2F1997042844620423168%2FoTEUzUzs_bigger.jpg)](https://nitter.net/QGallouedec)

[Quentin GallouÃ©dec](https://nitter.net/QGallouedec "Quentin GallouÃ©dec") [@QGallouedec](https://nitter.net/QGallouedec "@QGallouedec")

[22h](https://nitter.net/QGallouedec/status/2024900157091786811#m "Feb 20, 2026 Â· 5:33 PM UTC")

this one wonâ€™t go viral. and pls don't tell the "just ship" prophets.

we're doing the unsexy work of open source: api stability, backwards compat, clear public contract...

thatâ€™s how you turn a research prototype into something companies can actually depend on.

[![](https://nitter.net/pic/media%2FHBnj6X4WcAAGZHa.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBnj6X4WcAAGZHa.jpg)

5

4

29

[![](https://nitter.net/pic/profile_images%2F1652169745037242368%2FKRPTShbG_bigger.jpg)](https://nitter.net/teortaxesTex)

[Teortaxesâ–¶ï¸ (DeepSeek æŽ¨ç‰¹ðŸ‹é“ç²‰ 2023 â€“ âˆž)](https://nitter.net/teortaxesTex "Teortaxesâ–¶ï¸ (DeepSeek æŽ¨ç‰¹ðŸ‹é“ç²‰ 2023 â€“ âˆž)")

[@teortaxesTex](https://nitter.net/teortaxesTex "@teortaxesTex")

[22h](https://nitter.net/teortaxesTex/status/2024902144382411220#m "Feb 20, 2026 Â· 5:41 PM UTC")

Galgotias demonstrates why you need chutzpah for true breakthroughs.

[![](https://nitter.net/pic/media%2FHBnlh8IWkAAxCoZ.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBnlh8IWkAAxCoZ.jpg)

![](https://nitter.net/pic/profile_images%2F2014123605224042496%2F2vXwIPQh_mini.jpg)[Priyanshu Ratnakar](https://nitter.net/0xratnakar "Priyanshu Ratnakar")

[@0xratnakar](https://nitter.net/0xratnakar "@0xratnakar")

[Feb 20](https://nitter.net/0xratnakar/status/2024774476202979385#m "Feb 20, 2026 Â· 9:13 AM UTC")

TIL galgotias university files more patents than all IITs combined.

not because theyâ€™re innovating. bcz they figured out the cheat code.

filing a patent in india costs â‚¹1,600.

govt reimburses up to â‚¹2 lakh per filing.

thatâ€™s a 125x return. before the patent does anything.

so universities found the playbook:

file 1000 patents â†’ collect â‚¹20cr â†’ boost NIRF rank â†’ attract more students â†’ collect fees â†’ repeat

the patents? take a guess ðŸ¤¡

india ranks 5th globally in patent applications.

last among the top 6 in grant rate.
japan converts 70% of filings into grants.

we convert 40%.

we ainâ€™t building but chasing wrong metrics.

and the worst part? the system rewards it.

NIRF counts raw filings, not grants. so the incentive is to file garbage at scale, not build real IP.

this is what happens when you optimize for the scoreboard instead of the game.

weâ€™re really good at looking innovative.
not as good at being it.

fix is simple btw:
reimburse at grant stage, not filing stage. tie incentives to commercialization. weight NIRF on grants, not applications.

but simple fixes donâ€™t happen when the people gaming the system are also the ones writing the policy. need young + smart policy makers

innovation isnâ€™t a form you fill. itâ€™s a product you build. ðŸ«¡

[![](https://nitter.net/pic/media%2FHBlxpn1bIAAJDdN.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBlxpn1bIAAJDdN.jpg)

4

89

[![](https://nitter.net/pic/profile_images%2F1882196987115905024%2FIGWtKBkj_bigger.jpg)](https://nitter.net/wandb)

[Weights & Biases](https://nitter.net/wandb "Weights & Biases")

[@wandb](https://nitter.net/wandb "@wandb")

[22h](https://nitter.net/wandb/status/2024902055278903786#m "Feb 20, 2026 Â· 5:40 PM UTC")

Physical AI is where it gets real.

Weâ€™re hosting a webinar with [@CoreWeave](https://nitter.net/CoreWeave "CoreWeave"), [@ADI\_News](https://nitter.net/ADI_News "Analog Devices, Inc."), [@Monolith\_AI](https://nitter.net/Monolith_AI "Monolith"), and [@wandb](https://nitter.net/wandb "Weights & Biases") on how simulation + AI teams ship faster and with more confidence.

[![](https://nitter.net/pic/media%2FHBnlr9QbgAIOrMK.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBnlr9QbgAIOrMK.jpg)

1

2

8

[![](https://nitter.net/pic/profile_images%2F1882196987115905024%2FIGWtKBkj_bigger.jpg)](https://nitter.net/wandb)

[Weights & Biases](https://nitter.net/wandb "Weights & Biases")

[@wandb](https://nitter.net/wandb "@wandb")

[22h](https://nitter.net/wandb/status/2024902060286902403#m "Feb 20, 2026 Â· 5:40 PM UTC")

[wandb.ai/site/resources/evenâ€¦](https://wandb.ai/site/resources/events/from-physics-to-intelligence-how-adi-coreweave-monolith-and-weights-biases-accelerate-the-design-of-next-generation-products/?utm_source=twitter&utm_medium=social&utm_campaign=industry-campaign)

[![](https://nitter.net/pic/card_img%2F2024901485365264384%2F-mOIeT1o%3Fformat%3Djpg%26name%3D800x419)\\
\\
**From physics to intelligence: Accelerating the design of nextâ€‘generation products** \\
\\
Building reliable physical systems is too slow, too expensive, and too uncertain. Mainstream AI canâ€™t solve this challenge alone because it is fundamentally ungrounded in physics. Meanwhile, tradit...\\
\\
wandb.ai](https://wandb.ai/site/resources/events/from-physics-to-intelligence-how-adi-coreweave-monolith-and-weights-biases-accelerate-the-design-of-next-generation-products/?utm_source=twitter&utm_medium=social&utm_campaign=industry-campaign)

3

[![](https://nitter.net/pic/profile_images%2F1606206113245904897%2FN6RH65PF_bigger.jpg)](https://nitter.net/LearnOpenCV)

[Satya Mallick](https://nitter.net/LearnOpenCV "Satya Mallick")

[@LearnOpenCV](https://nitter.net/LearnOpenCV "@LearnOpenCV")

[22h](https://nitter.net/LearnOpenCV/status/2024901967093580000#m "Feb 20, 2026 Â· 5:40 PM UTC")

Early 2000s called today as I joined a meeting using Webex.

[![](https://nitter.net/pic/profile_images%2F1994231484752736256%2FU0xICyKq_bigger.jpg)](https://nitter.net/c_valenzuelab)

[CristÃ³bal Valenzuela](https://nitter.net/c_valenzuelab "CristÃ³bal Valenzuela")

[@c\_valenzuelab](https://nitter.net/c_valenzuelab "@c_valenzuelab")

[22h](https://nitter.net/c_valenzuelab/status/2024901728273912263#m "Feb 20, 2026 Â· 5:39 PM UTC")

You can just imagine things, and then you can just make them.

![](https://nitter.net/pic/profile_images%2F1831833504960729088%2FT6Dw8b_U_mini.jpg)[Nicolas Neubert](https://nitter.net/iamneubert "Nicolas Neubert")

[@iamneubert](https://nitter.net/iamneubert "@iamneubert")

[Feb 20](https://nitter.net/iamneubert/status/2024681698097820065#m "Feb 20, 2026 Â· 3:05 AM UTC")

This is what pre-production in the age of AI looks like.
Visualize ideas and make them happen.

[![](https://nitter.net/pic/media%2FHBkc7xibUAADdav.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBkc7xibUAADdav.jpg)

[![](https://nitter.net/pic/media%2FHBkc_gtakAA7tQL.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBkc_gtakAA7tQL.jpg)

[![](https://nitter.net/pic/media%2FHBkdAMnbUAAx4-V.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBkdAMnbUAAx4-V.jpg)

[![](https://nitter.net/pic/media%2FHBkdA3TbUAApCbR.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBkdA3TbUAApCbR.jpg)

6

3

45

[![](https://nitter.net/pic/profile_images%2F1882196987115905024%2FIGWtKBkj_bigger.jpg)](https://nitter.net/wandb)

[Weights & Biases](https://nitter.net/wandb "Weights & Biases")

[@wandb](https://nitter.net/wandb "@wandb")

[22h](https://nitter.net/wandb/status/2024901313306534024#m "Feb 20, 2026 Â· 5:37 PM UTC")

There are two fundamental approaches to ML in drug discovery: local models and global models.

Which should you use? [@IsomorphicLabs](https://nitter.net/IsomorphicLabs "Isomorphic Labs")' [@maxjaderberg](https://nitter.net/maxjaderberg "Max Jaderberg") breaks down the trade-off between laser-focused local data and generalizable global models.

Link in comments.

![](https://nitter.net/pic/amplify_video_thumb%2F2024898789707055106%2Fimg%2FEP1Ikb8L9Ho9X8cg.jpg%3Fname%3Dsmall%26format%3Dwebp)

Enable hls playback

1

[![](https://nitter.net/pic/profile_images%2F1882196987115905024%2FIGWtKBkj_bigger.jpg)](https://nitter.net/wandb)

[Weights & Biases](https://nitter.net/wandb "Weights & Biases")

[@wandb](https://nitter.net/wandb "@wandb")

[22h](https://nitter.net/wandb/status/2024901388531314791#m "Feb 20, 2026 Â· 5:38 PM UTC")

Watch the full episode: [piped.video/-hl0jpwWbV4?si=nAbKâ€¦](https://piped.video/-hl0jpwWbV4?si=nAbKCkTWrD1L6Kbl)

[![](https://nitter.net/pic/card_img%2F2024179753222361091%2FHnsKiT1B%3Fformat%3Djpg%26name%3D800x320_1)\\
\\
**Accelerating drug discovery with AI: Insights from Isomorphic Labs** \\
\\
In this episode of Gradient Dissent, Isomorphic Labs Chief AI Officer Max Jaderberg, and Chief Technology Officer Sergei Yakneen join our host Lukas Biewald ...\\
\\
youtube.com](https://piped.video/watch?v=-hl0jpwWbV4)

Jerry Liu retweeted

[![](https://nitter.net/pic/profile_images%2F1967920417760251904%2F0ytfduMQ_bigger.png)](https://nitter.net/llama_index)

[LlamaIndex ðŸ¦™](https://nitter.net/llama_index "LlamaIndex ðŸ¦™")

[@llama\_index](https://nitter.net/llama_index "@llama_index")

[22h](https://nitter.net/llama_index/status/2024892621911679102#m "Feb 20, 2026 Â· 5:03 PM UTC")

ðŸš€ Big drop from [@GoogleDeepMind](https://nitter.net/GoogleDeepMind "Google DeepMind"): Gemini 3.1 Pro is here, and we built a hands-on demo powered by LlamaCloud to put it to work and turn your receipt photos into real financial insights!

Using our Agent Workflows, the app:
ðŸ“¸ Parses receipt images with LlamaParse (Agentic tier)
ðŸ—‚ Stores everything locally in an SQLite database
ðŸ“Š Aggregates your spending monthly
ðŸ§  Uses Gemini 3.1 Pro to analyze trends and generate actionable tips to improve your finances

Check out the demo below!ðŸ‘‡
ðŸ‘©â€ðŸ’» GitHub repo: [github.com/run-llama/receiptâ€¦](http://github.com/run-llama/receipts-analyzer)
ðŸ¦™ Get started with LlamaCloud: [cloud.llamaindex.ai/signup](http://cloud.llamaindex.ai/signup)

![](https://nitter.net/pic/amplify_video_thumb%2F2024892570292391937%2Fimg%2F8SKsc_1N_Da8zZN3.jpg%3Fname%3Dsmall%26format%3Dwebp)

Enable hls playback

3

5

19

Weights & Biases retweeted

[![](https://nitter.net/pic/profile_images%2F1016982898556141569%2FR09dBwgv_bigger.jpg)](https://nitter.net/_ScottCondron)

[Scott Condron](https://nitter.net/_ScottCondron "Scott Condron")

[@\_ScottCondron](https://nitter.net/_ScottCondron "@_ScottCondron")

[Feb 20](https://nitter.net/_ScottCondron/status/2024854561987444743#m "Feb 20, 2026 Â· 2:32 PM UTC")

Code is starting to look like trained model artifacts.
The most advanced teams are tracing and evaluating agents, then running optimization loops where the agent improves itself with code artifacts versioned and promoted like models using [@wandb](https://nitter.net/wandb "Weights & Biases")

[![](https://nitter.net/pic/media%2FHBm4oEmXoAAOuEW.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBm4oEmXoAAOuEW.jpg)

![](https://nitter.net/pic/profile_images%2F2006806326140350470%2FKd5oZv-f_mini.jpg)[FranÃ§ois Chollet](https://nitter.net/fchollet "FranÃ§ois Chollet")

[@fchollet](https://nitter.net/fchollet "@fchollet")

[Feb 19](https://nitter.net/fchollet/status/2024519439140737442#m "Feb 19, 2026 Â· 4:20 PM UTC")

Sufficiently advanced agentic coding is essentially machine learning: the engineer sets up the optimization goal as well as some constraints on the search space (the spec and its tests), then an optimization process (coding agents) iterates until the goal is reached.

The result is a blackbox model (the generated codebase): an artifact that performs the task, that you deploy without ever inspecting its internal logic, just as we ignore individual weights in a neural network.

This implies that all classic issues encountered in ML will soon become problems for agentic coding: overfitting to the spec, Clever Hans shortcuts that don't generalize outside the tests, data leakage, concept drift, etc.

I would also ask: what will be the Keras of agentic coding? What will be the optimal set of high-level abstractions that allow humans to steer codebase 'training' with minimal cognitive overhead?

1

10

Eric Hartford retweeted

[![](https://nitter.net/pic/profile_images%2F1967672234056523776%2FFoFd2843_bigger.jpg)](https://nitter.net/DataChaz)

[Charly Wargnier](https://nitter.net/DataChaz "Charly Wargnier")

[@DataChaz](https://nitter.net/DataChaz "@DataChaz")

[Feb 19](https://nitter.net/DataChaz/status/2024391388637573387#m "Feb 19, 2026 Â· 7:51 AM UTC")

YES!

This paper basically confirms what many of us already suspected:

If you want better LLM results without paying for longer outputs or fine-tuning, thereâ€™s a concrete, low-effort tip:

Duplicate your prompt!

Researchers found that repeating the exact same input can dramatically improve performance (up to a 76% gain on specific tasks).

LLMs process text left to right, each token can only look at the previous context, never ahead.

So when you write a long prompt with context first and the question at the end, the model can rely on that context to answer, but the context was processed before the model even knew the question.

This asymmetry is a basic structural property of how LLMs work.

Repeating the prompt helps counter this limitation by giving the model a second pass over the full context.

There are no new losses to compute and no fancy prompt engineering involved.

Itâ€™s just a simple structural hack that works across almost every major model they tested.

Paper in ðŸ§µâ†“

[![](https://nitter.net/pic/media%2FHBgVPUeagAE5-tP.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBgVPUeagAE5-tP.jpg)

41

68

408

[![](https://nitter.net/pic/profile_images%2F1816551258905620480%2FkGMg3Z6W_bigger.jpg)](https://nitter.net/dzhng)

[David](https://nitter.net/dzhng "David")

[@dzhng](https://nitter.net/dzhng "@dzhng")

[22h](https://nitter.net/dzhng/status/2024899724231557568#m "Feb 20, 2026 Â· 5:31 PM UTC")

By popular request, we added a token leaderboard right within [@duetchat](https://nitter.net/duetchat "duet") so teams can see each member's token usage

[![](https://nitter.net/pic/media%2FHBnihHhacAA7Hzz.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBnihHhacAA7Hzz.jpg)

1

6

[![](https://nitter.net/pic/profile_images%2F1554922493101559808%2FSYSZhbcd_bigger.jpg)](https://nitter.net/DrJimFan)

[Jim Fan](https://nitter.net/DrJimFan "Jim Fan")

[@DrJimFan](https://nitter.net/DrJimFan "@DrJimFan")

[22h](https://nitter.net/DrJimFan/status/2024895359236051274#m "Feb 20, 2026 Â· 5:14 PM UTC")

Announcing DreamDojo: our open-source, interactive world model that takes robot motor controls and generates the future in pixels. No engine, no meshes, no hand-authored dynamics. It's Simulation 2.0. Time for robotics to take the bitter lesson pill.

Real-world robot learning is bottlenecked by time, wear, safety, and resets. If we want Physical AI to move at pretraining speed, we need a simulator that adapts to pretraining scale with as little human engineering as possible.

Our key insights: (1) human egocentric videos are a scalable source of first-person physics; (2) latent actions make them "robot-readable" across different hardware; (3) real-time inference unlocks live teleop, policy eval, and test-time planning \*inside\* a dream.

We pre-train on 44K hours of human videos: cheap, abundant, and collected with zero robot-in-the-loop. Humans have already explored the combinatorics: we grasp, pour, fold, assemble, fail, retryâ€”across cluttered scenes, shifting viewpoints, changing light, and hour-long task chainsâ€”at a scale no robot fleet could match. The missing piece: these videos have no action labels. So we introduce latent actions: a unified representation inferred directly from videos that captures "what changed between world states" without knowing the underlying hardware. This lets us train on any first-person video as if it came with motor commands attached.

As a result, DreamDojo generalizes zero-shot to objects and environments never seen in any robot training set, because humans saw them first.

Next, we post-train onto each robot to fit its specific hardware. Think of it as separating "how the world looks and behaves" from "how this particular robot actuates." The base model follows the general physical rules, then "snaps onto" the robot's unique mechanics. It's kind of like loading a new character and scene assets into Unreal Engine, but done through gradient descent and generalizes far beyond the post-training dataset.

A world simulator is only useful if it runs fast enough to close the loop. We train a real-time version of DreamDojo that runs at 10 FPS, stable for over a minute of continuous rollout. This unlocks exciting possibilities:

\- Live teleoperation \*inside\* a dream. Connect a VR controller, stream actions into DreamDojo, and teleop a virtual robot in real time. We demo this on Unitree G1 with a PICO headset and one RTX 5090.
\- Policy evaluation. You can benchmark a policy checkpoint in DreamDojo instead of the real world. The simulated success rates strongly correlate with real-world results - accurate enough to rank checkpoints without burning a single motor.
\- Model-based planning. Sample multiple action proposals â†’ simulate them all in parallel â†’ pick the best future. Gains +17% real-world success out of the box on a fruit packing task.

We open-source everything!! Weights, code, post-training dataset, eval set, and whitepaper with tons of details to reproduce. DreamDojo is based on NVIDIA Cosmos, which is open-weight too.

2026 is the year of World Models for physical AI. We want you to build with us. Happy scaling!

Links in thread:

![](https://nitter.net/pic/amplify_video_thumb%2F2024870774126034944%2Fimg%2FamZpCnQ3_ZVF4D3d.jpg%3Fname%3Dsmall%26format%3Dwebp)

Enable hls playback

59

134

889

[![](https://nitter.net/pic/profile_images%2F1554922493101559808%2FSYSZhbcd_bigger.jpg)](https://nitter.net/DrJimFan)

[Jim Fan](https://nitter.net/DrJimFan "Jim Fan")

[@DrJimFan](https://nitter.net/DrJimFan "@DrJimFan")

[22h](https://nitter.net/DrJimFan/status/2024895360922255776#m "Feb 20, 2026 Â· 5:14 PM UTC")

\- Project website: [dreamdojo-world.github.io/](https://dreamdojo-world.github.io/)
\- Paper: [arxiv.org/abs/2602.06949](https://arxiv.org/abs/2602.06949)
\- Code repo and model ckpts: [github.com/NVIDIA/DreamDojo](https://github.com/NVIDIA/DreamDojo)

This is a huge team work at NVIDIA. All credits go to the wonderful teams who poured their hearts into it!

[![](https://nitter.net/pic/media%2FHBnfLMmbUAEwaXP.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBnfLMmbUAEwaXP.jpg)

4

4

75

[![](https://nitter.net/pic/profile_images%2F1554922493101559808%2FSYSZhbcd_bigger.jpg)](https://nitter.net/DrJimFan)

[Jim Fan](https://nitter.net/DrJimFan "Jim Fan")

[@DrJimFan](https://nitter.net/DrJimFan "@DrJimFan")

[22h](https://nitter.net/DrJimFan/status/2024899289080910046#m "Feb 20, 2026 Â· 5:29 PM UTC")

Check out [@ShenyuanGao](https://nitter.net/ShenyuanGao "Shenyuan Gao")'s technical deep dive:

![](https://nitter.net/pic/profile_images%2F2023217771463815168%2FJxKAWYvk_mini.jpg)[Shenyuan Gao](https://nitter.net/ShenyuanGao "Shenyuan Gao")

[@ShenyuanGao](https://nitter.net/ShenyuanGao "@ShenyuanGao")

[22h](https://nitter.net/ShenyuanGao/status/2024898256334114876#m "Feb 20, 2026 Â· 5:25 PM UTC")

ðŸ¤– How can we enable zero-shot generalization to unseen scenarios for robot world models?

Thrilled to share DreamDojo ðŸŒŽ â€” an interactive robot world model pretrained on 44K hours of human egocentric videos, the largest and most diverse dataset to date for robot world model learning. Our model not only excels in generalization, but also supports real-time interaction at 10 FPS after distillation. It enables several important applications, including live teleoperation, policy evaluation, and model-based planning at test time.
ðŸ”— Project: [dreamdojo-world.github.io/](https://dreamdojo-world.github.io/)
ðŸ“° Paper: [arxiv.org/abs/2602.06949](https://arxiv.org/abs/2602.06949)
ðŸ¤— Code & models & datasets: [github.com/NVIDIA/DreamDojo](https://github.com/NVIDIA/DreamDojo) [#WorldModels](https://nitter.net/search?f=tweets&q=%23WorldModels) [#Robotics](https://nitter.net/search?f=tweets&q=%23Robotics) [#EmbodiedAI](https://nitter.net/search?f=tweets&q=%23EmbodiedAI) [#RL](https://nitter.net/search?f=tweets&q=%23RL) [#AI](https://nitter.net/search?f=tweets&q=%23AI) [#NVIDIA](https://nitter.net/search?f=tweets&q=%23NVIDIA)

Sharing more details in the thread ðŸ§µ

![](https://nitter.net/pic/amplify_video_thumb%2F2024897337404129280%2Fimg%2FSA7h3riCVJSp8dhV.jpg%3Fname%3Dsmall%26format%3Dwebp)

Enable hls playback

1

1

35

[![](https://nitter.net/pic/profile_images%2F1728327996375719936%2FRW7VBJfD_bigger.jpg)](https://nitter.net/kimmonismus)

[Chubbyâ™¨ï¸](https://nitter.net/kimmonismus "Chubbyâ™¨ï¸")

[@kimmonismus](https://nitter.net/kimmonismus "@kimmonismus")

[22h](https://nitter.net/kimmonismus/status/2024898716365455459#m "Feb 20, 2026 Â· 5:27 PM UTC")

Holy moly, what is happening inside those frontier labs?!

\- AGI very close - Superintelligence also not far off
\- watching "how fast the models accelerate internally" ASI is very close
\- a \*even faster\* take-off not very fast off

![](https://nitter.net/pic/amplify_video_thumb%2F2024898601454010368%2Fimg%2FZXK5PHOkahp0Dmpm.jpg%3Fname%3Dsmall%26format%3Dwebp)

Enable hls playback

98

107

1,334

[![](https://nitter.net/pic/profile_images%2F1728327996375719936%2FRW7VBJfD_bigger.jpg)](https://nitter.net/kimmonismus)

[Chubbyâ™¨ï¸](https://nitter.net/kimmonismus "Chubbyâ™¨ï¸")

[@kimmonismus](https://nitter.net/kimmonismus "@kimmonismus")

[22h](https://nitter.net/kimmonismus/status/2024898728407282102#m "Feb 20, 2026 Â· 5:27 PM UTC")

[piped.video/watch?v=qH7thwrCâ€¦](https://piped.video/watch?v=qH7thwrCluM)

[![](https://nitter.net/pic/card_img%2F2025074185152643073%2FwCk-IRN_%3Fformat%3Djpg%26name%3D800x320_1)\\
\\
**Sam Altman Unfiltered: ChatGPT, AI Risks & Whatâ€™s Coming Next, 40...** \\
\\
Sam Altman Exclusive: Is AI Getting Dangerous? ChatGPT, AI Safety, Risks & the Future of AI : Sam Altman Exclusive: In this exclusive 60-minute interview, S...\\
\\
youtube.com](https://piped.video/watch?v=qH7thwrCluM)

1

3

26

[![](https://nitter.net/pic/profile_images%2F1867875781676007424%2FRIF4Kt7U_bigger.jpg)](https://nitter.net/swyx)

[swyx](https://nitter.net/swyx "swyx")

[@swyx](https://nitter.net/swyx "@swyx")

[Feb 19](https://nitter.net/swyx/status/2024616612599587282#m "Feb 19, 2026 Â· 10:46 PM UTC")

[x.com/i/article/202460118068â€¦](http://x.com/i/article/2024601180689903616)

28

33

276

[![](https://nitter.net/pic/profile_images%2F1867875781676007424%2FRIF4Kt7U_bigger.jpg)](https://nitter.net/swyx)

[swyx](https://nitter.net/swyx "swyx")

[@swyx](https://nitter.net/swyx "@swyx")

[Feb 20](https://nitter.net/swyx/status/2024780514511794669#m "Feb 20, 2026 Â· 9:37 AM UTC")

oh my god the utter disrespect to [@MistralAI](https://nitter.net/MistralAI "Mistral AI") ceo who has 100x better models and achievements than whatever sarvam put out

![](https://nitter.net/pic/amplify_video_thumb%2F2024435328745164801%2Fimg%2FQocJiW4NF-LuusgZ.jpg%3Fname%3Dsmall%26format%3Dwebp)

Enable hls playback

14

1

130

[![](https://nitter.net/pic/profile_images%2F1867875781676007424%2FRIF4Kt7U_bigger.jpg)](https://nitter.net/swyx)

[swyx](https://nitter.net/swyx "swyx")

[@swyx](https://nitter.net/swyx "@swyx")

[22h](https://nitter.net/swyx/status/2024898670781759563#m "Feb 20, 2026 Â· 5:27 PM UTC")

ok day 2 for [@sama](https://nitter.net/sama "Sam Altman") is looking much better better. glad he stayed behind a bit to talk to the little folk

[piped.video/embed/qH7thwrCluâ€¦](https://piped.video/embed/qH7thwrCluM)

3

5

[![](https://nitter.net/pic/profile_images%2F1831493788679761920%2F-q9w6dzd_bigger.jpg)](https://nitter.net/scaling01)

[Lisan al Gaib](https://nitter.net/scaling01 "Lisan al Gaib")

[@scaling01](https://nitter.net/scaling01 "@scaling01")

[22h](https://nitter.net/scaling01/status/2024898141883871709#m "Feb 20, 2026 Â· 5:25 PM UTC")

As promised, I uploaded the code to a fork of the ARC-AGI-3-benchmarking repo:
\- [github.com/voice-from-the-ouâ€¦](https://github.com/voice-from-the-outer-world/arc-agi-3-benchmarking)

What I added:
\- my \`state-memory\` agent
\- Local live results viewer with playback and per-step details (action, reasoning, memory, full model input/output)
\- a silly download GIF button on the dashboard in case someone wants to share results of other models
\- a bunch of models incl. Gemini 3.1 Pro and Opus 4.6 via OpenRouter

Everything on how to use it is in the README.

Please don't ask me about any naming like why "state-memory" or why the new agent is in the adcr-agent's directory. It was all designed by the GPT-5.3-Codex gods. I don't dare to question their choices. Just want you to be able to try it out yourself.

This is expensive to run (at least for me). If you run all 3 games with 50 actions Gemini 3.1 Pro will set you back about $15-20. Opus-4.6-Thinking will set you back $35-45.

Smaller models like GLM-5, Kimi-K2.5 Thinking or Gemini-3 Flash are kinda pointless to run, but they will be $5-10 for the 50 steps for each of the 3 games.

I would love to see Opus 4.6 Thinking, GPT-5.2-xhigh and Gemini 3.1 Pro just run all the games until they get stuck or lose.

[![](https://nitter.net/pic/card_img%2F2024898144434003968%2FRAoYLneL%3Fformat%3Djpg%26name%3D800x419)\\
\\
**GitHub - voice-from-the-outer-world/arc-agi-3-benchmarking** \\
\\
Contribute to voice-from-the-outer-world/arc-agi-3-benchmarking development by creating an account on GitHub.\\
\\
github.com](https://github.com/voice-from-the-outer-world/arc-agi-3-benchmarking)

![](https://nitter.net/pic/profile_images%2F1831493788679761920%2F-q9w6dzd_mini.jpg)[Lisan al Gaib](https://nitter.net/scaling01 "Lisan al Gaib")

[@scaling01](https://nitter.net/scaling01 "@scaling01")

[Feb 20](https://nitter.net/scaling01/status/2024640940657246235#m "Feb 20, 2026 Â· 12:23 AM UTC")

[x.com/i/article/202462313394â€¦](http://x.com/i/article/2024623133945106432)

2

2

29

[![](https://nitter.net/pic/profile_images%2F1831493788679761920%2F-q9w6dzd_bigger.jpg)](https://nitter.net/scaling01)

[Lisan al Gaib](https://nitter.net/scaling01 "Lisan al Gaib")

[@scaling01](https://nitter.net/scaling01 "@scaling01")

[22h](https://nitter.net/scaling01/status/2024898634483990925#m "Feb 20, 2026 Â· 5:27 PM UTC")

these are the start commands I used for the Gemini 3.1 Pro and Opus 4.6 results in the article:

uv run python cli/run\_all.py --agent state-memory --game\_list\_file games.txt --model\_configs claude-opus-4-6-openrouter --num\_plays 1 --max\_actions 50

uv run python cli/run\_all.py --agent state-memory --game\_list\_file games.txt --model\_configs gemini-3-1-pro-openrouter --num\_plays 1 --max\_actions 50

4

[![](https://nitter.net/pic/profile_images%2F1803953120923254784%2F_l4nw1xZ_bigger.jpg)](https://nitter.net/jparkerholder)

[Jack Parker-Holder](https://nitter.net/jparkerholder "Jack Parker-Holder")

[@jparkerholder](https://nitter.net/jparkerholder "@jparkerholder")

[22h](https://nitter.net/jparkerholder/status/2024896194380529892#m "Feb 20, 2026 Â· 5:17 PM UTC")

Looks like a cool project, congrats [@DrJimFan](https://nitter.net/DrJimFan "Jim Fan") and team

![](https://nitter.net/pic/profile_images%2F1554922493101559808%2FSYSZhbcd_mini.jpg)[Jim Fan](https://nitter.net/DrJimFan "Jim Fan")

[@DrJimFan](https://nitter.net/DrJimFan "@DrJimFan")

[22h](https://nitter.net/DrJimFan/status/2024895359236051274#m "Feb 20, 2026 Â· 5:14 PM UTC")

Announcing DreamDojo: our open-source, interactive world model that takes robot motor controls and generates the future in pixels. No engine, no meshes, no hand-authored dynamics. It's Simulation 2.0. Time for robotics to take the bitter lesson pill.

Real-world robot learning is bottlenecked by time, wear, safety, and resets. If we want Physical AI to move at pretraining speed, we need a simulator that adapts to pretraining scale with as little human engineering as possible.

Our key insights: (1) human egocentric videos are a scalable source of first-person physics; (2) latent actions make them "robot-readable" across different hardware; (3) real-time inference unlocks live teleop, policy eval, and test-time planning \*inside\* a dream.

We pre-train on 44K hours of human videos: cheap, abundant, and collected with zero robot-in-the-loop. Humans have already explored the combinatorics: we grasp, pour, fold, assemble, fail, retryâ€”across cluttered scenes, shifting viewpoints, changing light, and hour-long task chainsâ€”at a scale no robot fleet could match. The missing piece: these videos have no action labels. So we introduce latent actions: a unified representation inferred directly from videos that captures "what changed between world states" without knowing the underlying hardware. This lets us train on any first-person video as if it came with motor commands attached.

As a result, DreamDojo generalizes zero-shot to objects and environments never seen in any robot training set, because humans saw them first.

Next, we post-train onto each robot to fit its specific hardware. Think of it as separating "how the world looks and behaves" from "how this particular robot actuates." The base model follows the general physical rules, then "snaps onto" the robot's unique mechanics. It's kind of like loading a new character and scene assets into Unreal Engine, but done through gradient descent and generalizes far beyond the post-training dataset.

A world simulator is only useful if it runs fast enough to close the loop. We train a real-time version of DreamDojo that runs at 10 FPS, stable for over a minute of continuous rollout. This unlocks exciting possibilities:

\- Live teleoperation \*inside\* a dream. Connect a VR controller, stream actions into DreamDojo, and teleop a virtual robot in real time. We demo this on Unitree G1 with a PICO headset and one RTX 5090.
\- Policy evaluation. You can benchmark a policy checkpoint in DreamDojo instead of the real world. The simulated success rates strongly correlate with real-world results - accurate enough to rank checkpoints without burning a single motor.
\- Model-based planning. Sample multiple action proposals â†’ simulate them all in parallel â†’ pick the best future. Gains +17% real-world success out of the box on a fruit packing task.

We open-source everything!! Weights, code, post-training dataset, eval set, and whitepaper with tons of details to reproduce. DreamDojo is based on NVIDIA Cosmos, which is open-weight too.

2026 is the year of World Models for physical AI. We want you to build with us. Happy scaling!

Links in thread:

![](https://nitter.net/pic/amplify_video_thumb%2F2024870774126034944%2Fimg%2FamZpCnQ3_ZVF4D3d.jpg%3Fname%3Dsmall%26format%3Dwebp)

Enable hls playback

1

1

28

[![](https://nitter.net/pic/profile_images%2F1554922493101559808%2FSYSZhbcd_bigger.jpg)](https://nitter.net/DrJimFan)

[Jim Fan](https://nitter.net/DrJimFan "Jim Fan")

[@DrJimFan](https://nitter.net/DrJimFan "@DrJimFan")

[22h](https://nitter.net/DrJimFan/status/2024896347195973765#m "Feb 20, 2026 Â· 5:18 PM UTC")

Thanks Jack!! Our robotics version of GENIE-3! Your work has been an inspiration.

4

Stanford NLP Group retweeted

[![](https://nitter.net/pic/profile_images%2F1125242928639533057%2FSHyC9CpI_bigger.png)](https://nitter.net/SciFi)

[AI Papers](https://nitter.net/SciFi "AI Papers") [@SciFi](https://nitter.net/SciFi "@SciFi")

[Feb 20](https://nitter.net/SciFi/status/2024789206053032427#m "Feb 20, 2026 Â· 10:12 AM UTC")

ODESteer: A Unified ODE-Based Steering Framework for LLM Alignment

Hongjue Zhao, Haosen Sun, Jiangtao Kong, Xiaochang Li, Qineng Wang, Liwei Jiang, Qi Zhu, Tarek Abdelzaher, Yejin Choi, Manling Li, Huajie Shao
[arxiv.org/abs/2602.17560](https://arxiv.org/abs/2602.17560) \[ðšŒðšœ.ð™°ð™¸\]

[![](https://nitter.net/pic/media%2FHBl_DadWAAEuIab.png%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBl_DadWAAEuIab.png)

2

6

Stanford NLP Group retweeted

[![](https://nitter.net/pic/profile_images%2F1988495095738626049%2FtAJnOA2q_bigger.jpg)](https://nitter.net/lcfreisi)

[Leonie Freisinger](https://nitter.net/lcfreisi "Leonie Freisinger")

[@lcfreisi](https://nitter.net/lcfreisi "@lcfreisi")

[Feb 20](https://nitter.net/lcfreisi/status/2024678366834807093#m "Feb 20, 2026 Â· 2:51 AM UTC")

gave a lecture at Stanford today on building (almost) production-ready agents with pydantic-ai --> donâ€™t over engineer your agents.

i demoed a toy SQL agent, some key ideas:
\- validate outputs + donâ€™t complicate dependencies
\- use self-documenting tools & models
\- include a self-correcting mechanism (ModelRetry)
\- use Langfuse for tracing ( [@marcklingen](https://nitter.net/marcklingen "Marc Klingen"))

shout out to [@joewhaley](https://nitter.net/joewhaley "John Whaley") for the invite! love the project-based format of CS 244G (Building & Scaling LLM Applications)

[![](https://nitter.net/pic/media%2FHBkZ9aba4AApCfA.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBkZ9aba4AApCfA.jpg)

13

16

224

CuddlySalmon retweeted

[![](https://nitter.net/pic/profile_images%2F1898919836308148224%2FHE5tIgc7_bigger.jpg)](https://nitter.net/TheCartelDel)

[Del](https://nitter.net/TheCartelDel "Del")

[@TheCartelDel](https://nitter.net/TheCartelDel "@TheCartelDel")

[Feb 20](https://nitter.net/TheCartelDel/status/2024700648353398833#m "Feb 20, 2026 Â· 4:20 AM UTC")

"Roblox had 150 million daily users in Q3 2025. Its quarterly engagement is now equal to Steam, PlayStation, and Fortnite combined."

![](https://nitter.net/pic/profile_images%2F1434863337473458182%2FJckcZMpU_mini.jpg)[Matthew Ball](https://nitter.net/ballmatthew "Matthew Ball")

[@ballmatthew](https://nitter.net/ballmatthew "@ballmatthew")

[Feb 17](https://nitter.net/ballmatthew/status/2023559741373341763#m "Feb 17, 2026 Â· 12:46 AM UTC")

My State of Video Games in 2026 is now out (Early Access)

1âƒ£ Why revenue growth is more elusive than headlines suggest
2âƒ£Why video gaming has been losing the attention war for a half decade (and to what)
3âƒ£ Where there's indisputable growth

\+ Lots more

[matthewball.co/all/presentatâ€¦](https://www.matthewball.co/all/presentation-the-state-of-video-gaming-in-2026)

68

403

9,653

Stanford NLP Group retweeted

[![](https://nitter.net/pic/profile_images%2F1868845402835017728%2FEw50qGxC_bigger.jpg)](https://nitter.net/edzitron)

[Ed Zitron](https://nitter.net/edzitron "Ed Zitron")

[@edzitron](https://nitter.net/edzitron "@edzitron")

[Feb 20](https://nitter.net/edzitron/status/2024725617221259767#m "Feb 20, 2026 Â· 5:59 AM UTC")

On two separate occasions Amazonâ€™s Kiro AI assistant caused an AWS outage, one that was 13 hours long. Amazon blames this on â€œuser error not AI error,â€ which is one of the most embarrassing things you could ever say as a human being

[![](https://nitter.net/pic/media%2FHBlFN9XbUAMB286.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBlFN9XbUAMB286.jpg)

[![](https://nitter.net/pic/media%2FHBlFN9XbUAIaID8.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBlFN9XbUAIaID8.jpg)

[![](https://nitter.net/pic/media%2FHBlFN9VaIAAuBSQ.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBlFN9VaIAAuBSQ.jpg)

![](https://nitter.net/pic/profile_images%2F1191943129823399936%2FZvfTRAlg_mini.jpg)[Techmeme](https://nitter.net/Techmeme "Techmeme")

[@Techmeme](https://nitter.net/Techmeme "@Techmeme")

[Feb 20](https://nitter.net/Techmeme/status/2024722364861468850#m "Feb 20, 2026 Â· 5:46 AM UTC")

Sources: Amazon's AI tools caused at least two AWS outages, including a 13-hour disruption in December after its Kiro AI deleted and recreated an environment ( [@rafeuddin\_](https://nitter.net/rafeuddin_ "Rafe Uddin") / Financial Times)

[ft.com/content/00c282de-ed14â€¦](https://www.ft.com/content/00c282de-ed14-4acd-a948-bc8d6bdb339d) [techmeme.com/260220/p1#a2602â€¦](http://www.techmeme.com/260220/p1#a260220p1)

ðŸ“¥ Send tips! [techmeme.com/contact](https://techmeme.com/contact)

21

303

2,023

[![](https://nitter.net/pic/profile_images%2F1661187442043486209%2Fa3E4t1eV_bigger.jpg)](https://nitter.net/rasbt)

[Sebastian Raschka](https://nitter.net/rasbt "Sebastian Raschka")

[@rasbt](https://nitter.net/rasbt "@rasbt")

[23h](https://nitter.net/rasbt/status/2024886543630966917#m "Feb 20, 2026 Â· 4:39 PM UTC")

February is one of those months...

\- Moonshot AI's Kimi K2.5 (Feb 2)
\- z. AI GLM 5 (Feb 12)
\- MiniMax M2.5 (Feb 12)
\- ByteDance Seed-2.0 (Feb 13)
\- Nanbeige 4.1 3B (Feb 13)
\- Qwen 3.5 (Feb 15)
\- Cohere's Tiny Aya (Feb 17)

(+Hopefully DeepSeek V4 soon)

Anything I forgot?

35

53

729

[![](https://nitter.net/pic/profile_images%2F1745893660099592193%2FMmYemsw6_bigger.jpg)](https://nitter.net/eliebakouch)

[elie](https://nitter.net/eliebakouch "elie")

[@eliebakouch](https://nitter.net/eliebakouch "@eliebakouch")

[22h](https://nitter.net/eliebakouch/status/2024893221545877734#m "Feb 20, 2026 Â· 5:05 PM UTC")

Qwen3-Coder-Next
Step 3.5 flash
joyai flash
ling and ring v2.5
Intern-S1-Pro

1

3

40

[![](https://nitter.net/pic/profile_images%2F1661187442043486209%2Fa3E4t1eV_bigger.jpg)](https://nitter.net/rasbt)

[Sebastian Raschka](https://nitter.net/rasbt "Sebastian Raschka")

[@rasbt](https://nitter.net/rasbt "@rasbt")

[22h](https://nitter.net/rasbt/status/2024894517317439781#m "Feb 20, 2026 Â· 5:10 PM UTC")

Ahhh Qwen3-Coder-Next... I actually looked into it (same architecture as Qwen3-Next I covered previously), so not sure why I forgot!

Thanks also for the other ones!

14

Graham Neubig retweeted

[![](https://nitter.net/pic/profile_images%2F2021416176610336768%2FFWPb-ujN_bigger.jpg)](https://nitter.net/ZhiruoW)

[Zora Wang](https://nitter.net/ZhiruoW "Zora Wang") [@ZhiruoW](https://nitter.net/ZhiruoW "@ZhiruoW")

[23h](https://nitter.net/ZhiruoW/status/2024880428612546655#m "Feb 20, 2026 Â· 4:14 PM UTC")

Most agents either run fully autonomously or interrupt at the wrong times.
What if agents know when YOU want to step in?

ðŸš€Introducing PlowPilot - a web agent that adapts to your interaction patterns
achieving +26.5% user-reported usefulness

Huge credit to [@FariaHuqOaishi](https://nitter.net/FariaHuqOaishi "Faria Huq | ðŸ¦‹: fariahuqoaishi") for leading this project!

[![](https://nitter.net/pic/media%2FHBnQdNzWAAAjwEx.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBnQdNzWAAAjwEx.jpg)

4

25

100

Aravind Srinivas retweeted

[![](https://nitter.net/pic/profile_images%2F1648535580870078465%2FOtGyTOWY_bigger.jpg)](https://nitter.net/Mr_Derivatives)

[Heisenberg](https://nitter.net/Mr_Derivatives "Heisenberg")

[@Mr\_Derivatives](https://nitter.net/Mr_Derivatives "@Mr_Derivatives")

[Feb 20](https://nitter.net/Mr_Derivatives/status/2024809372061409285#m "Feb 20, 2026 Â· 11:32 AM UTC")

Perplexity Finance > Google Finance.

AI battle in the financial sector heating upâ€¦

![](https://nitter.net/pic/profile_images%2F1615440606456864769%2FFgBZT7uE_mini.jpg)[Jeff Grimes](https://nitter.net/jeffgrimes9 "Jeff Grimes")

[@jeffgrimes9](https://nitter.net/jeffgrimes9 "@jeffgrimes9")

[Feb 19](https://nitter.net/jeffgrimes9/status/2024605091832180835#m "Feb 19, 2026 Â· 10:00 PM UTC")

Perplexity Finance now includes tap-through auditability to SEC filings. The filing is pre-scrolled to the page where that line item appears.

![](https://nitter.net/pic/amplify_video_thumb%2F2024604071425142784%2Fimg%2FHqNWDsYkDe6oZ49Z.jpg%3Fname%3Dsmall%26format%3Dwebp)

Enable hls playback

38

38

579

[![](https://nitter.net/pic/profile_images%2F1115600347%2Fdrawing-me_bigger.png)](https://nitter.net/gneubig)

[Graham Neubig](https://nitter.net/gneubig "Graham Neubig")

[@gneubig](https://nitter.net/gneubig "@gneubig")

[22h](https://nitter.net/gneubig/status/2024893532557955344#m "Feb 20, 2026 Â· 5:06 PM UTC")

Our Agent Data Protocol dataset now has 3.2M instances, double its original size!

Also the paper was accepted as an ICLR oral presentation!

Multimodal support coming soon as well.

[agentdataprotocol.com/](https://www.agentdataprotocol.com/)

![](https://nitter.net/pic/profile_images%2F1732388549260103680%2F1DlPnqVz_mini.jpg)[Yueqi Song](https://nitter.net/yueqi_song "Yueqi Song")

[@yueqi\_song](https://nitter.net/yueqi_song "@yueqi_song")

[23h](https://nitter.net/yueqi_song/status/2024890477133131890#m "Feb 20, 2026 Â· 4:54 PM UTC")

Updates:

Excited to share that Agent Data Protocol (ADP) is accepted to ICLR 2026 Oral! ðŸŽ‰

We also added support for 3 new datasets: SWE-Play, MiniCoder, and Toucan, bringing us to 3M trajectories supported.

If you're training agentic LMs, try ADP + tell us what dataset/agent format you want next. PRs & requests welcome. Let's make this the open standard for agent training data ðŸ”¥

ðŸš€Original post: [nitter.net/yueqi\_song/status/1983â€¦](https://nitter.net/yueqi_song/status/1983539504385253684)
ðŸ“„Read our paper: [arxiv.org/abs/2510.24702](https://arxiv.org/abs/2510.24702)
ðŸŒCheck our project website: [agentdataprotocol.com](https://agentdataprotocol.com/)

1

6

31

[![](https://nitter.net/pic/profile_images%2F1664559115581145088%2FUMD1vtMw_bigger.jpg)](https://nitter.net/vikhyatk)

[vik](https://nitter.net/vikhyatk "vik")

[@vikhyatk](https://nitter.net/vikhyatk "@vikhyatk")

[22h](https://nitter.net/vikhyatk/status/2024892638491779168#m "Feb 20, 2026 Â· 5:03 PM UTC")

if a developer reads a stackoverflow post and decides to delete and recreate a production stack, would you blame stackoverflow for causing the outage?

![](https://nitter.net/pic/profile_images%2F1868845402835017728%2FEw50qGxC_mini.jpg)[Ed Zitron](https://nitter.net/edzitron "Ed Zitron")

[@edzitron](https://nitter.net/edzitron "@edzitron")

[Feb 20](https://nitter.net/edzitron/status/2024725617221259767#m "Feb 20, 2026 Â· 5:59 AM UTC")

On two separate occasions Amazonâ€™s Kiro AI assistant caused an AWS outage, one that was 13 hours long. Amazon blames this on â€œuser error not AI error,â€ which is one of the most embarrassing things you could ever say as a human being

[![](https://nitter.net/pic/media%2FHBlFN9XbUAMB286.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBlFN9XbUAMB286.jpg)

[![](https://nitter.net/pic/media%2FHBlFN9XbUAIaID8.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBlFN9XbUAIaID8.jpg)

[![](https://nitter.net/pic/media%2FHBlFN9VaIAAuBSQ.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBlFN9VaIAAuBSQ.jpg)

3

39

[![](https://nitter.net/pic/profile_images%2F2017015061454438400%2FiNKfXZ_I_bigger.jpg)](https://nitter.net/arena)

[Arena.ai](https://nitter.net/arena "Arena.ai")

[@arena](https://nitter.net/arena "@arena")

[22h](https://nitter.net/arena/status/2024892330743124246#m "Feb 20, 2026 Â· 5:02 PM UTC")

ðŸ“ŠLetâ€™s dive deeper into [@AnthropicAI](https://nitter.net/AnthropicAI "Anthropic")'s Sonnet 4.6 vs 4.5. Overall: Sonnet 4.6 ranks 3 places higher (#13 vs #16)

Where Sonnet 4.6 gains:

Code:
â–ªï¸WebDev (+19 for Sonnet 4.6: #3 vs #22)

Text:
â–ªï¸Instruction Following (+6, #5 vs #11)
â–ªï¸English (+5, #9 vs #14)
â–ªï¸Hard Prompts (+5, #9 vs #14)

Occupational:
â–ªï¸Software & IT Services (+8, #8 vs #16)
â–ªï¸Writing, Literature, & Language (+4, #7 vs #11)
â–ªï¸Business, Management, & Financial Operations (+3, #10 vs #13)

Where Sonnet 4.5 is still ranking higher:

Text:
â–ªï¸Multi-Turn (4.5 leads by +3: #8 vs #11)
â–ªï¸Longer Query (4.5 leads by +2: #8 vs #10)

(note: these are calculated with style control).

[![](https://nitter.net/pic/media%2FHBnXvs1bAAAyAAd.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBnXvs1bAAAyAAd.jpg)

![](https://nitter.net/pic/profile_images%2F2017015061454438400%2FiNKfXZ_I_mini.jpg)[Arena.ai](https://nitter.net/arena "Arena.ai")

[@arena](https://nitter.net/arena "@arena")

[23h](https://nitter.net/arena/status/2024883614249615394#m "Feb 20, 2026 Â· 4:27 PM UTC")

Claude Sonnet 4.6 has landed #3 in Code and #13 in Text Arena!

Highlights:
â–ªï¸+130 pts jump in Code Arena (#22 -> #3) compared to Sonnet 4.5, surpassing top-tier thinking models like Gemini-3.1 and GPT-5.2

â–ªï¸Strong gains in Text categories: Math (#4) and Instruction Following (#5), Overall (#13)

Congrats to the [@AnthropicAI](https://nitter.net/AnthropicAI "Anthropic") team on another impressive milestone!

[![](https://nitter.net/pic/media%2FHBnQqe6bkAA1Tpd.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBnQqe6bkAA1Tpd.jpg)

10

10

158

[![](https://nitter.net/pic/profile_images%2F2017015061454438400%2FiNKfXZ_I_bigger.jpg)](https://nitter.net/arena)

[Arena.ai](https://nitter.net/arena "Arena.ai")

[@arena](https://nitter.net/arena "@arena")

[22h](https://nitter.net/arena/status/2024892333452656898#m "Feb 20, 2026 Â· 5:02 PM UTC")

Dig into the Arena leaderboard details for all the top frontier AI at: [arena.ai/leaderboard](http://arena.ai/leaderboard)

5

[![](https://nitter.net/pic/profile_images%2F1924485072801140736%2FVyZekL_z_bigger.jpg)](https://nitter.net/basetenco)

[Baseten](https://nitter.net/basetenco "Baseten")

[@basetenco](https://nitter.net/basetenco "@basetenco")

[23h](https://nitter.net/basetenco/status/2024891915637063714#m "Feb 20, 2026 Â· 5:00 PM UTC")

"No other product lets you launch ten different training jobs on four different datasets." â€“Head of Clinical NLP, OpenEvidence

Over 40% of U.S. physicians trust [@EvidenceOpen](https://nitter.net/EvidenceOpen "OpenEvidence")'s platform for fast, accurate medical information. Their secret: custom, specialized models built on Baseten Training.

Here's how we helped them save $1.9M via model training and improved their latency 23x to power 100M+ clinical consultations per year.

[baseten.co/resources/customeâ€¦](https://www.baseten.co/resources/customers/openevidence-baseten-training)

[![](https://nitter.net/pic/media%2FHBncdwNaAAAABFV.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBncdwNaAAAABFV.jpg)

6

26

merve retweeted

[![](https://nitter.net/pic/profile_images%2F1991559933473497089%2FmbrRS49P_bigger.jpg)](https://nitter.net/huggingface)

[Hugging Face](https://nitter.net/huggingface "Hugging Face")

[@huggingface](https://nitter.net/huggingface "@huggingface")

[Feb 20](https://nitter.net/huggingface/status/2024871487753044243#m "Feb 20, 2026 Â· 3:39 PM UTC")

Thrilled to have GGML with us going forward! ðŸ¤—â¤ï¸ðŸ¦™

Read the announcement blog [huggingface.co/blog/ggml-joiâ€¦](https://huggingface.co/blog/ggml-joins-hf)

[![](https://nitter.net/pic/media%2FHBnJ4vCW8AAmubV.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBnJ4vCW8AAmubV.jpg)

9

29

182

[![](https://nitter.net/pic/profile_images%2F1672359156391591939%2FKrJs4zUQ_bigger.jpg)](https://nitter.net/imjaredz)

[Jared Zoneraich](https://nitter.net/imjaredz "Jared Zoneraich")

[@imjaredz](https://nitter.net/imjaredz "@imjaredz")

[23h](https://nitter.net/imjaredz/status/2024889987833933943#m "Feb 20, 2026 Â· 4:52 PM UTC")

Uniquely American story

Americans excel at doing fun things

The best of our country do it for the love of the game

![](https://nitter.net/pic/profile_images%2F1927795530920239104%2Frv8FxhKB_mini.jpg)[Brad Stulberg](https://nitter.net/BStulberg "Brad Stulberg")

[@BStulberg](https://nitter.net/BStulberg "@BStulberg")

[Feb 19](https://nitter.net/BStulberg/status/2024628741910196463#m "Feb 19, 2026 Â· 11:34 PM UTC")

Joy is a competitive super power.

Alysa Liu retired from figure skating at 16.
She was tired of not not having fun, tired of being consumed by her sport.

She came back two years later with a new goal: to have as much fun on the ice as possible. And now sheâ€™s an Olympic gold medalist.

Liu won her first national title when she was just 13. But by 16, after competing in the 2022 Olympics, she decided sheâ€™d had enough and stepped away. She said pressure and losing her identity trying to be an elite athlete made it all miserable.

But then, she said she went on a ski trip that reminded her just how much fun she could have doing a sport. Something in her brain clicked. Maybe she could bring fun to figure skating. Maybe she could approach it in a way that could be full of joy and life and love.

She unretired at 18 and won a world championship the next year. At 20, she was ready to face these Olympic games differently than in 2022.

Liu went into the womenâ€™s figure skating final in third place. After her short program, she said:

â€œEven if I mess up and fall, thatâ€™s totally okay, too. Iâ€™m fine with any outcome, as long as Iâ€™m out there.â€

One of the greatest competitive advantages is having fun. People love to romanticize the athlete, artist, or entrepreneur who has a chip on their shoulder, fueled by anger and resentment.

But the truth is that if youâ€™re not having fun, you are not going to last long at whatever it is you do, and you certainly wonâ€™t get the best out of yourself. Thereâ€™s a foolish idea that you either have to be full of intensity or full of joy. But thatâ€™s nonsense.

Itâ€™s no surprise one of the first things out of Alysaâ€™s mouth after her free skate was: â€œThat was so much fun!â€

Joy and intensity can coexist, and in the best performers, they almost always do.

Alysa is unapologetically authentic and true to her values. She has said where she used to skate to win and be technically perfect, she now uses competition as a chance to show her art, to have fun, and to put herself out there.

Sheâ€™s a fierce athlete with an infectious sense of joy in her sport.

And she broke USA's 24-year gold medal draught in womenâ€™s figure skating doing it.

Excellence requires focus, determination, a little bit of crazy, at times obsession, and living a mundane lifestyle that many people would find boring.

But excellence also requires that you find deep joy in your craft, that you learn how to have fun while working hard.

What makes for excellenceâ€”and not just in sports, but in anythingâ€”is the combination of intensity and joy. Itâ€™s the latter that makes the former sustainable.

[![](https://nitter.net/pic/media%2FHBjolYDbUAIJFR4.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBjolYDbUAIJFR4.jpg)

4

[![](https://nitter.net/pic/profile_images%2F1831321531852496896%2F1yBZG884_bigger.jpg)](https://nitter.net/_philschmid)

[Philipp Schmid](https://nitter.net/_philschmid "Philipp Schmid")

[@\_philschmid](https://nitter.net/_philschmid "@_philschmid")

[23h](https://nitter.net/_philschmid/status/2024889903293563220#m "Feb 20, 2026 Â· 4:52 PM UTC")

ICYMI Gemini 3.1 Pro Preview is available on the Gemini Interactions API.

[ai.google.dev/gemini-api/docâ€¦](https://ai.google.dev/gemini-api/docs/interactions?ua=chat#basic-interactions)

[![](https://nitter.net/pic/media%2FHBnanFwXgAA9gwO.jpg%3Fname%3Dsmall%26format%3Dwebp)](https://nitter.net/pic/orig/media%2FHBnanFwXgAA9gwO.jpg)

6

4

66

[Load more](https://nitter.net/i/lists/1585430245762441216?cursor=DAABCgABHBsYPkH__e0KAAIcGdqjgxaBVAgAAwAAAAIAAA)