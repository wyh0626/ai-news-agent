---
description: "Gemini 3.1 Pro leads image-to-code on MagicPathAI; OpenAI reviewers debate British Columbia shooter's ChatGPT messages; AGI near, with ASI looming."
---

# AI Daily â€” 2026-02-20

> Covering 45 AI news items

## ðŸ”¥ Top Stories

### 1. Gemini 3.1 Pro Dominates Image-to-Code, on MagicPathAI

Gemini 3.1 Pro is claimed to be the leading model for converting images to code, suggesting the task is essentially solved. The post notes the model is now available through MagicPathAI and mentions enabling HLS playback. [Source-twitter](https://x.com/skirano/status/2024875637878526109)

### 2. OpenAI reviewers debated British Columbia shooter's ChatGPT messages

A report reveals that the British Columbia school shooter's ChatGPT messages were not only flagged by automation but were reviewed and debated by about a dozen OpenAI employees. The incident highlights the role of human moderation in AI safety workflows. [Source-twitter](https://x.com/AricToler/status/2024976260749820067)

### 3. AGI Very Close; Superintelligence and ASI Near

Frontier labs are alleged to be nearing AGI, with Superintelligence not far behind and ASI potentially within reach. The post emphasizes watching internal model acceleration and hints at a faster-than-expected take-off, fueling hype about imminent AI breakthroughs. [Source-twitter](https://x.com/kimmonismus/status/2024898716365455459)

## ðŸ“° Featured

### Multimodal

- **Lyria 3 by Google DeepMind Enables 30-Second Songs Inside Gemini Beta** â€” Google DeepMind's Lyria 3 is integrated into the Gemini app, allowing users to generate 30-second songs from text prompts or photos in beta. The output includes vocals and cover art, delivered directly in the Gemini app or on the website. [Source-producthunt](https://www.producthunt.com/products/lyria-3-by-google-deepmind?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+yinhewang+%28ID%3A+275680%29)

### LLM

- **GUI-Owl-1.5 Debuts Multi-Platform GUI Agent** â€” Researchers introduce GUI-Owl-1.5, a native GUI agent model available in multiple sizes (2B/4B/8B/32B/235B) with instruct/thinking variants. It supports desktop, mobile, browser, and other platforms to enable cloud-edge collaboration and real-time interaction. The model reportedly achieves state-of-the-art results on over 20 GUI benchmarks, including OSWorld (56.5), AndroidWorld (71.6), and WebArena (48.4). [Source-huggingface](https://huggingface.co/papers/2602.16855)
- **Chinese Models Dominate OpenRouter; Top 3 Surpass Trillion Tokens Weekly** â€” OpenRouter reports a milestone week, with at least one model exceeding 3 trillion tokens per week for the first time. More than one model surpassed a trillion tokens per week, a feat not seen since Grok 4 Fast months ago. Chinese models are leading the rankings, seemingly outperforming US counterparts. [Source-reddit](https://www.reddit.com/r/LocalLLaMA/comments/1r9zt8m/the_top_3_models_on_openrouter_this_week_chinese/)
- **Hugging Face Acquires GGML.AI** â€” GGML.AI has been acquired by Hugging Face, per a Reddit post. The acquisition marks a notable shift in the open-source AI tooling landscape as Hugging Face expands its ecosystem. The deal may influence integration of GGML.AI components with Hugging Face's platform. [Source-reddit](https://www.reddit.com/r/LocalLLaMA/comments/1r9vywq/ggmlai_has_got_acquired_by_huggingface/)
- **Claude Opus 4.6: 14.5-Hour 50% Time Horizon on Tasks** â€” Anthropic's Claude Opus 4.6 shows a 50% time-horizon of about 14.5 hours for software tasks, with a 95% CI of 6 to 98 hours. The estimate is the highest reported so far but is extremely noisy due to a saturated task suite, reflecting measurement uncertainty in benchmarking. [Source-twitter](https://x.com/METR_Evals/status/2024923422867030027)
- **Altman Warns of Rapid AI Takeoff, World Unprepared** â€” Sam Altman said AI companiesâ€™ inside view suggests extremely capable models are coming soon and that the world is not prepared. He warned the takeoff will be faster than he originally anticipated, describing it as stressful and anxiety-inducing. [Source-twitter](https://x.com/kimmonismus/status/2024887011522576766)
- **Every company building your AI assistant is an ad company** â€” The piece argues that firms developing AI assistants are increasingly turning into ad platforms, leveraging user data and targeted advertisements. It highlights privacy concerns and shifts in business models as AI assistants monetize through ads rather than pure services, with broader implications for users and developers. [Source-hackernews](https://juno-labs.com/blogs/every-company-building-your-ai-assistant-is-an-ad-company)
- **Ggml.ai Joins Hugging Face to Accelerate Local AI** â€” Ggml.ai announced it is joining Hugging Face to support the long-term progress of Local AI. The collaboration aims to combine ggml/llama.cpp-based tooling with Hugging Face's ecosystem to advance offline, privacy-preserving AI development. It signals growing emphasis on open-source local AI solutions. [Source-hackernews](https://github.com/ggml-org/llama.cpp/discussions/19759)
- **ByteDance Ouro-2.6B-Thinking Gains First Inference After 4.55 Fixes** â€” ByteDance released Ouro-2.6B-Thinking, a recurrent Universal Transformer that processes 48 layers four times per token (192 passes). The model faced compatibility issues with GGUFs due to transformers 4.55 changes; two bugs in modeling_ouro.py were fixed to enable proper inference. Early tests show correct output on a simple prompt, with NVIDIA L4 performance around 3.8 t/s and 5.3 GB memory usage. [Source-reddit](https://www.reddit.com/r/LocalLLaMA/comments/1ramir9/release_ouro26bthinking_first_working_inference/)
- **Strix Halo Benchmarks: Minimax M2.5, Step 3.5, Qwen3 Coder Next** â€” An AI benchmarking post reports llama.cpp benchmarks for Strix Halo models Minimax M2.5 and Step 3.5 Flash, plus Qwen3-coder-next, GLM 4.6V/4.7 Flash, and gpt-oss-120b. Benchmarks run on ROCm 7.2 with a Ryzen AI Max+ 395 (70W) and 128GB RAM, at 30,000-token context depth, with the author inviting model requests in the comments. [Source-reddit](https://www.reddit.com/r/LocalLLaMA/comments/1rabcyp/a_few_strix_halo_benchmarks_minimax_m25_step_35/)
- **TeichAI GLM-4.7, Flash Claude Opus 4.5 Distill on Hugging Face** â€” An open-source bundle featuring TeichAI/GLM-4.7 and Flash Claude Opus 4.5 High-Reasoning Distill has been highlighted on Hugging Face. The post was featured yesterday by Unsloth on X and shared on Reddit by user /u/jacek2023. [Source-reddit](https://www.reddit.com/r/LocalLLaMA/comments/1ranako/teichaiglm47flashclaudeopus45highreasoningdistillg/)
- **GGML and llama.cpp join HF to advance Local AI** â€” GGML and llama.cpp are joining Hugging Face to coordinate and sustain the long-term development of Local AI. The collaboration aims to align open-source tooling with Hugging Face's ecosystem, supporting ongoing progress and interoperability for locally run AI models. [Source-reddit](https://www.reddit.com/r/LocalLLaMA/comments/1r9wvg4/ggml_and_llamacpp_join_hf_to_ensure_the_longterm/)

### AI Safety

- **Claude Code Security Enters Limited Research Preview** â€” Anthropic introduces Claude Code Security, a tool that scans codebases for vulnerabilities and suggests targeted patches for human review. It helps teams find and fix issues that traditional tooling often misses. The feature is available in limited research preview; learn more at anthropic.com/news/claude-code-security. [Source-twitter](https://x.com/claudeai/status/2024907535145468326)

### AI

- **Stellan SkarsgÃ¥rd on AI's Growing Role in Film** â€” Stellan SkarsgÃ¥rd discusses the expanding influence of AI in cinema, noting that film has always explored human complexity and that AI could alter how stories are produced. He cautions that capital concentration, not the technology itself, is the industryâ€™s main challenge, and that AI remains dependent on people and the power structures behind it. [Source-twitter](https://x.com/Variety/status/2024983345499963815)
- **SpargeAttention2: Trainable Sparse Attention with Hybrid Masking** â€” Researchers investigate making sparse attention trainable to boost sparsity while preserving diffusion-model quality. They address failures of Top-k and Top-p masking, explain why trainable approaches can exceed training-free sparsity, and discuss the limits of fine-tuning via distillation. [Source-huggingface](https://huggingface.co/papers/2602.13515)

### Embodied AI

- **Pika AI Selves Debuts: Personal, Memory-Rich AI Progeny** â€” Pika Labs unveils Pika AI Selves, AI agents you birth, raise, and deploy as living extensions of yourself. Supposedly memory-rich and multimodal, they can perform tasks like sending pictures, creating games about your fish, or calling your mom. Interested users can join a waitlist at pika.me to birth their own AI self. [Source-twitter](https://x.com/pika_labs/status/2024919175878377587)

### Open Source

- **DreamDojo: Open-Source Interactive World Model for Robotic Pretraining** â€” DreamDojo is an open-source, interactive world model that takes robot motor commands and renders future frames in pixels, eliminating engines, meshes, or hand-authored dynamics. It pre-trains on 44,000 hours of human egocentric videos and uses latent actions to stay robot-readable across hardware, enabling real-time teleoperation, policy evaluation, and test-time planning inside the dream. [Source-twitter](https://x.com/DrJimFan/status/2024895359236051274)
- **RynnBrain: Open Embodied Foundation Model for Real-World AI** â€” RynnBrain is introduced as an open-source spatiotemporal foundation model aimed at embodied intelligence. It seeks to unify perception, reasoning, and planning within real-world spatial-temporal dynamics, strengthening four core capabilities in a unified framework, including egocentric understanding and diverse spatiotemporal localization. [Source-huggingface](https://huggingface.co/papers/2602.14979)
- **PentAGI: Autonomous AI Agents for Penetration Testing** â€” PentAGI is an open-source tool that automates security testing using AI, designed for information security professionals and enthusiasts. It offers a sandboxed, Docker-based environment with a modular framework for LLM agents, embeddings, and testing workflows to perform complex penetration tasks. [Source-github](https://github.com/vxcontrol/pentagi)
- **Vellium v0.3.5: Massive Writing Mode Upgrade, Native KoboldCpp, OpenAI TTS** â€” Vellium releases v0.3.5 with a major rewrite of its writing mode, improved local provider support, and new features like a book bible, DOCX import, and cached summaries. The update also enables OpenAI TTS and AI-assisted character patch-editing, streamlines the UI, and makes KoboldCpp integration fully native for local setups, including provider:memory, universal tags, and n-sigma. [Source-reddit](https://www.reddit.com/r/LocalLLaMA/comments/1rafo5b/update_vellium_v035_massive_writing_mode_upgrade/)

### Diffusion Models

- **SLA2 Improves Sparse-Linear Attention with Learnable Routing** â€” SLA combines sparse and linear attention to accelerate diffusion models and video generation, but relies on a heuristic split that can be suboptimal. The paper analyzes attention error and identifies a mismatch with a direct decomposition, proposing SLA2 with learnable routing and QAT to address these issues. [Source-huggingface](https://huggingface.co/papers/2602.12675)

### RL

- **AutoWebWorld Synthesizes Verifiable Web Environments via Finite State Machines** â€” AutoWebWorld introduces a framework to synthesize controllable, verifiable web interaction environments using finite state machines. It targets the bottleneck of obtaining real-world interaction trajectories for autonomous Web GUI agents, where hidden state transitions complicate verification. By providing synthetic, verifiable training environments, it aims to improve data quality and evaluation reliability. [Source-huggingface](https://huggingface.co/papers/2602.14296)

### Industry

- **Meta Deploys AI, Killing Our Agency** â€” An editorial on Mojodojoâ€”amplified by a Hacker News postâ€”argues that Meta's AI deployment undermines advertising agencies by automating work they traditionally perform. The piece claims Meta's AI-driven changes threaten client relationships and livelihoods, prompting debate about AI disruption in the advertising industry. [Source-hackernews](https://mojodojo.io/blog/meta-is-systematically-killing-our-agency/)

## âš¡ Quick Bites

- **AI May Replace Software Engineers Before Amazon Support Reps** â€” A tweet notes the irony that AI might automate software engineers before Amazon's 100,000 customer support reps. It argues that the people who build automation are automated first, highlighting counterintuitive dynamics in AI-driven labor shifts. [Source-twitter](https://x.com/Yuchenj_UW/status/2024907354656178257)
- **Claude Code Desktop Adds App Preview, Code Review, CI/PR Automation** â€” Anthropic's Claude Code on desktop can now preview running apps and review code, with background handling of CI failures and PRs. The update also enables HLS playback, extending Claude Code's automation for developers. [Source-twitter](https://x.com/claudeai/status/2024937960572104707)
- **Cursor tames Gemini, keeps Google models productive** â€” Cursor claims its tooling tames Google's Gemini, providing the only harness that keeps the models productive and on task. It casts Cursor as a standout option for managing large-language models like Gemini. The claim highlights the importance of model-management tooling in enterprise AI. [Source-twitter](https://x.com/theo/status/2024839053900910612)
- **OpenAI reports positive progress across all teams** â€” OpenAI's leadership posted a tweet signaling strong momentum, noting positive progress across all parts of the organization. The message emphasizes team pride but provides no specific details or metrics. It suggests broad internal momentum without public milestones. [Source-twitter](https://x.com/gdb/status/2024985187579560366)
- **Prism Videos: Unified AI video creation workspace with templates** â€” Prism launches an all-in-one AI video creation platform that lets users generate image and video assets from multiple models, organize them in a project, and edit on a timeline without downloading files. It supports templates and one-click asset recreation, enabling reuse of presets from Prism or the community instead of rebuilding assets from scratch. [Source-producthunt](https://www.producthunt.com/products/prism-videos?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+yinhewang+%28ID%3A+275680%29)
- **Rork Max: AI Swift app builder for iOS and Apple platforms** â€” Rork Max markets itself as an AI-powered Swift app builder that aims to replace Xcode for building iOS apps across Apple devices, including AR and 3D features. It claims to be the first web-based Swift app builder, with one-click iPhone installation and two-click deployment to the App Store. The platform touts cross-platform support across iPhone, iPad, Apple Watch, Apple TV, Vision Pro, and iMessage. [Source-producthunt](https://www.producthunt.com/products/rork-app-for-ios?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+yinhewang+%28ID%3A+275680%29)
- **git-lrc: Free AI code reviews on every git commit** â€” git-lrc hooks into git to run an AI review on every diff before it lands. It aims to prevent issues like broken logic, leaked credentials, and costly cloud calls when using GenAI. The tool positions itself as a braking system for AI-assisted coding. [Source-producthunt](https://www.producthunt.com/products/git-lrc?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+yinhewang+%28ID%3A+275680%29)
- **Woise: AI Voice & Screen Recorder for Website Feedback** â€” Woise is an AI-powered tool that lets users capture screen activity and voice to report bugs or propose features on websites. It automatically converts spoken feedback into text for quick review, reducing back-and-forth and guesswork. The goal is to turn vague reports like 'it's broken' into actionable, contextual feedback. [Source-producthunt](https://www.producthunt.com/products/woise-2?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+yinhewang+%28ID%3A+275680%29)
- **Cord: Coordinating Trees of AI Agents** â€” The item discusses Cord, a concept for coordinating AI agents arranged in hierarchical trees. It proposes hierarchical collaboration among agents to improve task decomposition and coordination, sparking discussion on scalable agent orchestration. [Source-hackernews](https://www.june.kim/cord)
- **Hugging Face Skills: Interoperable AI Task Definitions** â€” Hugging Face introduces Skills, reusable AI/ML task modules for dataset creation, model training, and evaluation. The Skills framework is designed to work across major coding agent tools (OpenAI Codex, Claude Code, Google DeepMind Gemini CLI, Cursor) and uses a standardized Agent Skill format with folders containing a SKILL.md file. The article notes terminology differences: 'Skills' is an Anthropic term used in Claude AI/Claude Code, while other tools use formats like AGENTS.md (Codex) or Gemini extensions. [Source-github](https://github.com/huggingface/skills)
- **Anthropic Launches Official Claude Code Plugins Directory** â€” Anthropic released an official, Anthropic-managed directory for Claude Code plugins, offering internal plugins under /plugins and third-party external plugins under /external_plugins. The directory provides installation guidance via Claude Code's plugin system and cautions users to trust plugins, noting Anthropic cannot verify third-party components. The repository at anthropics/claude-plugins-official hosts the project and shows internal plugins developed by Anthropic with a reference implementation reference. [Source-github](https://github.com/anthropics/claude-plugins-official)
- **Best Audio Models Feb 2026 Megathread** â€” A Reddit megathread highlights notable audio AI models (ASR, TTS, STT, and Text-to-Music) as of February 2026, inviting detailed setup and empirical comparisons. It notes closed models like ElevenLabs v3 often outperform open models for long-form, production use, with Qwen3 TTS singled out as notable. [Source-reddit](https://www.reddit.com/r/LocalLLaMA/comments/1r7bsfd/best_audio_models_feb_2026/)
- **GLM 5 Exhibits Claude-like Personality Under Claude Prompt** â€” A Reddit post claims GLM 5 changes its writing style and appears to bypass built-in censorship when prompted to act as Claude, Anthropic's model. Attempts to trigger a different persona, such as Tiny by Applet, do not replicate the effect, prompting speculation about the causes. The author speculates whether Claude-like traits are in GLM 5's training data or reflect emergent behavior, and notes Claude Code compatibility as a possibility. [Source-reddit](https://www.reddit.com/r/LocalLLaMA/comments/1raf3dm/glm_5_seems_to_have_a_claude_personality/)
- **AI Singularity Emerges as AI Takes Off** â€” An AI-focused Twitter post hints that the AI singularity is taking off, signaling accelerating AI progress. The message provides no technical details or evidence. Context is limited, making the claim more promotional than explanatory. [Source-twitter](https://x.com/scaling01/status/2024925692853395618)
- **I Hate AI Side Projects** â€” Dylan Castillo critiques the AI side projects trend, arguing that many hobbyist efforts prioritize flashy demos over durable impact. The piece questions practical value, long-term maintainability, and the broader effects on the AI community. [Source-hackernews](https://dylancastillo.co/posts/ai-side-projects.html)
- **Professor seeks lesser-known HuggingFace models for teaching** â€” A professor asks for recommendations of unique, lesser-known models hosted on HuggingFace to showcase beyond chatGPT. The post aims to expand students' minds by highlighting interesting and useful models, inviting the community to share suggestions. It was submitted by u/EngineeringBright82 on Reddit's r/LocalLLaMA. [Source-reddit](https://www.reddit.com/r/LocalLLaMA/comments/1rajez2/what_are_your_favorite_lesser_known_models_on/)
- **Gemma to Release New Version Soon** â€” A Reddit post on r/LocalLLaMA by user jacek2023 announces that Gemma will have a new version released soon. The post provides no release date or feature details. It appears to be an AI project update within the LocalLLaMA community. [Source-reddit](https://www.reddit.com/r/LocalLLaMA/comments/1ra8omf/gemma_which_we_will_be_releasing_a_new_version_of/)
- **New Jersey Residents Defeat AI Data Center in Community Victory** â€” New Jersey residents defeated a proposed AI data center, signaling strong community opposition to AI infrastructure and Big Tech expansion. The case highlights concerns about local impact, energy use, and data privacy associated with AI deployments. [Source-hackernews](https://www.commondreams.org/news/new-brunswick-ai-data-center)
- **Deepseek and Gemma: Reddit Discussion** â€” A Reddit post from /u/ZeusZCC on the LocalLLaMA subreddit highlights two AI items, Deepseek and Gemma. The snippet provides no further details beyond the post link. [Source-reddit](https://www.reddit.com/r/LocalLLaMA/comments/1r9uuc6/deepseek_and_gemma/)

---

*Generated by AI News Agent | 2026-02-20*