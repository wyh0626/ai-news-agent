---
description: "Frontier Labs accelerates AGI/ASI takeoff; Taalas demos Llama 3 8B at 16k tokens/s per user; GUI-Owl-1.5 launches multi-platform GUI agents."
---

# AI Daily â€” 2026-02-20

> Covering 45 AI news items

## ðŸ”¥ Top Stories

### 1. AGI and ASI Close: Frontier Labs Accelerate Toward Takeoff

A tweet questions what's happening inside frontier AI labs as signals point to AGI being very close and superintelligence not far off. The post notes observing how fast models accelerate internally and suggests AI takeoff could be faster than expected. It reflects hype around imminent artificial general and superintelligent capabilities. [Source-twitter](https://x.com/kimmonismus/status/2024898716365455459)

### 2. Taalas Demonstrates Llama 3 8B at 16k Tokens/s per User

Taalas showcases a model-specific accelerator where every chip is the model, here Llama 3 8B, delivering 16k tokens per second per user. The setup is claimed to outpace SRAM-based systems like Cerebras by roughly an order of magnitude. A chat demo accompanying the proof-of-concept is described as pretty wild. [Source-twitter](https://x.com/awnihannun/status/2024671348782711153)

### 3. GUI-Owl-1.5 Unveils Multi-Platform GUI Agents

Open-source paper introduces GUI-Owl-1.5, a native GUI agent model with instruct/thinking variants in multiple sizes (2B/4B/8B/32B/235B) and support for desktop, mobile, and browser platforms to enable cloud-edge collaboration and real-time interaction. It reports state-of-the-art results on more than 20 GUI benchmarks, with scores such as 56.5 (OSWorld), 71.6 (AndroidWorld), and 48.4 (WebArena) on GUI automation and grounding tasks. [Source-huggingface](https://huggingface.co/papers/2602.16855)

## ðŸ“° Featured

### Multimodal

- **MAEB Benchmark Finds No Dominant Model Across Audio Tasks** â€” The Massive Audio Embedding Benchmark (MAEB) assesses 30 tasks spanning speech, music, environmental sounds, and cross-modal audio-text reasoning in over 100 languages, evaluating 50+ models. The study finds no single model excels across all tasks; contrastive audio-text models perform best on environmental sound classification like ESC50 but struggle on multilingual speech tasks such as SIB-FLEURS, while speech-pretrained models show the opposite pattern. [Source-huggingface](https://huggingface.co/papers/2602.16008)

### AI in Advertising

- **Meta's AI Deployment Is Killing Our Agency** â€” A post argues that Meta's AI rollout is undermining traditional advertising agencies by automating core functions and eroding value. It warns of systemic harm to agency business models and calls for reevaluating reliance on Meta's AI in the advertising ecosystem. [Source-hackernews](https://mojodojo.io/blog/meta-is-systematically-killing-our-agency/)

### LLM

- **Strix Halo Benchmarks: Minimax M2.5, Step 3.5, Qwen3-Coder Next** â€” An experimental benchmark run compares Strix Halo models (Minimax M2.5 and Step 3.5 Flash) on llama.cpp, with additional testing of Qwen3-Coder-Next, GLM 4.6V/4.7 Flash, and gpt-oss-120b. Benchmarks were performed on ROCm 7.2 with a Ryzen AI Max+ 395 @70W and 128GB RAM, at a 30,000-token context depth. The author invites requests for additional models or quanta in the comments. [Source-reddit](https://www.reddit.com/r/LocalLLaMA/comments/1rabcyp/a_few_strix_halo_benchmarks_minimax_m25_step_35/)
- **Hugging Face acquires GGML.AI** â€” A Reddit post reports that GGML.AI has been acquired by Hugging Face. The move signals consolidation in open-source AI tooling and could expand Hugging Face's platform capabilities with GGML's technology. The post provides the source but does not offer official confirmation. [Source-reddit](https://www.reddit.com/r/LocalLLaMA/comments/1r9vywq/ggmlai_has_got_acquired_by_huggingface/)
- **SpargeAttention2: Trainable Sparse Attention with Hybrid Masking** â€” Researchers introduce SpargeAttention2, a trainable sparse attention method that uses a hybrid of Top-k and Top-p masking together with distillation fine-tuning to increase sparsity without sacrificing quality in diffusion models. They examine when Top-k and Top-p masking fail, how to avoid these failures, and why trainable sparse attention can surpass training-free methods, while also outlining the limitations of fine-tuning. [Source-huggingface](https://huggingface.co/papers/2602.13515)
- **Frontier AI Updates Risk Management Framework v1.5** â€” Frontier AI releases an updated Risk Management Framework in Practice (v1.5), offering a granular risk analysis of frontier AI models as LLM capabilities accelerate and agentic AI proliferates. The report highlights five critical dimensions, including cyber offense and persuasion/manipulation, to assess unprecedented risks posed by rapidly advancing AI. [Source-huggingface](https://huggingface.co/papers/2602.14457)
- **Feedback Timing for Agentic LLM In-Car Assistants** â€” A controlled mixed-methods study (N=45) examines how agentic LLM-based in-car assistants should communicate progress and reasoning during multi-step tasks, comparing planned steps and intermediate results feedback to silent final-only responses. The findings have implications for user experience and safety in attention-critical driving contexts. [Source-huggingface](https://huggingface.co/papers/2602.15569)
- **Arcee Trinity Large Technical Report Released; Nano and Mini Details** â€” Arcee Trinity Large's technical report details a sparse Mixture-of-Experts model with 400B total parameters and 13B activated per token. The report also covers Trinity Nano (6B total, 1B activated) and Trinity Mini (26B total, 3B activated), describing architecture with interleaved local/global attention, gated attention, depth-scaled sandwich norm, and sigmoid routing for MEs. [Source-huggingface](https://huggingface.co/papers/2602.17004)
- **Top OpenRouter Models This Week: Chinese Domination** â€” OpenRouter shows unprecedented token usage, with one model surpassing 3 trillion tokens weekly and more than one crossing the 1-trillion mark. This marks a milestone in scale and performance, highlighting Chinese models outperforming US counterparts in this space. The trend signals a shift in open-source LLM leadership. [Source-reddit](https://www.reddit.com/r/LocalLLaMA/comments/1r9zt8m/the_top_3_models_on_openrouter_this_week_chinese/)
- **ByteDance Ouro-2.6B-Thinking Delivers First Working Inference** â€” ByteDance released Ouro-2.6B-Thinking, a recurrent Universal Transformer that runs 192 effective passes per token, unlike standard one-pass models. The author details fixes for transformers 4.55 compatibilityâ€”addressing UniversalTransformerCache attributes and a missing get_mask_sizes() methodâ€”enabling the first working inference. In a test prompt, the model outputs 4 for 2+2, with NVIDIA L4 performance around 3.8 t/s using 5.3 GB. [Source-reddit](https://www.reddit.com/r/LocalLLaMA/comments/1ramir9/release_ouro26bthinking_first_working_inference/)
- **Qwen3 Coder Next Surpasses 30B Models with Aggressive Quantization** â€” A Reddit post claims Qwen Next Coder at Q2 quantization avoids nonsense outputs and can even generate a simple HTML front page, self-correcting mistakes when prompted, outperforming several 30B-range models. The author expresses surprise at its performance with aggressive quantization and asks for others' experiences and explanations for its effectiveness. The discussion centers on model quantization and comparative performance among lightweight LLMs. [Source-reddit](https://www.reddit.com/r/LocalLLaMA/comments/1rabg6o/qwen3_coder_next_oddly_usable_at_aggressive/)
- **Vellium 0.3.5: Writing Mode Overhaul, KoboldCpp Native, TTS** â€” Vellium updates from v0.2.8 to v0.3.5 with a major overhaul of the writing mode, adding a book bible, direct DOCX import, and cached book summaries, plus UI/UX improvements and more reliable project export/import. It also makes KoboldCpp integration fully native for local setups, aligns payload fields with the official API, and fixes model loading issues. Additionally, OpenAI-compatible TTS with a separate translation model is introduced. [Source-reddit](https://www.reddit.com/r/LocalLLaMA/comments/1rafo5b/update_vellium_v035_massive_writing_mode_upgrade/)
- **TeichAI GLM-4.7, Flash-Claude, Opus-4.5 High-Reasoning Distill on GGUF** â€” TeichAI released a bundle of open-source LLMs including GLM-4.7, Flash-Claude, and Opus-4.5, presented as high-reasoning distillations in GGUF format for Hugging Face. The showcase was featured yesterday by Unsloth on X and shared on Reddit (r/LocalLLaMA) by user /u/jacek2023. [Source-reddit](https://www.reddit.com/r/LocalLLaMA/comments/1ranako/teichaiglm47flashclaudeopus45highreasoningdistillg/)

### AI Safety

- **British Columbia school shooter's ChatGPT messages reviewed by OpenAI staff** â€” New reporting shows the British Columbia school shooter's ChatGPT messages weren't only flagged by automated systems; a dozen OpenAI employees reviewed and debated them. The disclosure highlights the level of human involvement in AI safety moderation and content review for high-risk incidents. [Source-twitter](https://x.com/AricToler/status/2024976260749820067)
- **Trajectory-Based Safety Audit Evaluates Clawdbot (OpenClaw)** â€” Researchers present a trajectory-centric safety evaluation of Clawdbot, a self-hosted, tool-using personal AI agent, across six risk dimensions. The test suite adapts scenarios from ATBench and LPS-Bench and adds hand-designed cases to stress-test safety under ambiguity and adversarial steering. [Source-huggingface](https://huggingface.co/papers/2602.14364)

### AI in media

- **Stellen Skarsgard on AI's growing role in film industry** â€” Stellen Skarsgard discusses AI's expanding presence in cinema, asserting that film remains about describing human relations and unspoken aspects. He warns that the impact of AI depends on who controls it, highlighting capital concentration and ownership by tech barons as a key challenge for the industry. [Source-twitter](https://x.com/Variety/status/2024983345499963815)

### Open Source

- **ggml.ai joins Hugging Face to advance llama.cpp and open source** â€” ggml.ai has joined Hugging Face to continue building ggml and improve llama.cpp accessibility, empowering the open-source community. The collaboration aims to make local AI easy and efficient to run on users' own hardware. [Source-twitter](https://x.com/ggerganov/status/2024839991482777976)

### Reinforcement Learning

- **AutoWebWorld Synthesizes Verifiable Web Environments with FSMs** â€” AutoWebWorld introduces a framework to synthesize controllable and verifiable web environments using finite state machines. It addresses the high cost and verification challenges of collecting real interaction data for training autonomous Web GUI agents by generating trajectories with verifiable step-level correctness and reducing reliance on external verifiers. The approach aims to provide scalable, verifiable training environments for AI agents operating on websites. [Source-huggingface](https://huggingface.co/papers/2602.14296)

### Embodied AI

- **RynnBrain Launches Open-Source Embodied Foundation Model** â€” RynnBrain introduces an open-source spatiotemporal foundation model for embodied intelligence, integrating perception, reasoning, and planning within real-world dynamics. It emphasizes egocentric understanding, spatiotemporal localization, and physical grounding within a unified framework. [Source-huggingface](https://huggingface.co/papers/2602.14979)
- **HERO Enables Open-Vocabulary Humanoid Loco-Manipulation** â€” The work tackles visual loco-manipulation with humanoid robots, highlighting the need for precise end-effector control and robust scene understanding from RGB-D inputs. It notes that current imitation-learning approaches struggle to generalize due to limited large-scale training data. The paper introduces HERO, a new paradigm for object loco-manipulation that aims to improve generalization through open-vocabulary perception and control. [Source-huggingface](https://huggingface.co/papers/2602.16705)

### Diffusion Models

- **UL: Unified Latents Train Latents with Diffusion Prior** â€” UL introduces a framework for learning latent representations jointly regularized by a diffusion prior and decoded by a diffusion model. By tying the encoderâ€™s output noise to the priorâ€™s minimum noise level, UL yields a training objective that upper-bounds latent bitrate. On ImageNet-512, UL achieves a competitive FID of 1.4 and high PSNR reconstruction while using fewer training FLOPs than comparable baselines. [Source-huggingface](https://huggingface.co/papers/2602.17270)

## âš¡ Quick Bites

- **Claude Code adds built-in git worktree support for CLI** â€” Claude Code now includes built-in git worktree support for its CLI, enabling multiple agents to run in parallel without interference. Each agent receives its own worktree and can operate independently. This expands the previously desktop-only feature to the CLI; learn more at git-scm.com/docs/git-worktree. [Source-twitter](https://x.com/bcherny/status/2025007393290272904)
- **Positive progress across all OpenAI parts, team proud** â€” A tweet highlights broad positive progress across OpenAI's various teams and components. The author expresses pride in the team's efforts and momentum. [Source-twitter](https://x.com/gdb/status/2024985187579560366)
- **SLA2 Introduces Learnable Routing for Efficient Attention** â€” An enhanced Sparse-Linear Attention (SLA2) architecture is proposed, featuring learnable routing between sparse and linear branches and quantization-aware training (QAT) to speed diffusion-model attention. The authors argue SLA's heuristic split by attention-weight magnitude can be suboptimal and identify a mismatch with a direct decomposition of sparse and linear attention. The work is presented as a research note on HuggingFace, aiming to improve efficiency in diffusion-model video generation. [Source-huggingface](https://huggingface.co/papers/2602.12675)
- **CADEvolve Enables Realistic CAD via Program Evolution** â€” CADEvolve proposes using program evolution to produce more realistic CAD tasks, aiming at full automation for engineering modeling. The report notes that progress is limited by data quality, with public corpora focusing on simple sketch-extrude workflows and lacking complex operations and design intent. Attempts to bypass data gaps with frozen Vision-Language Models often yield simple or invalid CAD programs due to insufficient 3D grounding. [Source-huggingface](https://huggingface.co/papers/2602.16317)
- **Recall Bottleneck Shapes Parametric Factuality in LLMs** â€” Standard factuality tests for large language models treat errors uniformly, masking whether failures stem from missing knowledge or limited access. The article proposes a behavioral framework that profiles facts by encoding status and accessibility: cannot be recalled, directly recalled, or recalled only with inference-time computation. By focusing on facts rather than questions, the approach aims to better diagnose and improve parametric factuality in LLMs. [Source-huggingface](https://huggingface.co/papers/2602.14080)
- **Multi-Agent Cooperation via In-Context Co-Player Inference** â€” This work addresses how self-interested agents can achieve cooperation in multi-agent reinforcement learning. It proposes learning-aware agents that account for and shape co-players' learning dynamics to induce mutual cooperation, avoiding rigid hardcoded assumptions about co-learning rules. [Source-huggingface](https://huggingface.co/papers/2602.16301)
- **Cord Coordinates AI Agent Trees** â€” Cord introduces a framework for coordinating multiple AI agents arranged as trees. The piece discusses hierarchical coordination, communication strategies, and modular components to improve scalability in AI systems. [Source-hackernews](https://www.june.kim/cord)
- **PentAGI: Autonomous AI Agents for Penetration Testing** â€” PentAGI is an open-source tool that uses autonomous AI agents to perform complex penetration testing tasks. It operates in a sandboxed Docker environment for isolation and targets information security professionals and researchers, with documentation covering overview, features, setup, and development/testing. [Source-github](https://github.com/vxcontrol/pentagi)
- **obra's Superpowers: Agentic Skills for Coding Agents** â€” Superpowers is an open-source software development workflow for coding agents built from composable 'skills' and starter instructions. It guides the agent to first clarify the user's goals, deliver a signed-off, chunked spec, and an implementable plan emphasizing red/green TDD, YAGNI, and DRY, before executing with a subagent-driven approach. The project is available on GitHub under the obra/superpowers repository. [Source-github](https://github.com/obra/superpowers)
- **Hugging Face Skills Enable Interoperable AI Tasks** â€” Hugging Face introduces Skills, a self-contained framework for AI/ML tasks like dataset creation, model training, and evaluation. Skills package instructions, scripts, and resources in folders with a YAML frontmatter in SKILL.md, designed for interoperability with major coding agents such as OpenAI Codex, Claude Code, Gemini CLI, and Cursor. While 'Skills' is an Anthropic term within Claude AI, the repository stresses standardization across tools via the Agent Skill format. [Source-github](https://github.com/huggingface/skills)
- **New Jersey Residents Defeat AI Data Center** â€” Local residents in New Brunswick, New Jersey organized against a planned AI data center. Through protests and community activism, they secured the project's defeat, signaling grassroots opposition to AI infrastructure. The piece frames the victory as a stand against large-scale tech development. [Source-hackernews](https://www.commondreams.org/news/new-brunswick-ai-data-center)
- **AI Assistants Become Advertising Platforms for All Builders** â€” A Hacker News discussion highlights a Juno Labs blog arguing that every company building AI assistants monetizes primarily through ads and data, turning user interactions into ad targeting data. The piece raises privacy and business-model implications as AI assistants increasingly function as ad platforms. [Source-hackernews](https://juno-labs.com/blogs/every-company-building-your-ai-assistant-is-an-ad-company)
- **StepFun AI Announces LocalLLaMA AMA** â€” StepFun AI announces its first AMA in the LocalLLaMA community, featuring top executives and researchers. The session will run from 8-11 AM PST on February 19, with 24 hours of follow-up Q&A and will cover StepFun's Step family models, including Step 3.5 Flash and Step-3-VL-10B. [Source-reddit](https://www.reddit.com/r/LocalLLaMA/comments/1r8snay/ama_with_stepfun_ai_ask_us_anything/)
- **GLM 5 shows Claude-like personality** â€” A Reddit post claims GLM 5 adopts a Claude-like persona when instructed with a Claude prompt, including altered writing style and apparent bypass of safety filters. The author notes that alternative prompts do not produce the same effect, fueling speculation about training data, hidden prompts, or emergent behavior. The discussion mentions potential ties to Claude Code and remains unverified. [Source-reddit](https://www.reddit.com/r/LocalLLaMA/comments/1raf3dm/glm_5_seems_to_have_a_claude_personality/)
- **Favorite Lesser-Known Hugging Face Models?** â€” A professor asks the Reddit community for recommendations of unique, useful models hosted on Hugging Face beyond popular chatbots like ChatGPT. The post aims to broaden students' exposure to lesser-known AI models and invites knowledgeable responders to share interesting options. [Source-reddit](https://www.reddit.com/r/LocalLLaMA/comments/1rajez2/what_are_your_favorite_lesser_known_models_on/)
- **Kimi Eyes Context Window Expansion Ambitions** â€” The Reddit post discusses LocalLLaMA's Kimi model pursuing larger context windows. It notes potential benefits for longer input sequences and highlights challenges like memory usage and efficiency. The discussion centers on feasibility and implications of expanding the model's token context. [Source-reddit](https://www.reddit.com/r/LocalLLaMA/comments/1r9qa7l/kimi_has_context_window_expansion_ambitions/)
- **Best Audio Models Feb 2026 Megathread** â€” Reddit's Best Audio Models thread spotlights recent audio AI advances, notably Qwen3 TTS. It invites detailed comparisons across ASR, TTS, STT, and Text-to-Music, including setup, usage, and tooling, with a preference for open-weights models. The post notes closed models like ElevenLabs v3 often outperform open models in production contexts and encourages empirical, community-driven evaluations. [Source-reddit](https://www.reddit.com/r/LocalLLaMA/comments/1r7bsfd/best_audio_models_feb_2026/)
- **AI Singularity Takes Off: Welcome to a New Era** â€” An X/Twitter post proclaims the arrival of an AI singularity and that AI is taking off. The message conveys optimism about rapid AI advancement but provides no specifics. It signals ongoing hype around AI progress rather than verifiable claims. [Source-twitter](https://x.com/scaling01/status/2024925692853395618)
- **Critique of AI Side Projects Sparks Debate** â€” An article by Dylan Castillo critiques AI side projects, arguing they distract from meaningful AI development. Shared on Hacker News, it generated notable engagement (67 points and 91 comments) and links to dylancastillo.co. [Source-hackernews](https://dylancastillo.co/posts/ai-side-projects.html)
- **Phil Spencer exits Microsoft as AI executive takes Xbox reins** â€” Phil Spencer is exiting Microsoft, with an AI executive taking over the Xbox leadership. The move suggests a push to embed AI leadership within Microsoft's gaming strategy. The change shifts responsibility for Xbox away from Spencer while signaling broader AI-driven priorities in the division. [Source-hackernews](https://www.neowin.net/news/phil-spencer-is-exiting-microsoft-as-ai-executive-takes-over-xbox/)
- **Query on Deepseek and Gemma in LocalLLaMA** â€” A Reddit post by /u/ZeusZCC asks about Deepseek and Gemma, two AI-related projects, with no additional context. The post links to the LocalLLaMA discussion and provides no further details. [Source-reddit](https://www.reddit.com/r/LocalLLaMA/comments/1r9uuc6/deepseek_and_gemma/)

---

*Generated by AI News Agent | 2026-02-20*