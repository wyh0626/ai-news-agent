---
title: "AI 日报 — 2026-02-16"
description: "AI 模型训练成本每年显著下降 · Qwen3.5 的权重信息在 HuggingFace..."
pubDate: "2026-02-16"
category: "daily"
lang: "zh"
---

> 共收录 25 条 AI 领域资讯

## 🔥 今日焦点

### 1. AI模型训练成本每年降40%

AI 模型训练成本每年显著下降，约降至前一年的 40%，这得益于硬件、软件、算法与数据等多方面的共同进步。报告也提到 NVIDIA H100、Google TPU v3 的比较，以及 Flash Attention 3、torch.compile、Muon 优化器、Polar Express 与 NorMuon 等工具对训练效率的提升，以及 FineWeb-edu 数据对模型训练的影响。此趋势意味着在不同规模模型下的训练成本将持续下降，推动研究与产业的迭代速度。[原始链接-reddit](https://www.reddit.com/r/LocalLLaMA/comments/1r5uhfu/deflation_cost_to_train_ai_models_drops_40_per/)

### 2. Qwen3.5 发布信息

Qwen3.5 的权重信息在 HuggingFace 发布，权重文件名为 Qwen3.5-397B-A17B，由 Reddit 用户 Stunning_Energy_7028 提交，归属 LocalLLaMA 社区。这为开源权重的追踪与复现提供了参考，有助于社区对后续微调与应用进行验证与重复性研究。[原始链接-reddit](https://www.reddit.com/r/LocalLLaMA/comments/1r657w5/qwen35_release_blog_post/)

## 📰 重点报道

### AI 安全与评估

- **博弈论视角的AI安全基准** — GT-HarmBench 覆盖 2,009 种高风险多代理情境，评估 15 个前沿模型的社会有益行动比例，显示提示敏感性与潜在风险。多代理干预可将有益结果提升至最多 18%，为 AI 安全领域提供标准化测试平台。[原始链接-arxiv](https://arxiv.org/abs/2602.12316)

### 行业应用与知识图谱

- **意图驱动的智能制造KG与LLM** — 将指令微调的 LLM 与本体对齐的知识图谱融合，实现制造服务生态中的意图驱动交互。实验在域数据集上对 Mistral-7B-Instruct-V02 微调，达到 89.33% 的严格匹配率和 97.27% 的综合准确率，显示显著性能提升。[原始链接-arxiv](https://arxiv.org/abs/2602.12419)

### 时序知识图谱与工具框架

- **实体状态调整促进TKG时序预测** — 提出 EST 框架，利用全局状态缓冲和闭环设计使实体状态持续演化，并将结构证据与序列信号对齐，实现结构-序列的协同推理。核心组件包括拓扑感知状态感知器、统一的时间上下文模块和可插拔的序列骨架。[原始链接-arxiv](https://arxiv.org/abs/2602.12389)

### 开源模型与本地部署

- **StepFunAIMA公告** — StepFun AI 将在 Reddit 的 r/LocalLLaMA 举办 AMA，聚焦背后的开源实验室及 Step-3.5-Flash 模型，AMA 安排在美西时间周四（2月19日）8:00-11:00 PST，提问请在独立帖子中提交。[原始链接-reddit](https://www.reddit.com/r/LocalLLaMA/comments/1r60qu9/ama_announcement_stepfun_ai_the_opensource_lab/)

- **MiniMax-2.5 本地运行** — 230B 参数的 MiniMax-2.5 在本地可部署，活跃约 10B，提供约 101GB 的 GGUF 模型以实现 62% 的尺寸缩减；官方指南及 GGUF 模型资源完备，便于本地部署与实验。[原始链接-reddit](https://www.reddit.com/r/LocalLLaMA/comments/1r5h1gj/you_can_run_minimax25_locally/)

- **AI代理的K8S编排工具** — Show HN 报道的一款生成式 AI 基础设施工具 Klaw.sh，借鉴 Kubernetes 的模型编排理念管理 AI 代理：集群、命名空间、通道与技能等实现团队隔离与跨账户治理，提供类似 kubectl 的 CLI，且将代理实现从 Node.js 切换到 Go，体积从 800MB+降至不足 10MB。[原始链接-github](https://github.com/klawsh/klaw.sh)

- **离线手机运行 AI** — Off Grid 是一款开源应用，可在手机端离线运行文本生成、图像生成、视觉 AI 和语音转写等能力，数据不上传云端，适合无网络环境使用。它通过 llama.cpp、Stable Diffusion、Whisper、SmolVLM/Qwen3-VL 等模型实现本地推理，MIT 许可，源代码托管在 GitHub。[原始链接-github](https://github.com/alichherawalla/off-grid-mobile)

- **新闻机构限互联网档案馆AI抓取** — 多家新闻出版商出于对 AI 系统抓取新闻内容用于训练 LLM 的担忧，限制对互联网档案馆的访问，可能影响历史档案研究与信息开放性的讨论。[原始链接-rss](https://www.niemanlab.org/2026/01/news-publishers-limit-internet-archive-access-due-to-ai-scraping-concerns/)

### 数据与档案开放性

- **数据与档案开放性相关讨论** — 新闻出版行业对互联网档案馆的访问限制反映出在 AI 训练数据获取方面的政策与安全考量，未来需在研究自由与版权保护之间寻找平衡点。[原始链接-rss](https://www.niemanlab.org/2026/01/news-publishers-limit-internet-archive-access-due-to-ai-scraping-concerns/)

## ⚡ 快讯速览

- **MiniMax AMA 问答** — MiniMax 团队在 r/LocalLLaMA 的 AMA 介绍了产品与计划，结束后将继续回答问题。[原始链接-reddit](https://www.reddit.com/r/LocalLLaMA/comments/1r3t775/ama_with_minimax_ask_us_anything/)
- **ClawdBot 入职 OpenAI** — OpenClaw 的 ClawdBot 将加入 OpenAI，职位细节待披露，引发行业关注。[原始链接-x](https://twitter.com/sama/status/2023150230905159801)
- **开源本地个人AI助手** — OpenClaw 提供本地离线个人 AI 助手，跨渠道对话与多平台支持，强调隐私和即时性。[原始链接-github](https://github.com/openclaw/openclaw)
- **端上实时语音识别开源库** — Moonshine Voice 提供端上实时语音识别工具包，低延迟、隐私友好，跨平台集成。[原始链接-github](https://github.com/moonshine-ai/moonshine)
- **多3090上vLLM极限性能** — 通过打补丁驱动的 p2p 与 vLLM，在 4x RTX 3090 上实现约 50% 的性能提升，需特定硬件配置与 BIOS 调整。[原始链接-reddit](https://www.reddit.com/r/LocalLLaMA/comments/1r66jyp/vllm_maximum_performance_on_multi3090/)
- **OpenClaw 离线化运行** — Fork 的 Physiclaw 支持完全离线运行，去除云端依赖，限制权限并去遥测。[原始链接-reddit](https://www.reddit.com/r/LocalLLaMA/comments/1r67b43/forked_openclaw_to_run_fully_airgapped_no_cloud/)
- **浏览器中可视化的微型GPT** — 在浏览器中可视化的微型 GPT，用于学习理解网络激活与可视化解释。[原始链接-rss](https://microgpt.boratto.ca)
- **两种加速LLM推理的技巧** — 两种提升 LLM 推理速度的技巧聚焦于推理阶段性能优化，激发社区讨论。[原始链接-rss](https://www.seangoedecke.com/fast-llm-inference/)
- **Gemini3深思绘鹈鹕骑车** — Gemini3 的 Deep Think 能直接生成可视化图形示例，如鹈鹕骑车的 SVG，展现多模态生成潜力。[原始链接-rss](https://simonwillison.net/2026/Feb/12/gemini-3-deep-think/)
- **Anthropic tries to hide Claude's AI actions. Devs hate it** — 探讨 Anthropic 对 Claude AI 操作的隐瞒及开发者态度的争议性话题。[原始链接-rss](https://www.theregister.com/2026/02/16/anthropic_claude_ai_edits/)
- **为何新模型都在讲代码？** — 针对新模型偏重编码能力的现象进行讨论，呼吁拓展非编码场景的应用潜力。[原始链接-reddit](https://www.reddit.com/r/LocalLLaMA/comments/1r63fhu/why_is_everything_about_code_now/)
- **StrixROCm提速后回归** — Strix Halo 在 llamacpp-rocm 的提示处理速度回归，比较多模型在 Vulkan 与 ROCm 下的性能差异。[原始链接-reddit](https://www.reddit.com/r/LocalLLaMA/comments/1r68z93/llamacpp_rocm_prompt_processing_speed_on_strix/)
- **AI领域变化快，信息泛滥** — 评论AI领域信息更新迅速、信息源分散导致深度信息获取困难的现状与挑战。[原始链接-reddit](https://www.reddit.com/r/LocalLLaMA/comments/1r68vle/ai_field_is_changing_so_quickly_and_there_is_so/)
- **DjVu与深度学习的联系** — 探讨 DjVu 数据格式及其与深度学习之间的潜在联系、压缩特性及训练数据加载影响。[原始链接-rss](https://scottlocklin.wordpress.com/2023/05/31/djvu-and-its-connection-to-deep-learning/)
- **质疑Openclaw热度** — Reddit 帖文质疑 OpenClaw 的传播真实性与热度，讨论是否存在营销效应与收购传闻。[原始链接-reddit](https://www.reddit.com/r/LocalLLaMA/comments/1r5v1jb/anyone_actually_using_openclaw/)

---

*本报告由 AI News Agent 自动生成 | 2026-02-16*